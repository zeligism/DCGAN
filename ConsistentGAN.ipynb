{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConsistentGAN",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ce15db1308cf4137a2651c8dfe89f3c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8703519d345d4810b176a58f12e00af3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9442ab6eda044d92a55b12aadd92a654",
              "IPY_MODEL_2444b40302af4c889a2ae77e7c01a3b3",
              "IPY_MODEL_5b87e2d7c84e41d390d9b563c688a7b7"
            ]
          }
        },
        "8703519d345d4810b176a58f12e00af3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9442ab6eda044d92a55b12aadd92a654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_28ea9c3081944102a13d7b6d3857eeb1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d822e29f9bde48b69ed5d7190fb60cef"
          }
        },
        "2444b40302af4c889a2ae77e7c01a3b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ecef038dece54a0ab78ad42ac9512dea",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b8dbe767bb9460bba2e7b209d16fdf8"
          }
        },
        "5b87e2d7c84e41d390d9b563c688a7b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6a11c43e1ef24e8a9a6bbbac57f00baa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [01:07&lt;00:00, 67.24s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_68328d286f264b8a9af2596a229ddb0a"
          }
        },
        "28ea9c3081944102a13d7b6d3857eeb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d822e29f9bde48b69ed5d7190fb60cef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ecef038dece54a0ab78ad42ac9512dea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b8dbe767bb9460bba2e7b209d16fdf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a11c43e1ef24e8a9a6bbbac57f00baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "68328d286f264b8a9af2596a229ddb0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d80138f64466454e9e4b082a2ca9ae2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2435793fc4104ff28dd4f7331d190de7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e1670c2b447a4f4aa3a90cf43063099c",
              "IPY_MODEL_57845f65f9ed4616a94a8705c24a5633",
              "IPY_MODEL_c2a0baa293da4d80882a040cc2213d05"
            ]
          }
        },
        "2435793fc4104ff28dd4f7331d190de7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1670c2b447a4f4aa3a90cf43063099c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_94b490b78049466e9841e8d19375bab3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_81ec79b2732541c68192101ea5ed93c5"
          }
        },
        "57845f65f9ed4616a94a8705c24a5633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fe4dc33999b2426cb90c315f0132315f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 781,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 79,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_27db98ab6d5540b98eacbc5533566cee"
          }
        },
        "c2a0baa293da4d80882a040cc2213d05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e40ed04938fd43c4806e148878ebd31b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 79/781 [01:07&lt;09:55,  1.18it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_168e2b0a3f9846aaa4da5fa989d4ee43"
          }
        },
        "94b490b78049466e9841e8d19375bab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "81ec79b2732541c68192101ea5ed93c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe4dc33999b2426cb90c315f0132315f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "27db98ab6d5540b98eacbc5533566cee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e40ed04938fd43c4806e148878ebd31b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "168e2b0a3f9846aaa4da5fa989d4ee43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeligism/DCGAN/blob/master/ConsistentGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxx3Jy_8qsPE"
      },
      "source": [
        "### Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MFx20xTNkpQ",
        "outputId": "d15b4218-cfdd-41ab-96fb-3601a17bae19"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-QNzdq01hSb"
      },
      "source": [
        "# Header"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSlF68ff2K8L"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf_Qrpq7z3iJ"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import glob\n",
        "import random\n",
        "import datetime\n",
        "import yaml\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "import torchvision\n",
        "import torchvision.utils as vutils\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.tensorboard as tensorboard\n",
        "\n",
        "from PIL import Image, ImageDraw\n",
        "from math import log2\n",
        "from pprint import pformat\n",
        "from collections import defaultdict"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USDduLe1Qkd9"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiRxrufxw1cm"
      },
      "source": [
        "### Report Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmEyNG58w2kJ"
      },
      "source": [
        "def plot_lines(losses_dict, filename=None, title=\"\"):\n",
        "    \"\"\"\n",
        "    Plots the losses of the discriminator and the generator.\n",
        "\n",
        "    Args:\n",
        "        filename: The plot's filename. If None, plot won't be saved.\n",
        "    \"\"\"\n",
        "\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.title(title)\n",
        "    for label, losses in losses_dict.items():\n",
        "        plt.plot(losses, label=label)\n",
        "    plt.xlabel(\"t\")\n",
        "    plt.legend()\n",
        "    \n",
        "    if filename is not None:\n",
        "        plt.savefig(filename)\n",
        "    \n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def create_progress_animation(frames, filename):\n",
        "    \"\"\"\n",
        "    Creates a video of the progress of the generator on a fixed latent vector.\n",
        "\n",
        "    Args:\n",
        "        filename: The animation's filename.\n",
        "    \"\"\"\n",
        "\n",
        "    fig = plt.figure(figsize=(8,8))\n",
        "    plt.axis(\"off\")\n",
        "    ims = [[plt.imshow(img.permute(1,2,0), animated=True)]\n",
        "           for img in frames]\n",
        "    ani = animation.ArtistAnimation(fig, ims, blit=True)\n",
        "    \n",
        "    ani.save(filename)\n",
        "\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def generate_grid(generator, latent):\n",
        "    \"\"\"\n",
        "    Check generator's output on latent vectors and return it.\n",
        "\n",
        "    Args:\n",
        "        generator: The generator.\n",
        "        latent: Latent vector from which an image grid will be generated.\n",
        "\n",
        "    Returns:\n",
        "        A grid of images generated by `generator` from `latent`.\n",
        "    \"\"\"\n",
        "\n",
        "    with torch.no_grad():\n",
        "        fake = generator(latent).detach()\n",
        "\n",
        "    image_grid = vutils.make_grid(fake.cpu(), padding=2, normalize=True, range=(-1,1))\n",
        "\n",
        "    return image_grid\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUzwGurc1qOx"
      },
      "source": [
        "# Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPhc2oS53G4e"
      },
      "source": [
        "## PyTorch Modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU7HFc6t5N8w"
      },
      "source": [
        "### DCGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJHPo8w13JmH"
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Default stride and padding half the size of features,\n",
        "    e.g. if input is [in_channels, 64, 64], output will be [out_channels, 32, 32].\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=4, stride=2, padding=1,\n",
        "                 use_batchnorm=True, use_spectralnorm=False, activation=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,\n",
        "                              stride=stride, padding=padding, bias=False)\n",
        "        if use_spectralnorm:\n",
        "            self.conv = nn.utils.parametrizations.spectral_norm(self.conv)\n",
        "        self.batchnorm = nn.BatchNorm2d(out_channels) if use_batchnorm else None\n",
        "        self.activation = nn.LeakyReLU(0.2, inplace=True) if activation is None else activation()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        if self.batchnorm:\n",
        "            x = self.batchnorm(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ConvTBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Default stride and padding double the size of features,\n",
        "    e.g. if input is [in_channels, 32, 32], output will be [out_channels, 64, 64].\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=4, stride=2, padding=1,\n",
        "                 use_batchnorm=True, use_spectralnorm=False, activation=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.convT = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size,\n",
        "                                        stride=stride, padding=padding, bias=False)\n",
        "        if use_spectralnorm:\n",
        "            self.convT = nn.utils.parametrizations.spectral_norm(self.convT)\n",
        "        self.batchnorm = nn.BatchNorm2d(out_channels) if use_batchnorm else None\n",
        "        self.activation = nn.ReLU(inplace=True) if activation is None else activation()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convT(x)\n",
        "        if self.batchnorm:\n",
        "            x = self.batchnorm(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DCGAN_Discriminator(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_latents=16,\n",
        "                 num_features=64,\n",
        "                 image_channels=3,\n",
        "                 image_size=64,\n",
        "                 feature_multiplier=2,\n",
        "                 max_features=512,\n",
        "                 gan_type=\"gan\",\n",
        "                 fully_convolutional=True,\n",
        "                 activation=None,\n",
        "                 use_batchnorm=True,\n",
        "                 use_spectralnorm=False,\n",
        "                 output_sigmoid=True,\n",
        "                 D_block=ConvBlock):\n",
        "        super().__init__()\n",
        "\n",
        "        using_grad_penalty = gan_type in (\"gan-gp\", \"wgan-gp\")\n",
        "        output_sigmoid = output_sigmoid and gan_type in (\"gan\", \"gan-gp\")\n",
        "\n",
        "        block_config = {\n",
        "            \"activation\": activation,\n",
        "            \"use_batchnorm\": use_batchnorm and not using_grad_penalty,\n",
        "            \"use_spectralnorm\": use_spectralnorm,\n",
        "        }\n",
        "\n",
        "        # Calculate intermediate image sizes\n",
        "        image_sizes = [image_size]\n",
        "        while image_sizes[-1] > 5:\n",
        "            image_sizes.append(image_sizes[-1] // 2)\n",
        "        latent_kernel = image_sizes[-1]  # should be either 3, 4, or 5\n",
        "        num_layers = len(image_sizes) - 1\n",
        "\n",
        "        # Calculate feature sizes\n",
        "        features = [min(max_features, round(num_features * feature_multiplier**i))\n",
        "                    for i in range(num_layers)]\n",
        "\n",
        "        # Input layer\n",
        "        self.input_layer = D_block(image_channels, features[0], **block_config)\n",
        "\n",
        "        # Intermediate layers\n",
        "        self.main_layers = nn.Sequential(*[\n",
        "            D_block(in_features, out_features, **block_config)\n",
        "            for in_features, out_features in zip(features, features[1:])\n",
        "        ])\n",
        "\n",
        "        # Output layer (feature_size = 3, 4, or 5 -> 1)\n",
        "        if fully_convolutional:\n",
        "            conv = nn.Conv2d(features[-1], num_latents, latent_kernel, bias=False)\n",
        "            if use_spectralnorm:\n",
        "                conv = nn.utils.parametrizations.spectral_norm(conv)\n",
        "            self.output_layer = nn.Sequential(conv, nn.Flatten())\n",
        "        else:\n",
        "            linear = nn.Linear(features[-1] * latent_kernel**2, num_latents, bias=False)\n",
        "            if use_spectralnorm:\n",
        "                linear = nn.utils.parametrizations.spectral_norm(linear)\n",
        "            self.output_layer = nn.Sequential(nn.Flatten(), linear)\n",
        "        \n",
        "        self.hidden_dim = features[-1] * latent_kernel**2\n",
        "\n",
        "        # Add sigmoid activation if using regular GAN loss\n",
        "        self.output_activation = nn.Sigmoid() if output_sigmoid else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_layer(x)\n",
        "        x = self.main_layers(x)\n",
        "        x = self.output_layer(x)\n",
        "        if self.output_activation:\n",
        "            x = self.output_activation(x)\n",
        "        # Remove H and W dimensions, infer channels dim (remove if 1)\n",
        "        x = x.view(x.size(0), -1).squeeze(1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DCGAN_Generator(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_latents=100,\n",
        "                 num_features=64,\n",
        "                 image_channels=3,\n",
        "                 image_size=64,\n",
        "                 feature_multiplier=2,\n",
        "                 max_features=512,\n",
        "                 gan_type=\"gan\",\n",
        "                 fully_convolutional=True,\n",
        "                 activation=None,\n",
        "                 use_batchnorm=True,\n",
        "                 use_spectralnorm=False,\n",
        "                 G_block=ConvTBlock):\n",
        "        super().__init__()\n",
        "\n",
        "        block_config = {\n",
        "            \"activation\": activation,\n",
        "            \"use_batchnorm\": use_batchnorm,\n",
        "            \"use_spectralnorm\": use_spectralnorm\n",
        "        }\n",
        "\n",
        "        # Calculate intermediate image sizes\n",
        "        image_sizes = [image_size]\n",
        "        while image_sizes[-1] > 5:\n",
        "            image_sizes.append(image_sizes[-1] // 2)\n",
        "        latent_kernel = image_sizes[-1]  # should be either 3, 4, or 5\n",
        "        num_layers = len(image_sizes) - 1\n",
        "\n",
        "        # Calculate feature sizes\n",
        "        features = [min(max_features, round(num_features * feature_multiplier**i))\n",
        "                    for i in range(num_layers)]\n",
        "\n",
        "        # Reverse order of image sizes and features for generator\n",
        "        image_sizes = image_sizes[::-1]\n",
        "        features = features[::-1]\n",
        "\n",
        "        # Input layer\n",
        "        if fully_convolutional:\n",
        "            self.input_layer = G_block(num_latents, features[0], kernel_size=latent_kernel,\n",
        "                                       stride=1, padding=0, **block_config)\n",
        "        else:\n",
        "            self.input_layer = nn.Sequential(\n",
        "                nn.Flatten(),\n",
        "                nn.Linear(num_latents, features[0] * image_sizes[0]**2, bias=False),\n",
        "                View(features[0], image_sizes[0], image_sizes[0])\n",
        "            )\n",
        "\n",
        "        # Intermediate layers\n",
        "        self.main_layers = nn.Sequential(*[\n",
        "            G_block(in_features, out_features, kernel_size=4+(expected_size%2), **block_config)\n",
        "            for in_features, out_features, expected_size in zip(features, features[1:], image_sizes[1:])\n",
        "        ])\n",
        "\n",
        "        # Output layer\n",
        "        self.output_layer = nn.ConvTranspose2d(features[-1], image_channels, kernel_size=4+(image_size%2),\n",
        "                                               stride=2, padding=1, bias=False)\n",
        "        self.output_activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Add H and W dimensions, infer channels dim (add if none)\n",
        "        x = x.view(x.size(0), -1, 1, 1)\n",
        "        x = self.input_layer(x)\n",
        "        x = self.main_layers(x)\n",
        "        x = self.output_layer(x)\n",
        "        x = self.output_activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DCGAN(nn.Module):\n",
        "    \"\"\"Deep Convolutional Generative Adversarial Network\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_latents=100,\n",
        "                 D_num_features=64,\n",
        "                 G_num_features=64,\n",
        "                 image_channels=3,\n",
        "                 image_size=64,\n",
        "                 feature_multiplier=2,\n",
        "                 gan_type=\"gan\",\n",
        "                 fully_convolutional=True,\n",
        "                 activation=None,\n",
        "                 use_batchnorm=True,\n",
        "                 use_spectralnorm=False,\n",
        "                 output_sigmoid=True,):\n",
        "        \"\"\"\n",
        "        Initializes DCGAN.\n",
        "\n",
        "        Args:\n",
        "            num_latents: Number of latent factors.\n",
        "            num_features: Number of features in the convolutions.\n",
        "            image_channels: Number of channels in the input image.\n",
        "            image_size: Size (i.e. height or width) of image.\n",
        "            gan_type: Type of GAN (e.g. \"gan\" or \"wgan-gp\").\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_latents = num_latents\n",
        "        self.D_num_features = D_num_features\n",
        "        self.G_num_features = G_num_features\n",
        "        self.image_channels = image_channels\n",
        "        self.image_size = image_size\n",
        "        self.feature_multiplier = feature_multiplier\n",
        "        self.gan_type = gan_type\n",
        "        self.fully_convolutional = fully_convolutional\n",
        "        self.activation = activation\n",
        "        self.use_batchnorm = use_batchnorm\n",
        "        self.use_spectralnorm = use_spectralnorm\n",
        "\n",
        "        D_params = {\n",
        "            \"num_latents\": 1,  # XXX\n",
        "            \"num_features\": D_num_features,\n",
        "            \"image_channels\": image_channels,\n",
        "            \"image_size\": image_size,\n",
        "            \"feature_multiplier\": feature_multiplier,\n",
        "            \"gan_type\": gan_type,\n",
        "            \"fully_convolutional\": fully_convolutional,\n",
        "            \"activation\": activation,\n",
        "            \"use_batchnorm\": use_batchnorm,\n",
        "            \"use_spectralnorm\": use_spectralnorm,\n",
        "            \"output_sigmoid\": output_sigmoid,\n",
        "        }\n",
        "        G_params = {\n",
        "            \"num_latents\": num_latents,\n",
        "            \"num_features\": G_num_features,\n",
        "            \"image_channels\": image_channels,\n",
        "            \"image_size\": image_size,\n",
        "            \"feature_multiplier\": feature_multiplier,\n",
        "            \"gan_type\": gan_type,\n",
        "            \"fully_convolutional\": fully_convolutional,\n",
        "            \"activation\": activation,\n",
        "            \"use_batchnorm\": True,\n",
        "            \"use_spectralnorm\": False,  # XXX\n",
        "        }\n",
        "\n",
        "        self.D = DCGAN_Discriminator(**D_params)\n",
        "        self.G = DCGAN_Generator(**G_params)\n",
        "\n",
        "\n",
        "class View(nn.Module):\n",
        "    def __init__(self, *shape, including_batch=False):\n",
        "        super().__init__()\n",
        "        self.shape = shape\n",
        "        self.including_batch = including_batch\n",
        "    \n",
        "    def forward(self, x):\n",
        "        if self.including_batch:\n",
        "            return x.view(*self.shape)\n",
        "        else:\n",
        "            return x.view(x.size(0), *self.shape)\n",
        "\n",
        "class ChannelNoise(nn.Module):\n",
        "    \"\"\"\n",
        "    Channel noise injection module.\n",
        "    Adds a linearly transformed noise to a convolution layer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_channels, std=0.02):\n",
        "        super().__init__()\n",
        "        self.std = std\n",
        "        self.scale = nn.Parameter(torch.ones(1, num_channels, 1, 1))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        noise_size = [x.size()[0], 1, *x.size()[2:]]  # single channel\n",
        "        noise = self.std * torch.randn(noise_size).to(x)\n",
        "\n",
        "        return x + self.scale * noise"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSPvaklIYvwT"
      },
      "source": [
        "### Third-party modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS9B8z4ZY4oX"
      },
      "source": [
        "#### DCGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLNQ90KUY_Is"
      },
      "source": [
        "class ConditionalBatchNorm2d(nn.Module):\n",
        "  def __init__(self, num_features, repr_dim):\n",
        "    super().__init__()\n",
        "    self.num_features = num_features\n",
        "    self.bn = nn.BatchNorm2d(num_features, affine=False)\n",
        "    self.embed = nn.Linear(repr_dim, num_features * 2)\n",
        "    self.embed.weight.data[:, :num_features].normal_(1, 0.02)  # Initialise scale at N(1, 0.02)\n",
        "    self.embed.weight.data[:, num_features:].zero_()  # Initialise bias at 0\n",
        "\n",
        "  def forward(self, x, y):\n",
        "    out = self.bn(x)\n",
        "    gamma, beta = self.embed(y).chunk(2, 1)\n",
        "    out = gamma.view(-1, self.num_features, 1, 1) * out + beta.view(-1, self.num_features, 1, 1)\n",
        "    return out\n",
        "\n",
        "\n",
        "#https://github.com/christiancosgrove/pytorch-spectral-normalization-gan/blob/master/model.py\n",
        "\n",
        "from torch.nn.utils.parametrizations import spectral_norm\n",
        "\n",
        "class SNDCGAN_Generator(nn.Module):\n",
        "    def __init__(self, z_dim, image_size=32, num_features=64, channels=3, repr_dim=None):\n",
        "        super().__init__()\n",
        "        self.z_dim = z_dim\n",
        "\n",
        "        self.conv1 = nn.ConvTranspose2d(z_dim, 8*num_features, 4, stride=1)\n",
        "        self.bn1 = ConditionalBatchNorm2d(8*num_features, repr_dim)\n",
        "        self.conv2 = nn.ConvTranspose2d(8*num_features, 4*num_features, 4, stride=2, padding=(1,1))\n",
        "        self.bn2 = ConditionalBatchNorm2d(4*num_features, repr_dim)\n",
        "        self.conv3 = nn.ConvTranspose2d(4*num_features, 2*num_features, 4, stride=2, padding=(1,1))\n",
        "        self.bn3 = ConditionalBatchNorm2d(2*num_features, repr_dim)\n",
        "        self.conv4 = nn.ConvTranspose2d(2*num_features, num_features, 4, stride=2, padding=(1,1))\n",
        "        self.bn4 = ConditionalBatchNorm2d(num_features, repr_dim)\n",
        "\n",
        "        if image_size == 64:\n",
        "            self.conv5 = nn.ConvTranspose2d(num_features, num_features//2, 4, stride=2, padding=(1,1))\n",
        "            self.bn5 = ConditionalBatchNorm2d(num_features//2, repr_dim)\n",
        "            self.final_conv = nn.ConvTranspose2d(num_features//2, channels, 3, stride=1, padding=(1,1))\n",
        "        else:\n",
        "            self.conv5 = None\n",
        "            self.bn5 = None\n",
        "            self.final_conv = nn.ConvTranspose2d(num_features, channels, 3, stride=1, padding=(1,1))\n",
        "\n",
        "        self.block_activation = nn.ReLU()\n",
        "        self.output_activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, z, repr=None):\n",
        "        h = z.view(-1, self.z_dim, 1, 1)\n",
        "        h = self.block_activation(self.bn1(self.conv1(h), repr))\n",
        "        h = self.block_activation(self.bn2(self.conv2(h), repr))\n",
        "        h = self.block_activation(self.bn3(self.conv3(h), repr))\n",
        "        h = self.block_activation(self.bn4(self.conv4(h), repr))\n",
        "        if self.conv5 is not None:\n",
        "            h = self.block_activation(self.bn5(self.conv5(h), repr))\n",
        "        return self.output_activation(self.final_conv(h))\n",
        "\n",
        "class SNDCGAN_Discriminator(nn.Module):\n",
        "    def __init__(self, image_size=32, num_features=64, channels=3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            spectral_norm(nn.Conv2d(channels, num_features, 3, stride=1, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(num_features, num_features, 4, stride=2, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(num_features, 2*num_features, 3, stride=1, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(2*num_features, 2*num_features, 4, stride=2, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(2*num_features, 4*num_features, 3, stride=1, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(4*num_features, 4*num_features, 4, stride=2, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(4*num_features, 8*num_features, 3, stride=1, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True)\n",
        "        )\n",
        "\n",
        "        if image_size == 64:\n",
        "            self.from64 = nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(8*num_features, 8*num_features, 3, stride=2, padding=(1,1))),\n",
        "                nn.LeakyReLU(0.1, inplace=True),\n",
        "                spectral_norm(nn.Conv2d(8*num_features, 16*num_features, 3, stride=1, padding=(1,1))),\n",
        "                nn.LeakyReLU(0.1, inplace=True),\n",
        "            )\n",
        "            self.hidden_dim = 4*4 * 16*num_features\n",
        "        else:\n",
        "            self.from64 = None\n",
        "            self.hidden_dim = 4*4 * 8*num_features\n",
        "\n",
        "        self.fc = spectral_norm(nn.Linear(self.hidden_dim, 1))\n",
        "\n",
        "    def forward(self, x, return_h=False):\n",
        "        h = self.main(x)\n",
        "        if self.from64 is not None:\n",
        "            h = self.from64(h)\n",
        "        h = h.flatten(start_dim=1)\n",
        "        out = self.fc(h).squeeze(1)\n",
        "        if return_h:\n",
        "            return out, h\n",
        "        else:\n",
        "            return out\n",
        "\n",
        "\n",
        "class SNDCGAN(nn.Module):\n",
        "    def __init__(self, num_latents, image_size=32,\n",
        "                 D_num_features=64, G_num_features=64, channels=3, repr_dim=None):\n",
        "        super().__init__()\n",
        "        self.num_latents = num_latents\n",
        "        self.channels = channels\n",
        "        self.D = SNDCGAN_Discriminator(channels=channels,\n",
        "                                       image_size=image_size,\n",
        "                                       num_features=D_num_features)\n",
        "        self.G = SNDCGAN_Generator(num_latents, channels=channels,\n",
        "                                   image_size=image_size,\n",
        "                                   num_features=G_num_features,\n",
        "                                   repr_dim=repr_dim)\n",
        "    "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eiu_Ri-XY6yy"
      },
      "source": [
        "#### ResNet GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFjWBbXzdlSF"
      },
      "source": [
        "# https://github.com/christiancosgrove/pytorch-spectral-normalization-gan/blob/master/model_resnet.py\n",
        "\n",
        "from torch.nn.utils.parametrizations import spectral_norm\n",
        "\n",
        "class ResBlockGenerator(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, repr_dim=None):\n",
        "        super(ResBlockGenerator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, 1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=1)\n",
        "        nn.init.xavier_uniform_(self.conv1.weight.data, 1.)\n",
        "        nn.init.xavier_uniform_(self.conv2.weight.data, 1.)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            self.conv1,\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            self.conv2\n",
        "            )\n",
        "        self.bypass = nn.Sequential()\n",
        "        if stride != 1:\n",
        "            self.bypass = nn.Upsample(scale_factor=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x) + self.bypass(x)\n",
        "\n",
        "class ResBlockGeneratorConditional(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, repr_dim=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, 1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=1)\n",
        "        nn.init.xavier_uniform_(self.conv1.weight.data, 1.)\n",
        "        nn.init.xavier_uniform_(self.conv2.weight.data, 1.)\n",
        "\n",
        "        self.bn1 = ConditionalBatchNorm2d(in_channels, repr_dim)\n",
        "        self.upsample = nn.Upsample(scale_factor=2)\n",
        "        self.bn2 = ConditionalBatchNorm2d(out_channels, repr_dim)\n",
        "\n",
        "        self.bypass = nn.Sequential()\n",
        "        if stride != 1:\n",
        "            self.bypass = nn.Upsample(scale_factor=2)\n",
        "\n",
        "    def forward(self, x, repr):\n",
        "        h = F.relu(self.bn1(x, repr))\n",
        "        h = self.conv1(self.upsample(h))\n",
        "        h = F.relu(self.bn2(h, repr))\n",
        "        h = self.conv2(h)\n",
        "        return self.bypass(x) + h\n",
        "\n",
        "\n",
        "class ResBlockDiscriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResBlockDiscriminator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, 1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=1)\n",
        "        nn.init.xavier_uniform_(self.conv1.weight.data, 1.)\n",
        "        nn.init.xavier_uniform_(self.conv2.weight.data, 1.)\n",
        "\n",
        "        if stride == 1:\n",
        "            self.model = nn.Sequential(\n",
        "                nn.ReLU(),\n",
        "                spectral_norm(self.conv1),\n",
        "                nn.ReLU(),\n",
        "                spectral_norm(self.conv2)\n",
        "                )\n",
        "        else:\n",
        "            self.model = nn.Sequential(\n",
        "                nn.ReLU(),\n",
        "                spectral_norm(self.conv1),\n",
        "                nn.ReLU(),\n",
        "                spectral_norm(self.conv2),\n",
        "                nn.AvgPool2d(2, stride=stride, padding=0)\n",
        "                )\n",
        "        self.bypass = nn.Sequential()\n",
        "        if stride != 1:\n",
        "\n",
        "            self.bypass_conv = nn.Conv2d(in_channels,out_channels, 1, 1, padding=0)\n",
        "            nn.init.xavier_uniform_(self.bypass_conv.weight.data, np.sqrt(2))\n",
        "\n",
        "            self.bypass = nn.Sequential(\n",
        "                spectral_norm(self.bypass_conv),\n",
        "                nn.AvgPool2d(2, stride=stride, padding=0)\n",
        "            )\n",
        "            # if in_channels == out_channels:\n",
        "            #     self.bypass = nn.AvgPool2d(2, stride=stride, padding=0)\n",
        "            # else:\n",
        "            #     self.bypass = nn.Sequential(\n",
        "            #         spectral_norm(nn.Conv2d(in_channels,out_channels, 1, 1, padding=0)),\n",
        "            #         nn.AvgPool2d(2, stride=stride, padding=0)\n",
        "            #     )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x) + self.bypass(x)\n",
        "\n",
        "# special ResBlock just for the first layer of the discriminator\n",
        "class FirstResBlockDiscriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(FirstResBlockDiscriminator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, 1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=1)\n",
        "        self.bypass_conv = nn.Conv2d(in_channels, out_channels, 1, 1, padding=0)\n",
        "        nn.init.xavier_uniform_(self.conv1.weight.data, 1.)\n",
        "        nn.init.xavier_uniform_(self.conv2.weight.data, 1.)\n",
        "        nn.init.xavier_uniform_(self.bypass_conv.weight.data, np.sqrt(2))\n",
        "\n",
        "        # we don't want to apply ReLU activation to raw image before convolution transformation.\n",
        "        self.model = nn.Sequential(\n",
        "            spectral_norm(self.conv1),\n",
        "            nn.ReLU(),\n",
        "            spectral_norm(self.conv2),\n",
        "            nn.AvgPool2d(2)\n",
        "            )\n",
        "        self.bypass = nn.Sequential(\n",
        "            nn.AvgPool2d(2),\n",
        "            spectral_norm(self.bypass_conv),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x) + self.bypass(x)\n",
        "\n",
        "\n",
        "class SNResNetGenerator(nn.Module):\n",
        "    def __init__(self, z_dim, num_features=128, channels=3, repr_dim=None):\n",
        "        super().__init__()\n",
        "        self.z_dim = z_dim\n",
        "        self.num_features = num_features\n",
        "\n",
        "        self.dense = nn.Linear(self.z_dim, 4 * 4 * num_features)\n",
        "        self.final = nn.Conv2d(num_features, channels, 3, stride=1, padding=1)\n",
        "        nn.init.xavier_uniform_(self.dense.weight.data, 1.)\n",
        "        nn.init.xavier_uniform_(self.final.weight.data, 1.)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            ResBlockGenerator(num_features, num_features, stride=2),\n",
        "            ResBlockGenerator(num_features, num_features, stride=2),\n",
        "            ResBlockGenerator(num_features, num_features, stride=2),\n",
        "            nn.BatchNorm2d(num_features),\n",
        "            nn.ReLU(),\n",
        "            self.final,\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(self.dense(z).view(-1, self.num_features, 4, 4))\n",
        "\n",
        "class SNResNetGeneratorConditional(nn.Module):\n",
        "    def __init__(self, z_dim, num_features=128, image_size=32, channels=3, repr_dim=None):\n",
        "        super().__init__()\n",
        "        self.z_dim = z_dim\n",
        "        self.num_features = num_features\n",
        "\n",
        "        self.dense = nn.Linear(self.z_dim, 4 * 4 * num_features)\n",
        "        self.final = nn.Conv2d(num_features, channels, 3, stride=1, padding=1)\n",
        "        nn.init.xavier_uniform_(self.dense.weight.data, 1.)\n",
        "        nn.init.xavier_uniform_(self.final.weight.data, 1.)\n",
        "\n",
        "        self.block1 = ResBlockGeneratorConditional(num_features, num_features, stride=2, repr_dim=repr_dim)\n",
        "        self.block2 = ResBlockGeneratorConditional(num_features, num_features, stride=2, repr_dim=repr_dim)\n",
        "        self.block3 = ResBlockGeneratorConditional(num_features, num_features, stride=2, repr_dim=repr_dim)\n",
        "        if image_size == 64:\n",
        "            self.block4 = ResBlockGeneratorConditional(num_features, num_features, stride=2, repr_dim=repr_dim)\n",
        "        else:\n",
        "            self.block4 = None\n",
        "        self.bn = ConditionalBatchNorm2d(num_features, repr_dim)\n",
        "\n",
        "    def forward(self, z, repr):\n",
        "        h = self.dense(z).view(-1, self.num_features, 4, 4)\n",
        "        h = self.block1(h, repr)\n",
        "        h = self.block2(h, repr)\n",
        "        h = self.block3(h, repr)\n",
        "        if self.block4 is not None:\n",
        "            h = self.block4(h, repr)\n",
        "        h = F.relu(self.bn(h, repr))\n",
        "        out = F.tanh(self.final(h))\n",
        "        return out\n",
        "\n",
        "\n",
        "class SNResNetDiscriminator(nn.Module):\n",
        "    def __init__(self, num_features=128, image_size=32, channels=3):\n",
        "        super().__init__()\n",
        "        self.num_features = num_features\n",
        "        self.hidden_dim = num_features\n",
        "        if image_size == 64:\n",
        "            self.hidden_dim *= 4\n",
        "\n",
        "        self.model = [\n",
        "                FirstResBlockDiscriminator(channels, num_features, stride=2),\n",
        "                ResBlockDiscriminator(num_features, num_features, stride=2),\n",
        "                ResBlockDiscriminator(num_features, num_features),\n",
        "                ResBlockDiscriminator(num_features, num_features),\n",
        "        ]\n",
        "        if image_size == 64:\n",
        "            self.model += [ResBlockDiscriminator(num_features, num_features)]\n",
        "        self.model += [nn.ReLU(), nn.AvgPool2d(8)]\n",
        "        self.model = nn.Sequential(*self.model)\n",
        "\n",
        "        self.fc = nn.Linear(self.hidden_dim, 1)\n",
        "        nn.init.xavier_uniform_(self.fc.weight.data, 1.)\n",
        "        self.fc = spectral_norm(self.fc)\n",
        "\n",
        "    def forward(self, x, return_h=False):\n",
        "        h = self.model(x)\n",
        "        h = h.view(-1, self.hidden_dim)\n",
        "        if return_h:\n",
        "            return self.fc(h), h\n",
        "        else:\n",
        "            return self.fc(h)\n",
        "\n",
        "\n",
        "class SNResNetGAN(nn.Module):\n",
        "    def __init__(self, num_latents,\n",
        "                 D_num_features=128, G_num_features=128,\n",
        "                 image_size=64, channels=3, repr_dim=None):\n",
        "        super().__init__()\n",
        "        self.num_latents = num_latents\n",
        "        self.channels = channels\n",
        "        self.D = SNResNetDiscriminator(num_features=D_num_features,\n",
        "                                       image_size=image_size,\n",
        "                                       channels=channels)\n",
        "        self.G = SNResNetGeneratorConditional(num_latents,\n",
        "                                              num_features=G_num_features,\n",
        "                                              image_size=image_size,\n",
        "                                              channels=channels,\n",
        "                                              repr_dim=repr_dim)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYujBEzC7EOO"
      },
      "source": [
        "#### SimSiam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-YcNut27F-v"
      },
      "source": [
        "class SimSiam(nn.Module):\n",
        "    \"\"\"\n",
        "    Build a SimSiam model.\n",
        "    \"\"\"\n",
        "    def __init__(self, base_encoder, dim=2048, pred_dim=512):\n",
        "        \"\"\"\n",
        "        dim: feature dimension (default: 2048)\n",
        "        pred_dim: hidden dimension of the predictor (default: 512)\n",
        "        \"\"\"\n",
        "        super(SimSiam, self).__init__()\n",
        "\n",
        "        # create the encoder\n",
        "        # num_classes is the output fc dimension, zero-initialize last BNs\n",
        "        self.encoder = base_encoder(num_classes=dim, zero_init_residual=True)\n",
        "\n",
        "        # build a 3-layer projector\n",
        "        prev_dim = self.encoder.fc.weight.shape[1]\n",
        "        self.encoder.fc = nn.Sequential(nn.Linear(prev_dim, prev_dim, bias=False),\n",
        "                                        nn.BatchNorm1d(prev_dim),\n",
        "                                        nn.ReLU(inplace=True), # first layer\n",
        "                                        nn.Linear(prev_dim, prev_dim, bias=False),\n",
        "                                        nn.BatchNorm1d(prev_dim),\n",
        "                                        nn.ReLU(inplace=True), # second layer\n",
        "                                        self.encoder.fc,\n",
        "                                        nn.BatchNorm1d(dim, affine=False)) # output layer\n",
        "        self.encoder.fc[6].bias.requires_grad = False # hack: not use bias as it is followed by BN\n",
        "\n",
        "        # build a 2-layer predictor\n",
        "        self.predictor = nn.Sequential(nn.Linear(dim, pred_dim, bias=False),\n",
        "                                        nn.BatchNorm1d(pred_dim),\n",
        "                                        nn.ReLU(inplace=True), # hidden layer\n",
        "                                        nn.Linear(pred_dim, dim)) # output layer\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            x1: first views of images\n",
        "            x2: second views of images\n",
        "        Output:\n",
        "            p1, p2, z1, z2: predictors and targets of the network\n",
        "            See Sec. 3 of https://arxiv.org/abs/2011.10566 for detailed notations\n",
        "        \"\"\"\n",
        "\n",
        "        # compute features for one view\n",
        "        z1 = self.encoder(x1) # NxC\n",
        "        z2 = self.encoder(x2) # NxC\n",
        "\n",
        "        p1 = self.predictor(z1) # NxC\n",
        "        p2 = self.predictor(z2) # NxC\n",
        "\n",
        "        return p1, p2, z1.detach(), z2.detach()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEuurkcmLLd3"
      },
      "source": [
        "### Latent Transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eTlMYVgLN5E"
      },
      "source": [
        "class LatentTransform(nn.Module):\n",
        "    def __init__(self, repr_dim, latent_dim, hidden_dim, full_transform=True, noop=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.repr_dim = repr_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.full_transform = full_transform\n",
        "        self.noop = noop\n",
        "\n",
        "        if self.noop:\n",
        "            self.output_dim = self.latent_dim\n",
        "            return\n",
        "        elif self.full_transform:\n",
        "            self.input_dim = self.repr_dim + self.latent_dim\n",
        "            self.output_dim = self.hidden_dim\n",
        "        else:\n",
        "            self.input_dim = self.repr_dim\n",
        "            self.output_dim = self.hidden_dim + self.latent_dim\n",
        "\n",
        "        self.transform = nn.Linear(self.input_dim, self.hidden_dim)\n",
        "    \n",
        "    def forward(self, repr, noise):\n",
        "        if self.noop:\n",
        "            return noise\n",
        "\n",
        "        # assuming latent is concat as [repr,noise] XXX\n",
        "        if self.full_transform:\n",
        "            latent = torch.cat([repr, noise], dim=1)\n",
        "            latent = self.transform(latent)\n",
        "        else:\n",
        "            repr = self.transform(repr)\n",
        "            latent = torch.cat([repr, noise], dim=1)\n",
        "\n",
        "        return latent\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yRivPV9BwFk"
      },
      "source": [
        "# Training v2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5rpQp2E9rE5"
      },
      "source": [
        "### Imports and globals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51zFNn509xLz"
      },
      "source": [
        "import argparse\n",
        "import builtins\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "import warnings\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.distributed as dist\n",
        "import torch.optim\n",
        "import torch.multiprocessing as mp\n",
        "import torch.utils.data\n",
        "import torch.utils.data.distributed\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "\n",
        "GANSIAM_DIR = \"/content/drive/My Drive/gansiam\"\n",
        "SIMSIAM_PATH = os.path.join(GANSIAM_DIR, \"pretrained_batch256.tar\")\n",
        "TINYIMAGENET_DIR = \"tiny-imagenet-200\""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9X_JYE2Vwxd"
      },
      "source": [
        "### Download Tiny Imagenet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "559H2an_V03M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "976b7c3a-8692-4b40-ffd4-61930b194167"
      },
      "source": [
        "%%bash\n",
        "if [[ -d  \"tiny-imagenet-200\" ]]; then\n",
        "    echo \"Tiny Imagenet exists.\"\n",
        "else\n",
        "    wget -q \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
        "    unzip -qq \"tiny-imagenet-200.zip\" && rm \"tiny-imagenet-200.zip\"\n",
        "    echo \"Downloaded Tiny Imagenet.\"\n",
        "fi"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded Tiny Imagenet.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vbo7T6blPVTc"
      },
      "source": [
        "### Load pre-trained SimSiam model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyzHmINsryyh"
      },
      "source": [
        "#### SimSiam Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8KJUUeWr1dI"
      },
      "source": [
        "from PIL import ImageFilter\n",
        "import random\n",
        "\n",
        "\n",
        "class TwoCropsTransform:\n",
        "    \"\"\"Take two random crops of one image as the query and key.\"\"\"\n",
        "\n",
        "    def __init__(self, base_transform):\n",
        "        self.base_transform = base_transform\n",
        "\n",
        "    def __call__(self, x):\n",
        "        q = self.base_transform(x)\n",
        "        k = self.base_transform(x)\n",
        "        return [q, k]\n",
        "\n",
        "\n",
        "class GaussianBlur(object):\n",
        "    \"\"\"Gaussian blur augmentation in SimCLR https://arxiv.org/abs/2002.05709\"\"\"\n",
        "\n",
        "    def __init__(self, sigma=[.1, 2.]):\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def __call__(self, x):\n",
        "        sigma = random.uniform(self.sigma[0], self.sigma[1])\n",
        "        x = x.filter(ImageFilter.GaussianBlur(radius=sigma))\n",
        "        return x\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "\n",
        "\n",
        "class ProgressMeter(object):\n",
        "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
        "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
        "        self.meters = meters\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def display(self, batch):\n",
        "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
        "        entries += [str(meter) for meter in self.meters]\n",
        "        print('\\t'.join(entries))\n",
        "\n",
        "    def _get_batch_fmtstr(self, num_batches):\n",
        "        num_digits = len(str(num_batches // 1))\n",
        "        fmt = '{:' + str(num_digits) + 'd}'\n",
        "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nr8clgi_AzY",
        "outputId": "391cedd9-2d53-48ce-c112-8122cec4fbbf"
      },
      "source": [
        "checkpoint = torch.load(SIMSIAM_PATH, map_location=\"cuda:0\")\n",
        "# remove 'module.' from dict keys\n",
        "model_dict = OrderedDict((k[7:], v) for k, v in checkpoint[\"state_dict\"].items())\n",
        "\n",
        "# Load model\n",
        "simsiam = SimSiam(models.__dict__[\"resnet50\"])\n",
        "simsiam.load_state_dict(model_dict)\n",
        "#print(simsiam)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kckB_xSVX8kB"
      },
      "source": [
        "# Training v3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nouxldrYb0r"
      },
      "source": [
        "## Args"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUP5vn8OX--p"
      },
      "source": [
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.load = True\n",
        "        self.print_freq = 10\n",
        "        self.seed = None\n",
        "        self.gpu = 0\n",
        "        self.workers = 2\n",
        "        self.epochs = 100\n",
        "\n",
        "        ### lr is about 2e-4 for batch size of 64\n",
        "        # we scale according to our choice of batch size\n",
        "        self.batch_size = 128\n",
        "        self.D_lr = 1e-3 * (self.batch_size / 256)\n",
        "        self.G_lr = 1e-3 * (self.batch_size / 256)\n",
        "        self.Q_lr = self.D_lr\n",
        "        self.latent_transform_lr = self.G_lr\n",
        "        self.lr_decay = 0.02\n",
        "        #self.betas = (0.5, 0.999)\n",
        "        self.betas = (0., 0.9)\n",
        "\n",
        "        # SimSiam (_don't change_ if loading pre-trained)\n",
        "        self.dim = 2048\n",
        "        self.pred_dim = 512\n",
        "\n",
        "        # GAN\n",
        "        self.repr_dim = self.dim  # don't change\n",
        "        self.latent_full_transform = False\n",
        "        self.latent_noise_dim = 512\n",
        "        self.latent_hidden_dim = 512  # dim of transform output\n",
        "        self.Q_hidden_dim = 512\n",
        "        self.num_features = 64\n",
        "        self.D_iters = 5\n",
        "\n",
        "        self.gan_type = \"gan\"  # ignore this\n",
        "        self.resnetgan = True  # overrides wgan when True\n",
        "        self.wgan = False  # if False, use spectral norm\n",
        "        self.grad_penalty = 0.  # 0 if wgan is False\n",
        "        self.grad_center = 1.  # not important\n",
        "\n",
        "        self.generate_grid_interval = 50\n",
        "\n",
        "        # make noise proportional to sd(data)\n",
        "        self.im_noise = 1e-2  # image sd is about 1.0\n",
        "        self.repr_noise = 1e-5  # repr sd is about 1e-3\n",
        "\n",
        "        # Start small, increase later\n",
        "        self.G_consistency = 0.1\n",
        "        self.D_consistency = 0.1\n",
        "\n",
        "\n",
        "GENERATED_GRIDS = []\n",
        "IMAGE_SIZE = 64\n",
        "DATASET = \"Tiny ImageNet\"\n",
        "#DATASET = \"CIFAR10\"\n",
        "args = Args()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xihRlU0PYhiJ"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW_P-JfeYiOe"
      },
      "source": [
        "# image normalization\n",
        "mean = [0.5]\n",
        "std = [0.5]\n",
        "normalize = transforms.Normalize(mean=mean, std=std)\n",
        "inv_normalize = transforms.Normalize(\n",
        "   mean= [-m/s for m, s in zip(mean, std)],\n",
        "   std= [1/s for s in std]\n",
        ")\n",
        "\n",
        "augmentation = [\n",
        "    transforms.Resize(IMAGE_SIZE),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "]\n",
        "\n",
        "# MoCo v2's aug: similar to SimCLR https://arxiv.org/abs/2002.05709\n",
        "_augmentation = [\n",
        "    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.2, 1.)),\n",
        "    transforms.RandomApply([\n",
        "        transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)  # not strengthened\n",
        "    ], p=0.8),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.RandomApply([GaussianBlur([.1, 2.])], p=0.5),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "]\n",
        "\n",
        "if DATASET == \"MNIST\":\n",
        "    augmentation = [transforms.Grayscale(3)] + augmentation\n",
        "    train_dataset = datasets.MNIST(\n",
        "        root=os.path.join(GANSIAM_DIR, \"mnist/train\"), train=True, download=True,\n",
        "        transform=transforms.Compose(augmentation))\n",
        "elif DATASET == \"CelebA\":\n",
        "    train_dataset = datasets.CelebA(\n",
        "        root=os.path.join(GANSIAM_DIR, \"celeba\"), download=True,\n",
        "        transform=transforms.Compose(augmentation))\n",
        "elif DATASET == \"CIFAR10\":\n",
        "    train_dataset = datasets.CIFAR10(\n",
        "        root=os.path.join(GANSIAM_DIR, \"cifar10/train\"), train=True, download=True,\n",
        "        transform=transforms.Compose(augmentation))\n",
        "        #transform=TwoCropsTransform(transforms.Compose(augmentation)))\n",
        "elif DATASET == \"Tiny ImageNet\":\n",
        "    train_dataset = datasets.ImageFolder(\n",
        "        root=os.path.join(TINYIMAGENET_DIR, 'train'),\n",
        "        transform=transforms.Compose(augmentation))\n",
        "else:\n",
        "    raise Exception(f\"Dataset '{DATASET}' not found\")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=args.batch_size, shuffle=True,\n",
        "    num_workers=args.workers, pin_memory=True, sampler=None, drop_last=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oQ0_BfjmAHf"
      },
      "source": [
        "### Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmLiHFvBimb3"
      },
      "source": [
        "def D_criterion_NS(D_real, D_fake):\n",
        "    d_loss = F.softplus(-D_real) + F.softplus(D_fake)\n",
        "    return d_loss.mean()\n",
        "\n",
        "def G_criterion_NS(D_fake):\n",
        "    return F.softplus(-D_fake).mean()\n",
        "\n",
        "def D_criterion_LS(D_real, D_fake):\n",
        "    d_loss = 0.5 * (D_real - torch.ones_like(D_real))**2 + 0.5 * (D_fake)**2\n",
        "    return d_loss.mean()\n",
        "\n",
        "def G_criterion_LS(D_fake):\n",
        "    gen_loss = 0.5 * (D_fake - torch.ones_like(D_fake))**2\n",
        "    return gen_loss.mean()\n",
        "\n",
        "def D_criterion_hinge(D_real, D_fake):\n",
        "    return torch.mean(F.relu(1. - D_real)) + torch.mean(F.relu(1. + D_fake))\n",
        "\n",
        "def G_criterion_hinge(D_fake):\n",
        "    return -torch.mean(D_fake)\n",
        "\n",
        "def D_criterion_wasserstein(D_real, D_fake):\n",
        "    return torch.mean(D_fake - D_real)\n",
        "\n",
        "def G_criterion_wasserstein(D_fake):\n",
        "    return -torch.mean(D_fake)\n",
        "\n",
        "def interpolate(real, fake, eps=None):\n",
        "    if eps is None:\n",
        "        eps_size = [1] * len(real.size())\n",
        "        eps_size[0] = real.size(0)\n",
        "        eps = torch.rand(eps_size).to(real)\n",
        "    return eps * real + (1 - eps) * fake\n",
        "    \n",
        "def simple_gradient_penalty(D, x, center=0.):\n",
        "    x.requires_grad_()\n",
        "    D_x = D(x)\n",
        "    D_grad = torch.autograd.grad(D_x, x, torch.ones_like(D_x), create_graph=True)\n",
        "    D_grad_norm = D_grad[0].view(x.size(0), -1).norm(dim=1)\n",
        "    return (D_grad_norm - center).pow(2).mean()\n",
        "\n",
        "def lerp(x1, x2, t=None):\n",
        "    return interpolate(x1, x2, t)\n",
        "\n",
        "def slerp(x1, x2, t=None):\n",
        "    if t is None:\n",
        "        t = torch.rand(x1.size(0)).to(x1)\n",
        "    # assuming normalized x and x2\n",
        "    omega = torch.acos((x1*x2).sum(1))\n",
        "    so = torch.sin(omega)\n",
        "    res = (torch.sin((1.-t)*omega) / so).unsqueeze(1) * x1 \\\n",
        "        + (torch.sin(t*omega) / so).unsqueeze(1) * x2\n",
        "    return res\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0Z4Ke6DYkDg"
      },
      "source": [
        "## Model + Opt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rO_MvGzYldx",
        "outputId": "dd96789d-899f-443c-ced2-87d8c688e173"
      },
      "source": [
        "if args.seed is not None:\n",
        "    random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    cudnn.deterministic = True\n",
        "\n",
        "torch.cuda.set_device(args.gpu)\n",
        "\n",
        "latent_transform = LatentTransform(repr_dim=args.repr_dim,\n",
        "                                   latent_dim=args.latent_noise_dim,\n",
        "                                   hidden_dim=args.latent_hidden_dim,\n",
        "                                   full_transform=args.latent_full_transform,\n",
        "                                   )\n",
        "\n",
        "model = DCGAN(num_latents=latent_transform.output_dim,\n",
        "              image_size=IMAGE_SIZE,\n",
        "              gan_type=args.gan_type,  # doesn't make a difference\n",
        "              D_num_features=args.num_features,\n",
        "              G_num_features=args.num_features,\n",
        "              use_batchnorm=False,  # for D only\n",
        "              output_sigmoid=False,  # for D only\n",
        "              use_spectralnorm=not args.wgan,  # for spectral norm, use the below model\n",
        "              )\n",
        "\n",
        "\n",
        "if not args.wgan:\n",
        "    model = SNDCGAN(num_latents=latent_transform.output_dim,\n",
        "                    image_size=IMAGE_SIZE,\n",
        "                    D_num_features=args.num_features//(IMAGE_SIZE//32),\n",
        "                    G_num_features=args.num_features,\n",
        "                    repr_dim=args.repr_dim)\n",
        "if args.resnetgan:\n",
        "    model = SNResNetGAN(num_latents=latent_transform.output_dim,\n",
        "                        image_size=IMAGE_SIZE,\n",
        "                        D_num_features=args.num_features*2,\n",
        "                        G_num_features=args.num_features*2,\n",
        "                        repr_dim=args.repr_dim)\n",
        "\n",
        "Q_hidden_dim = args.Q_hidden_dim\n",
        "Q = nn.Sequential(nn.Linear(model.D.hidden_dim, Q_hidden_dim, bias=False),\n",
        "                    nn.Linear(Q_hidden_dim, args.repr_dim))\n",
        "\n",
        "model = model.cuda(args.gpu)\n",
        "Q = Q.cuda(args.gpu)\n",
        "latent_transform = latent_transform.cuda(args.gpu)\n",
        "simsiam = simsiam.cuda(args.gpu)\n",
        "\n",
        "print(\"Num of params in D:\", sum(map(torch.numel, model.D.parameters())))\n",
        "print(\"Num of params in G:\", sum(map(torch.numel, model.G.parameters())))\n",
        "print(\"Num of params in Q:\", sum(map(torch.numel, Q.parameters())))\n",
        "print(\"Num of params in L:\", sum(map(torch.numel, latent_transform.parameters())))\n",
        "\n",
        "# Define D and G loss functions\n",
        "D_criterion = D_criterion_hinge\n",
        "G_criterion = G_criterion_hinge\n",
        "\n",
        "# Optimizers\n",
        "G_optimizer = torch.optim.Adam(\n",
        "    [{\"params\": model.G.parameters()},\n",
        "     {\"params\": latent_transform.parameters(), \"lr\": args.latent_transform_lr}],\n",
        "     args.G_lr, betas=args.betas)\n",
        "D_optimizer = torch.optim.Adam(\n",
        "    [{\"params\": model.D.parameters(), \"lr\": args.D_lr},\n",
        "     {\"params\": Q.parameters(), \"lr\": args.Q_lr}],\n",
        "     args.Q_lr, betas=args.betas)\n",
        "\n",
        "D_sched = torch.optim.lr_scheduler.ExponentialLR(D_optimizer, 1. - args.lr_decay)\n",
        "G_sched = torch.optim.lr_scheduler.ExponentialLR(G_optimizer, 1. - args.lr_decay)\n",
        "\n",
        "cudnn.benchmark = True\n",
        "\n",
        "if args.load:\n",
        "    print(\"Loading...\")\n",
        "    model.load_state_dict(torch.load(f\"{GANSIAM_DIR}/results/model.pth.tar\")[\"state_dict\"])\n",
        "    latent_transform.load_state_dict(torch.load(f\"{GANSIAM_DIR}/results/latent_transform.pth.tar\")[\"state_dict\"])\n",
        "    Q.load_state_dict(torch.load(f\"{GANSIAM_DIR}/results/Q.pth.tar\")[\"state_dict\"])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of params in D: 1349377\n",
            "Num of params in G: 8004227\n",
            "Num of params in Q: 1312768\n",
            "Num of params in L: 1049088\n",
            "Loading...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUTqwby4cX0i",
        "outputId": "969a4a9a-921c-4c64-f910-b9621c235c26"
      },
      "source": [
        "print(model)\n",
        "print(Q)\n",
        "print(latent_transform)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SNResNetGAN(\n",
            "  (D): SNResNetDiscriminator(\n",
            "    (model): Sequential(\n",
            "      (0): FirstResBlockDiscriminator(\n",
            "        (conv1): ParametrizedConv2d(\n",
            "          3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (conv2): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (bypass_conv): ParametrizedConv2d(\n",
            "          3, 128, kernel_size=(1, 1), stride=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (model): Sequential(\n",
            "          (0): ParametrizedConv2d(\n",
            "            3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (1): ReLU()\n",
            "          (2): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "        )\n",
            "        (bypass): Sequential(\n",
            "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (1): ParametrizedConv2d(\n",
            "            3, 128, kernel_size=(1, 1), stride=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1): ResBlockDiscriminator(\n",
            "        (conv1): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (conv2): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (model): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (2): ReLU()\n",
            "          (3): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (4): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "        )\n",
            "        (bypass): Sequential(\n",
            "          (0): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(1, 1), stride=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "        )\n",
            "        (bypass_conv): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(1, 1), stride=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): ResBlockDiscriminator(\n",
            "        (conv1): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (conv2): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (model): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (2): ReLU()\n",
            "          (3): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (bypass): Sequential()\n",
            "      )\n",
            "      (3): ResBlockDiscriminator(\n",
            "        (conv1): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (conv2): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (model): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (2): ReLU()\n",
            "          (3): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (bypass): Sequential()\n",
            "      )\n",
            "      (4): ResBlockDiscriminator(\n",
            "        (conv1): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (conv2): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (model): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (2): ReLU()\n",
            "          (3): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (bypass): Sequential()\n",
            "      )\n",
            "      (5): ReLU()\n",
            "      (6): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
            "    )\n",
            "    (fc): ParametrizedLinear(\n",
            "      in_features=512, out_features=1, bias=True\n",
            "      (parametrizations): ModuleDict(\n",
            "        (weight): ParametrizationList(\n",
            "          (0): _SpectralNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (G): SNResNetGeneratorConditional(\n",
            "    (dense): Linear(in_features=1024, out_features=2048, bias=True)\n",
            "    (final): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (block1): ResBlockGeneratorConditional(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): ConditionalBatchNorm2d(\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
            "      )\n",
            "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      (bn2): ConditionalBatchNorm2d(\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
            "      )\n",
            "      (bypass): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    )\n",
            "    (block2): ResBlockGeneratorConditional(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): ConditionalBatchNorm2d(\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
            "      )\n",
            "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      (bn2): ConditionalBatchNorm2d(\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
            "      )\n",
            "      (bypass): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    )\n",
            "    (block3): ResBlockGeneratorConditional(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): ConditionalBatchNorm2d(\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
            "      )\n",
            "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      (bn2): ConditionalBatchNorm2d(\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
            "      )\n",
            "      (bypass): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    )\n",
            "    (block4): ResBlockGeneratorConditional(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): ConditionalBatchNorm2d(\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
            "      )\n",
            "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      (bn2): ConditionalBatchNorm2d(\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
            "      )\n",
            "      (bypass): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    )\n",
            "    (bn): ConditionalBatchNorm2d(\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "      (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Sequential(\n",
            "  (0): Linear(in_features=512, out_features=512, bias=False)\n",
            "  (1): Linear(in_features=512, out_features=2048, bias=True)\n",
            ")\n",
            "LatentTransform(\n",
            "  (transform): Linear(in_features=2048, out_features=512, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeDicP6QZNQ2"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckj9x-2fNtnp"
      },
      "source": [
        "def sample_noise(num_samples):\n",
        "    return torch.randn(num_samples, args.latent_noise_dim)\n",
        "\n",
        "def get_repr(img):\n",
        "    with torch.no_grad():\n",
        "        repr = simsiam.encoder(img)\n",
        "        repr = repr + args.repr_noise * torch.randn_like(repr)\n",
        "    return repr\n",
        "\n",
        "def sample_G(repr):\n",
        "    noise = sample_noise(repr.size(0)).cuda(args.gpu)\n",
        "    z = latent_transform(repr, noise)\n",
        "    fake = model.G(z, repr)\n",
        "    fake = fake + args.im_noise * torch.randn_like(fake)\n",
        "    return fake"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEVERm6alJt6"
      },
      "source": [
        "# Sample a global latent for reuse\n",
        "fixed_x, _ = next(iter(train_loader))\n",
        "fixed_x = fixed_x[:32].cuda(args.gpu)\n",
        "fixed_repr = get_repr(fixed_x)\n",
        "fixed_noise = sample_noise(32).cuda(args.gpu)\n",
        "\n",
        "def check_G_progress(G):\n",
        "    with torch.no_grad():\n",
        "        z = latent_transform(fixed_repr, fixed_noise)\n",
        "        fake_progress = G(z, fixed_repr)\n",
        "    im_grid = torch.cat([fixed_x, fake_progress], dim=0)\n",
        "    grid = vutils.make_grid(im_grid.cpu(), padding=2, normalize=True, range=(-1,1))\n",
        "    return grid"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7gU4I8OZOer"
      },
      "source": [
        "def train(train_loader, model, simsiam,\n",
        "          D_criterion, G_criterion, D_optimizer, G_optimizer, epoch, args):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    data_time = AverageMeter('Data', ':6.3f')\n",
        "    D_on_reals = AverageMeter('D(real)', ':.4f')\n",
        "    D_on_fakes1 = AverageMeter('D(fake)1', ':.4f')\n",
        "    D_on_fakes2 = AverageMeter('D(fake)2', ':.4f')\n",
        "    D_grads = AverageMeter('grad(D)', ':.4f')\n",
        "    G_repr_losses = AverageMeter('G repr loss', ':.4f')\n",
        "    D_repr_losses = AverageMeter('D repr loss', ':.4f')\n",
        "    progress = ProgressMeter(\n",
        "        len(train_loader),\n",
        "        [batch_time, data_time,\n",
        "         D_on_reals, D_on_fakes1, D_on_fakes2, D_grads, G_repr_losses, D_repr_losses],\n",
        "        prefix=\"Epoch: [{}]\".format(epoch))\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "    \n",
        "    # Create dataset sampler\n",
        "    data_iter = iter(enumerate(train_loader))\n",
        "    batch_idx = [0]  # just an ugly hack\n",
        "    def sample_data():\n",
        "        i, (x, y) = next(data_iter)\n",
        "        batch_idx[0] = i\n",
        "        x = x.cuda(args.gpu, non_blocking=True)\n",
        "        real = x + args.im_noise * torch.randn_like(x)\n",
        "        return real\n",
        "    \n",
        "    def sample_repr():\n",
        "        # (1) Sample a random representation from a prior distribution\n",
        "        #repr = 1e-2*torch.rand(args.batch_size, args.repr_dim).cuda(args.gpu)\n",
        "        #repr = torch.randn(args.batch_size, args.repr_dim).cuda(args.gpu)\n",
        "\n",
        "        # (2) Sample a real represenation (best so far)\n",
        "        repr = get_repr(sample_data())\n",
        "\n",
        "        # (3) Sample an interpolated represenation\n",
        "        \"\"\"\n",
        "        real1, real2 = sample_data(), sample_data()\n",
        "        repr1, repr2 = get_repr(real1), get_repr(real2)\n",
        "        repr = lerp(repr1, repr2)\n",
        "        #repr = slerp(repr1, repr2)\n",
        "        \"\"\"\n",
        "        \n",
        "        return repr\n",
        "\n",
        "    end = time.time()\n",
        "    # Train until data_iter is exhausted\n",
        "    try:\n",
        "        i = -1\n",
        "        while True:\n",
        "            i += 1\n",
        "            # measure data loading time\n",
        "            data_time.update(time.time() - end)\n",
        "\n",
        "            ### Train generator\n",
        "            # Sample data and get representation\n",
        "            repr = sample_repr()\n",
        "            # Sample from generator given repr\n",
        "            fake = sample_G(repr)\n",
        "            # Classify fake data\n",
        "            D_fake, h_fake = model.D(fake, return_h=True)\n",
        "            # Calculate adversarial loss\n",
        "            G_loss = G_criterion(D_fake)\n",
        "            # Calculate consistency loss\n",
        "            if args.G_consistency != 0.:\n",
        "                fake_repr = simsiam.encoder(fake)\n",
        "                G_repr_loss = -F.cosine_similarity(fake_repr, repr).mean()\n",
        "                G_repr_losses.update(G_repr_loss.mean().item(), args.batch_size)\n",
        "                G_loss = G_loss + args.G_consistency * G_repr_loss\n",
        "            if args.D_consistency != 0.:\n",
        "                D_repr_loss = -F.cosine_similarity(Q(h_fake), repr).mean()\n",
        "                D_repr_losses.update(D_repr_loss.mean().item(), args.batch_size)\n",
        "                G_loss = G_loss + args.D_consistency * D_repr_loss\n",
        "            # Calculate gradient and minimize\n",
        "            G_optimizer.zero_grad()\n",
        "            G_loss.backward()\n",
        "            G_optimizer.step()\n",
        "            # Update average\n",
        "            D_on_fakes1.update(D_fake.mean().item(), args.batch_size)\n",
        "\n",
        "            ### Train discriminator\n",
        "            for _ in range(args.D_iters):\n",
        "                # Sample data and get representation\n",
        "                real = sample_data()\n",
        "                repr = sample_repr()\n",
        "                # Sample from generator given repr\n",
        "                with torch.no_grad():\n",
        "                    fake = sample_G(repr)\n",
        "                # Classify real and fake data\n",
        "                D_real, h_real = model.D(real, return_h=True)\n",
        "                D_fake, h_fake = model.D(fake, return_h=True)\n",
        "                # Calculate loss\n",
        "                D_loss = D_criterion(D_real, D_fake)\n",
        "                # Gradient penalty\n",
        "                if args.grad_penalty != 0.:\n",
        "                    D_grad_penalty = simple_gradient_penalty(\n",
        "                        model.D, interpolate(real, fake), center=args.grad_center)\n",
        "                    D_loss = D_loss + args.grad_penalty * D_grad_penalty\n",
        "                    D_grads.update(D_grad_penalty.mean().item(), args.batch_size)\n",
        "                # Calculate consistency loss\n",
        "                if args.D_consistency != 0.:\n",
        "                    real_repr = simsiam.encoder(real)\n",
        "                    D_repr_loss_real = -F.cosine_similarity(Q(h_real), real_repr).mean()\n",
        "                    D_repr_loss_fake = -F.cosine_similarity(Q(h_fake), repr).mean()\n",
        "                    D_repr_loss = 0.5 * (D_repr_loss_real + D_repr_loss_fake)\n",
        "                    D_repr_losses.update(D_repr_loss.mean().item(), args.batch_size)\n",
        "                    D_loss = D_loss + args.D_consistency * D_repr_loss\n",
        "                # Calculate gradient and minimize\n",
        "                D_optimizer.zero_grad()\n",
        "                D_loss.backward()\n",
        "                D_optimizer.step()\n",
        "                # Update average\n",
        "                D_on_reals.update(D_real.mean().item(), args.batch_size)\n",
        "                D_on_fakes2.update(D_fake.mean().item(), args.batch_size)\n",
        "\n",
        "            # Check generator's progress by recording its output on a fixed input\n",
        "            if i % args.generate_grid_interval == 0:\n",
        "                grid = check_G_progress(model.G)\n",
        "                GENERATED_GRIDS.append(grid)\n",
        "\n",
        "            if i % args.print_freq == 0:\n",
        "                progress.display(batch_idx[0])\n",
        "\n",
        "            # measure elapsed time\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "    \n",
        "    except StopIteration:\n",
        "        progress.display(batch_idx[0])\n",
        "        return"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v24ES94Re55W"
      },
      "source": [
        "## Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDMPwe-ae6q-"
      },
      "source": [
        "def save():\n",
        "    torch.save({'state_dict': model.state_dict()},\n",
        "                f\"{GANSIAM_DIR}/results/model.pth.tar\")\n",
        "    torch.save({'state_dict': latent_transform.state_dict()},\n",
        "                f\"{GANSIAM_DIR}/results/latent_transform.pth.tar\")\n",
        "    torch.save({'state_dict': Q.state_dict()},\n",
        "                f\"{GANSIAM_DIR}/results/Q.pth.tar\")\n",
        "\n",
        "def save_vid():\n",
        "    vidname = f\"grids_per_{args.generate_grid_interval}_iters.mp4\"\n",
        "    vidname = os.path.join(GANSIAM_DIR, \"results\", \"progress\", vidname)\n",
        "    create_progress_animation(GENERATED_GRIDS, vidname)\n",
        "\n",
        "def run(epochs):\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # train for one epoch\n",
        "        train(train_loader, model, simsiam,\n",
        "            D_criterion, G_criterion, D_optimizer, G_optimizer, epoch, args)\n",
        "        D_sched.step()\n",
        "        G_sched.step()\n",
        "\n",
        "        # Check G's progress evey epoch by generating an image\n",
        "        grid = check_G_progress(model.G)\n",
        "        imname = f'{GANSIAM_DIR}/results/progress/grid_{epoch:04d}.png'\n",
        "        plt.imsave(imname, grid.permute(1,2,0).numpy())\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            save()\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qjya-BRT_cJ"
      },
      "source": [
        "epochs_per_cell = 10"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmNNZfXWe5Rr",
        "outputId": "54d60916-4931-4e89-da5d-a202a4a7032d"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) -0.5365 (0.0614)\tD(fake)1 -0.4880 (-0.4880)\tD(fake)2 -0.8690 (-0.6315)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0911 (-0.0911)\tD repr loss -0.3950 (-0.4146)\n",
            "Epoch: [0][120/781]\tTime  2.496 ( 2.731)\tData  0.000 ( 0.000)\tD(real) -0.6581 (0.1115)\tD(fake)1 -0.3810 (-0.1775)\tD(fake)2 -0.6950 (-0.2501)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3062 (-0.2156)\tD repr loss -0.3476 (-0.3867)\n",
            "Epoch: [0][230/781]\tTime  2.465 ( 2.612)\tData  0.000 ( 0.000)\tD(real) 2.0648 (0.0829)\tD(fake)1 -0.4916 (-0.4189)\tD(fake)2 1.6449 (-0.2826)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2979 (-0.2251)\tD repr loss -0.2932 (-0.3902)\n",
            "Epoch: [0][340/781]\tTime  2.441 ( 2.571)\tData  0.000 ( 0.000)\tD(real) 0.6026 (0.0817)\tD(fake)1 -1.5579 (-0.5056)\tD(fake)2 -0.5061 (-0.2963)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0863 (-0.2347)\tD repr loss -0.4128 (-0.3911)\n",
            "Epoch: [0][450/781]\tTime  2.459 ( 2.550)\tData  0.000 ( 0.000)\tD(real) 0.1051 (0.0967)\tD(fake)1 -0.3866 (-0.4744)\tD(fake)2 -0.3217 (-0.2845)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2473 (-0.2416)\tD repr loss -0.4389 (-0.3964)\n",
            "Epoch: [0][560/781]\tTime  2.474 ( 2.539)\tData  0.000 ( 0.000)\tD(real) 0.3204 (0.1155)\tD(fake)1 -0.9796 (-0.5385)\tD(fake)2 -0.1184 (-0.3008)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2809 (-0.2459)\tD repr loss -0.4430 (-0.3999)\n",
            "Epoch: [0][670/781]\tTime  2.500 ( 2.531)\tData  0.000 ( 0.000)\tD(real) 0.1079 (0.1331)\tD(fake)1 0.5238 (-0.4898)\tD(fake)2 -0.7823 (-0.2936)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1097 (-0.2478)\tD repr loss -0.4206 (-0.4019)\n",
            "Epoch: [0][780/781]\tTime  2.461 ( 2.524)\tData  0.000 ( 0.000)\tD(real) -0.8435 (0.1487)\tD(fake)1 0.2298 (-0.4564)\tD(fake)2 -1.0892 (-0.2829)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3389 (-0.2460)\tD repr loss -0.3291 (-0.4011)\n",
            "Epoch: [0][780/781]\tTime  2.450 ( 2.523)\tData  0.000 ( 0.000)\tD(real) -0.8435 (0.1487)\tD(fake)1 0.2298 (-0.4564)\tD(fake)2 -1.0892 (-0.2829)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3389 (-0.2460)\tD repr loss -0.3291 (-0.4011)\n",
            "Epoch: [1][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.7652 (0.6264)\tD(fake)1 -0.1216 (-0.1216)\tD(fake)2 1.5277 (0.0163)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3080 (-0.3080)\tD repr loss -0.3109 (-0.3699)\n",
            "Epoch: [1][120/781]\tTime  2.462 ( 2.510)\tData  0.000 ( 0.000)\tD(real) 0.2933 (0.2527)\tD(fake)1 -0.7041 (-0.4198)\tD(fake)2 -0.2155 (-0.2843)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2073 (-0.2800)\tD repr loss -0.3598 (-0.4192)\n",
            "Epoch: [1][230/781]\tTime  2.533 ( 2.498)\tData  0.000 ( 0.000)\tD(real) 0.4602 (0.2366)\tD(fake)1 0.5037 (-0.4029)\tD(fake)2 -0.0523 (-0.2824)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3170 (-0.2550)\tD repr loss -0.3980 (-0.4142)\n",
            "Epoch: [1][340/781]\tTime  2.473 ( 2.495)\tData  0.000 ( 0.000)\tD(real) 0.1327 (0.2728)\tD(fake)1 -0.1597 (-0.2635)\tD(fake)2 -0.7538 (-0.2585)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2747 (-0.2522)\tD repr loss -0.3842 (-0.4134)\n",
            "Epoch: [1][450/781]\tTime  2.553 ( 2.495)\tData  0.000 ( 0.000)\tD(real) 0.2022 (0.2548)\tD(fake)1 -0.7998 (-0.3235)\tD(fake)2 -0.1934 (-0.2633)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2153 (-0.2503)\tD repr loss -0.4453 (-0.4138)\n",
            "Epoch: [1][560/781]\tTime  2.511 ( 2.494)\tData  0.000 ( 0.000)\tD(real) -0.1771 (0.2700)\tD(fake)1 -0.5301 (-0.3110)\tD(fake)2 -0.8353 (-0.2625)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3190 (-0.2487)\tD repr loss -0.4377 (-0.4162)\n",
            "Epoch: [1][670/781]\tTime  2.499 ( 2.494)\tData  0.000 ( 0.000)\tD(real) -0.5490 (0.2772)\tD(fake)1 0.0200 (-0.3269)\tD(fake)2 -1.1797 (-0.2669)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2456 (-0.2488)\tD repr loss -0.3838 (-0.4135)\n",
            "Epoch: [1][780/781]\tTime  2.502 ( 2.495)\tData  0.000 ( 0.000)\tD(real) 1.8581 (0.2812)\tD(fake)1 -0.7040 (-0.3237)\tD(fake)2 0.8749 (-0.2752)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2046 (-0.2470)\tD repr loss -0.4279 (-0.4125)\n",
            "Epoch: [1][780/781]\tTime  2.441 ( 2.495)\tData  0.000 ( 0.000)\tD(real) 1.8581 (0.2812)\tD(fake)1 -0.7040 (-0.3237)\tD(fake)2 0.8749 (-0.2752)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2046 (-0.2470)\tD repr loss -0.4279 (-0.4125)\n",
            "Epoch: [2][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) -0.5674 (-0.2228)\tD(fake)1 -0.9982 (-0.9982)\tD(fake)2 -1.0549 (-0.6266)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3065 (-0.3065)\tD repr loss -0.4045 (-0.4282)\n",
            "Epoch: [2][120/781]\tTime  2.513 ( 2.506)\tData  0.000 ( 0.000)\tD(real) 0.8002 (0.2799)\tD(fake)1 -0.6323 (-0.6000)\tD(fake)2 0.2856 (-0.3278)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3373 (-0.3024)\tD repr loss -0.4728 (-0.4314)\n",
            "Epoch: [2][230/781]\tTime  2.478 ( 2.504)\tData  0.000 ( 0.000)\tD(real) -0.2533 (0.2950)\tD(fake)1 -1.2945 (-0.5964)\tD(fake)2 -1.1522 (-0.3253)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3544 (-0.2782)\tD repr loss -0.4196 (-0.4358)\n",
            "Epoch: [2][340/781]\tTime  2.493 ( 2.501)\tData  0.000 ( 0.000)\tD(real) -0.0965 (0.3194)\tD(fake)1 0.8905 (-0.5389)\tD(fake)2 -0.8170 (-0.3034)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2930 (-0.2709)\tD repr loss -0.4121 (-0.4316)\n",
            "Epoch: [2][450/781]\tTime  2.452 ( 2.496)\tData  0.000 ( 0.000)\tD(real) -0.5431 (0.3223)\tD(fake)1 0.6426 (-0.4646)\tD(fake)2 -1.1751 (-0.3120)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2496 (-0.2600)\tD repr loss -0.4105 (-0.4297)\n",
            "Epoch: [2][560/781]\tTime  2.522 ( 2.498)\tData  0.000 ( 0.000)\tD(real) 0.1894 (0.3219)\tD(fake)1 -1.1862 (-0.4667)\tD(fake)2 -0.6762 (-0.3090)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2412 (-0.2605)\tD repr loss -0.3832 (-0.4281)\n",
            "Epoch: [2][670/781]\tTime  2.443 ( 2.496)\tData  0.000 ( 0.000)\tD(real) 2.5013 (0.3324)\tD(fake)1 0.2553 (-0.4422)\tD(fake)2 2.3662 (-0.3016)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1607 (-0.2554)\tD repr loss -0.2786 (-0.4260)\n",
            "Epoch: [2][780/781]\tTime  2.480 ( 2.493)\tData  0.000 ( 0.000)\tD(real) -0.2686 (0.3286)\tD(fake)1 -0.2105 (-0.3898)\tD(fake)2 -1.2200 (-0.3104)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1078 (-0.2543)\tD repr loss -0.4159 (-0.4242)\n",
            "Epoch: [2][780/781]\tTime  2.454 ( 2.492)\tData  0.000 ( 0.000)\tD(real) -0.2686 (0.3286)\tD(fake)1 -0.2105 (-0.3898)\tD(fake)2 -1.2200 (-0.3104)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1078 (-0.2543)\tD repr loss -0.4159 (-0.4242)\n",
            "Epoch: [3][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.1325 (0.6209)\tD(fake)1 0.6768 (0.6768)\tD(fake)2 0.1834 (-0.1994)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0638 (-0.0638)\tD repr loss -0.4366 (-0.3709)\n",
            "Epoch: [3][120/781]\tTime  2.447 ( 2.496)\tData  0.000 ( 0.000)\tD(real) 0.8543 (0.3339)\tD(fake)1 -0.3908 (-0.4017)\tD(fake)2 0.2195 (-0.3349)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3930 (-0.2341)\tD repr loss -0.4035 (-0.4126)\n",
            "Epoch: [3][230/781]\tTime  2.505 ( 2.493)\tData  0.000 ( 0.000)\tD(real) -0.2937 (0.3061)\tD(fake)1 -1.5596 (-0.4302)\tD(fake)2 -0.9693 (-0.3511)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2303 (-0.2477)\tD repr loss -0.4334 (-0.4212)\n",
            "Epoch: [3][340/781]\tTime  2.523 ( 2.496)\tData  0.000 ( 0.000)\tD(real) 1.0984 (0.3355)\tD(fake)1 1.1432 (-0.4134)\tD(fake)2 0.3672 (-0.3352)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2923 (-0.2526)\tD repr loss -0.4644 (-0.4234)\n",
            "Epoch: [3][450/781]\tTime  2.500 ( 2.494)\tData  0.000 ( 0.000)\tD(real) -0.6839 (0.3331)\tD(fake)1 -1.3229 (-0.5186)\tD(fake)2 -1.1649 (-0.3610)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2714 (-0.2524)\tD repr loss -0.3779 (-0.4239)\n",
            "Epoch: [3][560/781]\tTime  2.518 ( 2.498)\tData  0.000 ( 0.000)\tD(real) 0.4533 (0.3412)\tD(fake)1 0.8651 (-0.4930)\tD(fake)2 -0.2180 (-0.3654)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2415 (-0.2561)\tD repr loss -0.4183 (-0.4241)\n",
            "Epoch: [3][670/781]\tTime  2.483 ( 2.498)\tData  0.000 ( 0.000)\tD(real) 0.9346 (0.3472)\tD(fake)1 -1.0176 (-0.4868)\tD(fake)2 -0.1391 (-0.3645)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1824 (-0.2581)\tD repr loss -0.4012 (-0.4246)\n",
            "Epoch: [3][780/781]\tTime  2.524 ( 2.497)\tData  0.000 ( 0.000)\tD(real) -0.6582 (0.3578)\tD(fake)1 -1.2597 (-0.5426)\tD(fake)2 -1.3166 (-0.3586)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2893 (-0.2586)\tD repr loss -0.4097 (-0.4236)\n",
            "Epoch: [3][780/781]\tTime  2.485 ( 2.497)\tData  0.000 ( 0.000)\tD(real) -0.6582 (0.3578)\tD(fake)1 -1.2597 (-0.5426)\tD(fake)2 -1.3166 (-0.3586)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2893 (-0.2586)\tD repr loss -0.4097 (-0.4236)\n",
            "Epoch: [4][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.8837 (0.4510)\tD(fake)1 0.1038 (0.1038)\tD(fake)2 0.0131 (-0.3260)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2972 (-0.2972)\tD repr loss -0.4470 (-0.4719)\n",
            "Epoch: [4][120/781]\tTime  2.513 ( 2.511)\tData  0.000 ( 0.000)\tD(real) -0.1871 (0.4061)\tD(fake)1 -1.2712 (-0.4836)\tD(fake)2 -0.9462 (-0.3573)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3427 (-0.2699)\tD repr loss -0.4413 (-0.4121)\n",
            "Epoch: [4][230/781]\tTime  2.518 ( 2.501)\tData  0.000 ( 0.000)\tD(real) 1.7204 (0.3858)\tD(fake)1 -0.8140 (-0.6215)\tD(fake)2 0.5362 (-0.3940)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2331 (-0.2764)\tD repr loss -0.4261 (-0.4221)\n",
            "Epoch: [4][340/781]\tTime  2.529 ( 2.496)\tData  0.000 ( 0.000)\tD(real) 0.1325 (0.3810)\tD(fake)1 -0.4144 (-0.7124)\tD(fake)2 -0.7298 (-0.4006)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3548 (-0.2806)\tD repr loss -0.4340 (-0.4232)\n",
            "Epoch: [4][450/781]\tTime  2.455 ( 2.494)\tData  0.000 ( 0.000)\tD(real) 0.0329 (0.3875)\tD(fake)1 -1.2305 (-0.6558)\tD(fake)2 -0.6942 (-0.3883)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2293 (-0.2794)\tD repr loss -0.4217 (-0.4296)\n",
            "Epoch: [4][560/781]\tTime  2.502 ( 2.495)\tData  0.000 ( 0.000)\tD(real) 1.3043 (0.3857)\tD(fake)1 -0.1884 (-0.6169)\tD(fake)2 0.4819 (-0.3897)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3024 (-0.2886)\tD repr loss -0.3925 (-0.4338)\n",
            "Epoch: [4][670/781]\tTime  2.488 ( 2.495)\tData  0.000 ( 0.000)\tD(real) 0.0593 (0.3967)\tD(fake)1 -0.0123 (-0.5755)\tD(fake)2 -0.6405 (-0.3907)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2945 (-0.2883)\tD repr loss -0.3703 (-0.4341)\n",
            "Epoch: [4][780/781]\tTime  2.480 ( 2.493)\tData  0.000 ( 0.000)\tD(real) 0.1512 (0.3957)\tD(fake)1 -1.2202 (-0.5725)\tD(fake)2 -0.9750 (-0.3846)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2809 (-0.2809)\tD repr loss -0.3994 (-0.4336)\n",
            "Epoch: [4][780/781]\tTime  2.466 ( 2.492)\tData  0.000 ( 0.000)\tD(real) 0.1512 (0.3957)\tD(fake)1 -1.2202 (-0.5725)\tD(fake)2 -0.9750 (-0.3846)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2809 (-0.2809)\tD repr loss -0.3994 (-0.4336)\n",
            "Epoch: [5][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.8795 (0.6274)\tD(fake)1 1.0722 (1.0722)\tD(fake)2 -0.1910 (-0.1259)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2328 (-0.2328)\tD repr loss -0.3930 (-0.4300)\n",
            "Epoch: [5][120/781]\tTime  2.486 ( 2.519)\tData  0.000 ( 0.000)\tD(real) 0.1424 (0.4310)\tD(fake)1 0.4252 (-0.2726)\tD(fake)2 -0.4471 (-0.3396)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2095 (-0.2486)\tD repr loss -0.3815 (-0.4288)\n",
            "Epoch: [5][230/781]\tTime  2.449 ( 2.495)\tData  0.000 ( 0.000)\tD(real) 0.1591 (0.4321)\tD(fake)1 -0.9638 (-0.3589)\tD(fake)2 -0.6412 (-0.3626)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3185 (-0.2496)\tD repr loss -0.3964 (-0.4304)\n",
            "Epoch: [5][340/781]\tTime  2.482 ( 2.492)\tData  0.000 ( 0.000)\tD(real) 0.8298 (0.4308)\tD(fake)1 0.5163 (-0.2917)\tD(fake)2 -0.1531 (-0.3648)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2179 (-0.2502)\tD repr loss -0.3885 (-0.4225)\n",
            "Epoch: [5][450/781]\tTime  2.521 ( 2.494)\tData  0.000 ( 0.000)\tD(real) -0.6627 (0.4080)\tD(fake)1 -0.7746 (-0.3929)\tD(fake)2 -1.4292 (-0.3938)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1650 (-0.2649)\tD repr loss -0.4179 (-0.4255)\n",
            "Epoch: [5][560/781]\tTime  2.473 ( 2.493)\tData  0.000 ( 0.000)\tD(real) 2.0640 (0.4000)\tD(fake)1 -1.2310 (-0.4517)\tD(fake)2 0.8967 (-0.4040)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2977 (-0.2685)\tD repr loss -0.4762 (-0.4284)\n",
            "Epoch: [5][670/781]\tTime  2.475 ( 2.492)\tData  0.000 ( 0.000)\tD(real) -0.3838 (0.4204)\tD(fake)1 0.1056 (-0.4285)\tD(fake)2 -1.3101 (-0.4059)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2149 (-0.2670)\tD repr loss -0.4376 (-0.4261)\n",
            "Epoch: [5][780/781]\tTime  2.505 ( 2.490)\tData  0.000 ( 0.000)\tD(real) -0.3416 (0.4190)\tD(fake)1 -0.6902 (-0.4033)\tD(fake)2 -1.2068 (-0.4040)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3331 (-0.2694)\tD repr loss -0.3268 (-0.4269)\n",
            "Epoch: [5][780/781]\tTime  2.489 ( 2.490)\tData  0.000 ( 0.000)\tD(real) -0.3416 (0.4190)\tD(fake)1 -0.6902 (-0.4033)\tD(fake)2 -1.2068 (-0.4040)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3331 (-0.2694)\tD repr loss -0.3268 (-0.4269)\n",
            "Epoch: [6][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.8305 (0.4410)\tD(fake)1 -0.0562 (-0.0562)\tD(fake)2 0.1300 (-0.2212)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2309 (-0.2309)\tD repr loss -0.4063 (-0.4237)\n",
            "Epoch: [6][120/781]\tTime  2.456 ( 2.524)\tData  0.000 ( 0.000)\tD(real) 0.2015 (0.4275)\tD(fake)1 -0.5570 (-0.7629)\tD(fake)2 -0.7140 (-0.3962)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2998 (-0.2989)\tD repr loss -0.4451 (-0.4389)\n",
            "Epoch: [6][230/781]\tTime  2.511 ( 2.516)\tData  0.000 ( 0.000)\tD(real) -0.6821 (0.4199)\tD(fake)1 -0.8624 (-0.6520)\tD(fake)2 -1.2497 (-0.3892)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2618 (-0.3393)\tD repr loss -0.4464 (-0.4507)\n",
            "Epoch: [6][340/781]\tTime  2.510 ( 2.513)\tData  0.000 ( 0.000)\tD(real) -0.3528 (0.4204)\tD(fake)1 -0.8918 (-0.5830)\tD(fake)2 -1.1637 (-0.4085)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3155 (-0.3333)\tD repr loss -0.4171 (-0.4492)\n",
            "Epoch: [6][450/781]\tTime  2.513 ( 2.508)\tData  0.000 ( 0.000)\tD(real) -0.6684 (0.4101)\tD(fake)1 -0.9217 (-0.5706)\tD(fake)2 -1.2074 (-0.4087)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2669 (-0.3282)\tD repr loss -0.4211 (-0.4473)\n",
            "Epoch: [6][560/781]\tTime  2.516 ( 2.505)\tData  0.000 ( 0.000)\tD(real) 0.9777 (0.3953)\tD(fake)1 -0.0960 (-0.5377)\tD(fake)2 0.0364 (-0.4018)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2597 (-0.3214)\tD repr loss -0.4094 (-0.4463)\n",
            "Epoch: [6][670/781]\tTime  2.453 ( 2.503)\tData  0.000 ( 0.000)\tD(real) 0.4683 (0.3924)\tD(fake)1 -0.2596 (-0.5713)\tD(fake)2 -0.2669 (-0.4039)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2731 (-0.3136)\tD repr loss -0.4297 (-0.4451)\n",
            "Epoch: [6][780/781]\tTime  2.498 ( 2.503)\tData  0.000 ( 0.000)\tD(real) 0.7893 (0.4013)\tD(fake)1 -0.3618 (-0.5565)\tD(fake)2 0.0815 (-0.3994)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2784 (-0.3088)\tD repr loss -0.4532 (-0.4441)\n",
            "Epoch: [6][780/781]\tTime  2.476 ( 2.503)\tData  0.000 ( 0.000)\tD(real) 0.7893 (0.4013)\tD(fake)1 -0.3618 (-0.5565)\tD(fake)2 0.0815 (-0.3994)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2784 (-0.3088)\tD repr loss -0.4532 (-0.4441)\n",
            "Epoch: [7][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) -0.7666 (0.2444)\tD(fake)1 -0.9921 (-0.9921)\tD(fake)2 -1.4566 (-0.6211)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2562 (-0.2562)\tD repr loss -0.3771 (-0.4618)\n",
            "Epoch: [7][120/781]\tTime  2.494 ( 2.508)\tData  0.000 ( 0.000)\tD(real) 0.6875 (0.4136)\tD(fake)1 0.2099 (-0.5538)\tD(fake)2 -0.5530 (-0.4580)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2344 (-0.2393)\tD repr loss -0.4181 (-0.4389)\n",
            "Epoch: [7][230/781]\tTime  2.473 ( 2.499)\tData  0.000 ( 0.000)\tD(real) 0.6887 (0.4176)\tD(fake)1 -1.1768 (-0.5326)\tD(fake)2 -0.0989 (-0.4030)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2211 (-0.2551)\tD repr loss -0.3524 (-0.4393)\n",
            "Epoch: [7][340/781]\tTime  2.498 ( 2.500)\tData  0.000 ( 0.000)\tD(real) -0.4142 (0.4211)\tD(fake)1 -1.0156 (-0.4219)\tD(fake)2 -1.1511 (-0.4011)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2016 (-0.2551)\tD repr loss -0.4574 (-0.4388)\n",
            "Epoch: [7][450/781]\tTime  2.506 ( 2.499)\tData  0.000 ( 0.000)\tD(real) -0.1342 (0.4112)\tD(fake)1 -1.2829 (-0.5036)\tD(fake)2 -0.8427 (-0.4087)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3289 (-0.2682)\tD repr loss -0.4229 (-0.4409)\n",
            "Epoch: [7][560/781]\tTime  2.469 ( 2.501)\tData  0.000 ( 0.000)\tD(real) 1.2754 (0.4136)\tD(fake)1 -0.8494 (-0.4761)\tD(fake)2 0.8696 (-0.4018)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3674 (-0.2723)\tD repr loss -0.3633 (-0.4415)\n",
            "Epoch: [7][670/781]\tTime  2.519 ( 2.503)\tData  0.000 ( 0.000)\tD(real) 1.1931 (0.4084)\tD(fake)1 0.2568 (-0.4161)\tD(fake)2 0.1514 (-0.3997)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2928 (-0.2747)\tD repr loss -0.4381 (-0.4426)\n",
            "Epoch: [7][780/781]\tTime  2.507 ( 2.504)\tData  0.000 ( 0.000)\tD(real) -0.3582 (0.3990)\tD(fake)1 1.2894 (-0.4169)\tD(fake)2 -1.1804 (-0.4081)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2392 (-0.2744)\tD repr loss -0.3978 (-0.4438)\n",
            "Epoch: [7][780/781]\tTime  2.487 ( 2.504)\tData  0.000 ( 0.000)\tD(real) -0.3582 (0.3990)\tD(fake)1 1.2894 (-0.4169)\tD(fake)2 -1.1804 (-0.4081)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2392 (-0.2744)\tD repr loss -0.3978 (-0.4438)\n",
            "Epoch: [8][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.3144 (0.5249)\tD(fake)1 -0.1684 (-0.1684)\tD(fake)2 0.2300 (-0.3322)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2939 (-0.2939)\tD repr loss -0.4393 (-0.4826)\n",
            "Epoch: [8][120/781]\tTime  2.498 ( 2.542)\tData  0.000 ( 0.000)\tD(real) 1.2229 (0.4590)\tD(fake)1 1.0677 (-0.5704)\tD(fake)2 0.1906 (-0.4231)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2853 (-0.2940)\tD repr loss -0.4137 (-0.4513)\n",
            "Epoch: [8][230/781]\tTime  2.515 ( 2.517)\tData  0.000 ( 0.000)\tD(real) 0.2235 (0.3975)\tD(fake)1 -0.3684 (-0.6385)\tD(fake)2 -0.6947 (-0.4645)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2395 (-0.2959)\tD repr loss -0.2736 (-0.4483)\n",
            "Epoch: [8][340/781]\tTime  2.538 ( 2.516)\tData  0.000 ( 0.000)\tD(real) 0.4497 (0.4242)\tD(fake)1 -0.9430 (-0.4434)\tD(fake)2 -0.6885 (-0.4595)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2450 (-0.2944)\tD repr loss -0.3955 (-0.4460)\n",
            "Epoch: [8][450/781]\tTime  2.510 ( 2.514)\tData  0.000 ( 0.000)\tD(real) 0.8035 (0.4286)\tD(fake)1 -0.1435 (-0.4414)\tD(fake)2 -0.2173 (-0.4346)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2557 (-0.2798)\tD repr loss -0.4445 (-0.4439)\n",
            "Epoch: [8][560/781]\tTime  2.508 ( 2.515)\tData  0.000 ( 0.000)\tD(real) 0.0729 (0.4273)\tD(fake)1 0.3366 (-0.3845)\tD(fake)2 -1.0256 (-0.4244)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3119 (-0.2840)\tD repr loss -0.4307 (-0.4440)\n",
            "Epoch: [8][670/781]\tTime  2.506 ( 2.516)\tData  0.000 ( 0.000)\tD(real) -0.0416 (0.4222)\tD(fake)1 -1.2164 (-0.4007)\tD(fake)2 -0.8713 (-0.4121)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3244 (-0.2832)\tD repr loss -0.4260 (-0.4444)\n",
            "Epoch: [8][780/781]\tTime  2.480 ( 2.516)\tData  0.000 ( 0.000)\tD(real) 0.3246 (0.4190)\tD(fake)1 -0.8661 (-0.4089)\tD(fake)2 -0.6628 (-0.4151)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3521 (-0.2851)\tD repr loss -0.4388 (-0.4440)\n",
            "Epoch: [8][780/781]\tTime  2.500 ( 2.516)\tData  0.000 ( 0.000)\tD(real) 0.3246 (0.4190)\tD(fake)1 -0.8661 (-0.4089)\tD(fake)2 -0.6628 (-0.4151)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3521 (-0.2851)\tD repr loss -0.4388 (-0.4440)\n",
            "Epoch: [9][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.7032 (0.3675)\tD(fake)1 -0.3215 (-0.3215)\tD(fake)2 -0.1720 (-0.4119)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2767 (-0.2767)\tD repr loss -0.4498 (-0.4370)\n",
            "Epoch: [9][120/781]\tTime  2.501 ( 2.540)\tData  0.000 ( 0.000)\tD(real) -0.3734 (0.4438)\tD(fake)1 -1.1397 (-0.5090)\tD(fake)2 -1.2055 (-0.4126)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3543 (-0.2401)\tD repr loss -0.4249 (-0.4247)\n",
            "Epoch: [9][230/781]\tTime  2.518 ( 2.521)\tData  0.000 ( 0.000)\tD(real) 2.4349 (0.4462)\tD(fake)1 -0.4613 (-0.4807)\tD(fake)2 -0.8985 (-0.4519)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2563 (-0.2875)\tD repr loss -0.4149 (-0.4380)\n",
            "Epoch: [9][340/781]\tTime  2.480 ( 2.516)\tData  0.000 ( 0.000)\tD(real) -0.0871 (0.4316)\tD(fake)1 -0.6987 (-0.4847)\tD(fake)2 -0.9768 (-0.4275)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3209 (-0.2986)\tD repr loss -0.4063 (-0.4362)\n",
            "Epoch: [9][450/781]\tTime  2.553 ( 2.516)\tData  0.000 ( 0.000)\tD(real) 0.9919 (0.4179)\tD(fake)1 -0.4268 (-0.5241)\tD(fake)2 0.1499 (-0.4272)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2764 (-0.2969)\tD repr loss -0.4327 (-0.4395)\n",
            "Epoch: [9][560/781]\tTime  2.543 ( 2.517)\tData  0.000 ( 0.000)\tD(real) 0.3699 (0.4288)\tD(fake)1 -0.4972 (-0.5201)\tD(fake)2 -0.8008 (-0.4213)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3903 (-0.3014)\tD repr loss -0.3768 (-0.4411)\n",
            "Epoch: [9][670/781]\tTime  2.517 ( 2.516)\tData  0.000 ( 0.000)\tD(real) 0.0887 (0.4232)\tD(fake)1 -1.2316 (-0.4939)\tD(fake)2 -1.0346 (-0.4241)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3281 (-0.3019)\tD repr loss -0.4280 (-0.4431)\n",
            "Epoch: [9][780/781]\tTime  2.484 ( 2.513)\tData  0.000 ( 0.000)\tD(real) 0.8435 (0.4247)\tD(fake)1 0.2748 (-0.4504)\tD(fake)2 -0.3518 (-0.4246)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3204 (-0.3058)\tD repr loss -0.4667 (-0.4446)\n",
            "Epoch: [9][780/781]\tTime  2.478 ( 2.513)\tData  0.000 ( 0.000)\tD(real) 0.8435 (0.4247)\tD(fake)1 0.2748 (-0.4504)\tD(fake)2 -0.3518 (-0.4246)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3204 (-0.3058)\tD repr loss -0.4667 (-0.4446)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-p4wAlbftUb",
        "outputId": "41c369d8-fe1e-413e-c1b1-72cf0bca29ab"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.1875 (0.4724)\tD(fake)1 -0.4469 (-0.4469)\tD(fake)2 0.2495 (-0.4026)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4334 (-0.4334)\tD repr loss -0.4448 (-0.4809)\n",
            "Epoch: [0][120/781]\tTime  2.507 ( 2.528)\tData  0.000 ( 0.000)\tD(real) 0.8538 (0.4678)\tD(fake)1 -0.5082 (-0.3796)\tD(fake)2 -0.3611 (-0.4832)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3128 (-0.3186)\tD repr loss -0.4066 (-0.4495)\n",
            "Epoch: [0][230/781]\tTime  2.490 ( 2.515)\tData  0.000 ( 0.000)\tD(real) 1.7175 (0.4704)\tD(fake)1 -1.2268 (-0.6345)\tD(fake)2 0.5976 (-0.4801)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2698 (-0.3094)\tD repr loss -0.3656 (-0.4482)\n",
            "Epoch: [0][340/781]\tTime  2.472 ( 2.516)\tData  0.000 ( 0.000)\tD(real) -0.5439 (0.4688)\tD(fake)1 -0.2804 (-0.6375)\tD(fake)2 -1.4148 (-0.4830)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2573 (-0.2957)\tD repr loss -0.4708 (-0.4465)\n",
            "Epoch: [0][450/781]\tTime  2.532 ( 2.518)\tData  0.000 ( 0.000)\tD(real) 0.7560 (0.4532)\tD(fake)1 0.8663 (-0.6399)\tD(fake)2 -0.3861 (-0.4932)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3832 (-0.2982)\tD repr loss -0.4439 (-0.4463)\n",
            "Epoch: [0][560/781]\tTime  2.532 ( 2.518)\tData  0.000 ( 0.000)\tD(real) 1.5976 (0.4657)\tD(fake)1 -1.1255 (-0.5890)\tD(fake)2 0.2958 (-0.4798)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2727 (-0.2971)\tD repr loss -0.4369 (-0.4493)\n",
            "Epoch: [0][670/781]\tTime  2.522 ( 2.517)\tData  0.000 ( 0.000)\tD(real) 0.4028 (0.4625)\tD(fake)1 -0.8038 (-0.6358)\tD(fake)2 -0.4913 (-0.4782)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2979 (-0.3032)\tD repr loss -0.4269 (-0.4498)\n",
            "Epoch: [0][780/781]\tTime  2.524 ( 2.516)\tData  0.000 ( 0.000)\tD(real) 0.7400 (0.4634)\tD(fake)1 -0.8827 (-0.6578)\tD(fake)2 -0.8284 (-0.4825)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1623 (-0.3014)\tD repr loss -0.4331 (-0.4494)\n",
            "Epoch: [0][780/781]\tTime  2.519 ( 2.516)\tData  0.000 ( 0.000)\tD(real) 0.7400 (0.4634)\tD(fake)1 -0.8827 (-0.6578)\tD(fake)2 -0.8284 (-0.4825)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1623 (-0.3014)\tD repr loss -0.4331 (-0.4494)\n",
            "Epoch: [1][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.5727 (0.4149)\tD(fake)1 0.2220 (0.2220)\tD(fake)2 -0.3787 (-0.2350)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4090 (-0.4090)\tD repr loss -0.4798 (-0.4525)\n",
            "Epoch: [1][120/781]\tTime  2.476 ( 2.511)\tData  0.000 ( 0.000)\tD(real) 0.6790 (0.4622)\tD(fake)1 -0.6666 (-0.4403)\tD(fake)2 -0.4700 (-0.4144)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3112 (-0.3638)\tD repr loss -0.4602 (-0.4529)\n",
            "Epoch: [1][230/781]\tTime  2.521 ( 2.512)\tData  0.000 ( 0.000)\tD(real) 0.3568 (0.4344)\tD(fake)1 -0.9939 (-0.4986)\tD(fake)2 -0.7171 (-0.4693)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3140 (-0.3577)\tD repr loss -0.4593 (-0.4519)\n",
            "Epoch: [1][340/781]\tTime  2.471 ( 2.507)\tData  0.000 ( 0.000)\tD(real) -0.0157 (0.4372)\tD(fake)1 -0.4529 (-0.5216)\tD(fake)2 -1.0873 (-0.4613)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1149 (-0.3393)\tD repr loss -0.4203 (-0.4469)\n",
            "Epoch: [1][450/781]\tTime  2.509 ( 2.508)\tData  0.000 ( 0.000)\tD(real) -0.6344 (0.4465)\tD(fake)1 -0.6169 (-0.5289)\tD(fake)2 -1.2419 (-0.4646)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1653 (-0.3361)\tD repr loss -0.4511 (-0.4468)\n",
            "Epoch: [1][560/781]\tTime  2.509 ( 2.506)\tData  0.000 ( 0.000)\tD(real) -0.5711 (0.4456)\tD(fake)1 -1.1184 (-0.5607)\tD(fake)2 -1.1630 (-0.4771)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2808 (-0.3324)\tD repr loss -0.4519 (-0.4484)\n",
            "Epoch: [1][670/781]\tTime  2.497 ( 2.505)\tData  0.000 ( 0.000)\tD(real) 0.0984 (0.4569)\tD(fake)1 -0.3758 (-0.5827)\tD(fake)2 -0.5359 (-0.4765)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3466 (-0.3330)\tD repr loss -0.4476 (-0.4512)\n",
            "Epoch: [1][780/781]\tTime  2.505 ( 2.504)\tData  0.000 ( 0.000)\tD(real) 0.7012 (0.4582)\tD(fake)1 -1.1879 (-0.5905)\tD(fake)2 -0.2763 (-0.4733)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2638 (-0.3297)\tD repr loss -0.3721 (-0.4533)\n",
            "Epoch: [1][780/781]\tTime  2.492 ( 2.504)\tData  0.000 ( 0.000)\tD(real) 0.7012 (0.4582)\tD(fake)1 -1.1879 (-0.5905)\tD(fake)2 -0.2763 (-0.4733)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2638 (-0.3297)\tD repr loss -0.3721 (-0.4533)\n",
            "Epoch: [2][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.0884 (0.5157)\tD(fake)1 -0.4570 (-0.4570)\tD(fake)2 -1.1718 (-0.7267)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3067 (-0.3067)\tD repr loss -0.4858 (-0.4808)\n",
            "Epoch: [2][120/781]\tTime  2.533 ( 2.526)\tData  0.000 ( 0.000)\tD(real) 0.8046 (0.5057)\tD(fake)1 -1.0966 (-0.4865)\tD(fake)2 -0.2152 (-0.4784)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3907 (-0.3393)\tD repr loss -0.5364 (-0.4522)\n",
            "Epoch: [2][230/781]\tTime  2.500 ( 2.513)\tData  0.000 ( 0.000)\tD(real) -0.3533 (0.4700)\tD(fake)1 -1.4678 (-0.4878)\tD(fake)2 -0.9757 (-0.4704)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3782 (-0.3201)\tD repr loss -0.4681 (-0.4506)\n",
            "Epoch: [2][340/781]\tTime  2.509 ( 2.510)\tData  0.000 ( 0.000)\tD(real) 0.9789 (0.4702)\tD(fake)1 0.0103 (-0.5795)\tD(fake)2 0.0902 (-0.4834)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3201 (-0.3200)\tD repr loss -0.4353 (-0.4519)\n",
            "Epoch: [2][450/781]\tTime  2.527 ( 2.511)\tData  0.000 ( 0.000)\tD(real) 0.2658 (0.4689)\tD(fake)1 -0.5829 (-0.6101)\tD(fake)2 -0.6036 (-0.4788)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4081 (-0.3163)\tD repr loss -0.4503 (-0.4537)\n",
            "Epoch: [2][560/781]\tTime  2.514 ( 2.515)\tData  0.000 ( 0.000)\tD(real) 1.0953 (0.4745)\tD(fake)1 -0.3790 (-0.6529)\tD(fake)2 -0.1597 (-0.4819)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3912 (-0.3129)\tD repr loss -0.4389 (-0.4547)\n",
            "Epoch: [2][670/781]\tTime  2.524 ( 2.512)\tData  0.000 ( 0.000)\tD(real) -0.5847 (0.4690)\tD(fake)1 -1.1505 (-0.6747)\tD(fake)2 -1.1517 (-0.4882)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2359 (-0.3070)\tD repr loss -0.4271 (-0.4532)\n",
            "Epoch: [2][780/781]\tTime  2.499 ( 2.510)\tData  0.000 ( 0.000)\tD(real) -0.5185 (0.4730)\tD(fake)1 -0.8208 (-0.7041)\tD(fake)2 -1.4349 (-0.4888)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2949 (-0.3076)\tD repr loss -0.4494 (-0.4548)\n",
            "Epoch: [2][780/781]\tTime  2.500 ( 2.510)\tData  0.000 ( 0.000)\tD(real) -0.5185 (0.4730)\tD(fake)1 -0.8208 (-0.7041)\tD(fake)2 -1.4349 (-0.4888)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2949 (-0.3076)\tD repr loss -0.4494 (-0.4548)\n",
            "Epoch: [3][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) -0.2959 (0.5431)\tD(fake)1 -1.0465 (-1.0465)\tD(fake)2 -1.2311 (-0.6346)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2472 (-0.2472)\tD repr loss -0.4957 (-0.4367)\n",
            "Epoch: [3][120/781]\tTime  2.485 ( 2.512)\tData  0.000 ( 0.000)\tD(real) 1.1156 (0.5848)\tD(fake)1 -1.2902 (-0.2975)\tD(fake)2 0.1290 (-0.4618)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2367 (-0.3195)\tD repr loss -0.4710 (-0.4502)\n",
            "Epoch: [3][230/781]\tTime  2.492 ( 2.505)\tData  0.000 ( 0.000)\tD(real) -0.4925 (0.5304)\tD(fake)1 -0.4288 (-0.4494)\tD(fake)2 -1.3720 (-0.4836)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3702 (-0.3419)\tD repr loss -0.4101 (-0.4544)\n",
            "Epoch: [3][340/781]\tTime  2.525 ( 2.507)\tData  0.000 ( 0.000)\tD(real) 1.0354 (0.5076)\tD(fake)1 -0.4471 (-0.4587)\tD(fake)2 0.4817 (-0.4968)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3188 (-0.3461)\tD repr loss -0.4057 (-0.4572)\n",
            "Epoch: [3][450/781]\tTime  2.459 ( 2.505)\tData  0.000 ( 0.000)\tD(real) 0.7726 (0.4974)\tD(fake)1 1.7433 (-0.4342)\tD(fake)2 -1.0086 (-0.4725)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2930 (-0.3375)\tD repr loss -0.3561 (-0.4571)\n",
            "Epoch: [3][560/781]\tTime  2.454 ( 2.501)\tData  0.000 ( 0.000)\tD(real) 1.0724 (0.4943)\tD(fake)1 -0.3402 (-0.4044)\tD(fake)2 -0.5872 (-0.4680)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3177 (-0.3302)\tD repr loss -0.3025 (-0.4573)\n",
            "Epoch: [3][670/781]\tTime  2.465 ( 2.503)\tData  0.000 ( 0.000)\tD(real) 0.5203 (0.4960)\tD(fake)1 -0.3276 (-0.3898)\tD(fake)2 -0.4782 (-0.4684)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2445 (-0.3219)\tD repr loss -0.4217 (-0.4572)\n",
            "Epoch: [3][780/781]\tTime  2.510 ( 2.504)\tData  0.000 ( 0.000)\tD(real) 1.1023 (0.4961)\tD(fake)1 -0.2471 (-0.4125)\tD(fake)2 0.1832 (-0.4688)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2715 (-0.3160)\tD repr loss -0.4908 (-0.4579)\n",
            "Epoch: [3][780/781]\tTime  2.489 ( 2.503)\tData  0.000 ( 0.000)\tD(real) 1.1023 (0.4961)\tD(fake)1 -0.2471 (-0.4125)\tD(fake)2 0.1832 (-0.4688)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2715 (-0.3160)\tD repr loss -0.4908 (-0.4579)\n",
            "Epoch: [4][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.4818 (0.3452)\tD(fake)1 -1.3047 (-1.3047)\tD(fake)2 -0.2758 (-0.4960)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3157 (-0.3157)\tD repr loss -0.3836 (-0.4241)\n",
            "Epoch: [4][120/781]\tTime  2.508 ( 2.499)\tData  0.000 ( 0.000)\tD(real) 0.6204 (0.4294)\tD(fake)1 -0.3795 (-0.5531)\tD(fake)2 -0.2353 (-0.5002)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3675 (-0.3099)\tD repr loss -0.4220 (-0.4573)\n",
            "Epoch: [4][230/781]\tTime  2.461 ( 2.501)\tData  0.000 ( 0.000)\tD(real) 1.1983 (0.4337)\tD(fake)1 -0.3516 (-0.5525)\tD(fake)2 -0.0069 (-0.5034)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3326 (-0.3196)\tD repr loss -0.4622 (-0.4598)\n",
            "Epoch: [4][340/781]\tTime  2.522 ( 2.504)\tData  0.000 ( 0.000)\tD(real) 0.8578 (0.4649)\tD(fake)1 0.4254 (-0.6234)\tD(fake)2 -0.4225 (-0.4858)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3329 (-0.3032)\tD repr loss -0.4299 (-0.4547)\n",
            "Epoch: [4][450/781]\tTime  2.504 ( 2.501)\tData  0.000 ( 0.000)\tD(real) 0.6284 (0.4827)\tD(fake)1 -0.1342 (-0.6283)\tD(fake)2 -0.5111 (-0.4922)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2743 (-0.3021)\tD repr loss -0.4799 (-0.4565)\n",
            "Epoch: [4][560/781]\tTime  2.511 ( 2.501)\tData  0.000 ( 0.000)\tD(real) -0.0417 (0.4805)\tD(fake)1 -1.2234 (-0.6178)\tD(fake)2 -1.0197 (-0.4959)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3482 (-0.2988)\tD repr loss -0.4609 (-0.4568)\n",
            "Epoch: [4][670/781]\tTime  2.520 ( 2.502)\tData  0.000 ( 0.000)\tD(real) 0.0747 (0.4854)\tD(fake)1 -1.2364 (-0.6079)\tD(fake)2 -0.9320 (-0.4989)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3824 (-0.3058)\tD repr loss -0.4780 (-0.4590)\n",
            "Epoch: [4][780/781]\tTime  2.459 ( 2.503)\tData  0.000 ( 0.000)\tD(real) 0.0904 (0.4943)\tD(fake)1 -0.9433 (-0.5956)\tD(fake)2 -0.8918 (-0.4916)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2547 (-0.3113)\tD repr loss -0.4318 (-0.4582)\n",
            "Epoch: [4][780/781]\tTime  2.504 ( 2.503)\tData  0.000 ( 0.000)\tD(real) 0.0904 (0.4943)\tD(fake)1 -0.9433 (-0.5956)\tD(fake)2 -0.8918 (-0.4916)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2547 (-0.3113)\tD repr loss -0.4318 (-0.4582)\n",
            "Epoch: [5][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.1003 (0.5324)\tD(fake)1 -0.0243 (-0.0243)\tD(fake)2 0.0468 (-0.3861)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2961 (-0.2961)\tD repr loss -0.4633 (-0.4574)\n",
            "Epoch: [5][120/781]\tTime  2.485 ( 2.520)\tData  0.000 ( 0.000)\tD(real) 0.0361 (0.4450)\tD(fake)1 -0.9548 (-0.6166)\tD(fake)2 -0.8478 (-0.5348)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2946 (-0.2996)\tD repr loss -0.4128 (-0.4581)\n",
            "Epoch: [5][230/781]\tTime  2.447 ( 2.506)\tData  0.000 ( 0.000)\tD(real) 0.3780 (0.4436)\tD(fake)1 -0.4808 (-0.5301)\tD(fake)2 -0.6521 (-0.5176)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3218 (-0.2924)\tD repr loss -0.4545 (-0.4558)\n",
            "Epoch: [5][340/781]\tTime  2.512 ( 2.500)\tData  0.000 ( 0.000)\tD(real) 1.4894 (0.4593)\tD(fake)1 -0.8936 (-0.6241)\tD(fake)2 0.4326 (-0.4974)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1473 (-0.2949)\tD repr loss -0.4299 (-0.4529)\n",
            "Epoch: [5][450/781]\tTime  2.456 ( 2.499)\tData  0.000 ( 0.000)\tD(real) -0.4889 (0.4514)\tD(fake)1 -0.6769 (-0.5473)\tD(fake)2 -1.3802 (-0.4952)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2157 (-0.2957)\tD repr loss -0.4547 (-0.4524)\n",
            "Epoch: [5][560/781]\tTime  2.492 ( 2.497)\tData  0.000 ( 0.000)\tD(real) -0.2471 (0.4628)\tD(fake)1 -1.0644 (-0.4768)\tD(fake)2 -1.0504 (-0.4875)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3055 (-0.3038)\tD repr loss -0.4424 (-0.4528)\n",
            "Epoch: [5][670/781]\tTime  2.504 ( 2.496)\tData  0.000 ( 0.000)\tD(real) 0.8051 (0.4716)\tD(fake)1 -0.0703 (-0.4903)\tD(fake)2 -0.1436 (-0.4895)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2997 (-0.3057)\tD repr loss -0.2989 (-0.4560)\n",
            "Epoch: [5][780/781]\tTime  2.444 ( 2.494)\tData  0.000 ( 0.000)\tD(real) 2.2701 (0.4792)\tD(fake)1 -0.8227 (-0.5180)\tD(fake)2 -1.1168 (-0.4912)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3025 (-0.3117)\tD repr loss -0.1847 (-0.4559)\n",
            "Epoch: [5][780/781]\tTime  2.483 ( 2.494)\tData  0.000 ( 0.000)\tD(real) 2.2701 (0.4792)\tD(fake)1 -0.8227 (-0.5180)\tD(fake)2 -1.1168 (-0.4912)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3025 (-0.3117)\tD repr loss -0.1847 (-0.4559)\n",
            "Epoch: [6][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.0077 (0.7661)\tD(fake)1 1.9005 (1.9005)\tD(fake)2 -0.2346 (-0.0520)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3813 (-0.3813)\tD repr loss -0.4321 (-0.4583)\n",
            "Epoch: [6][120/781]\tTime  2.460 ( 2.496)\tData  0.000 ( 0.000)\tD(real) 1.0368 (0.5501)\tD(fake)1 -0.3822 (-0.5196)\tD(fake)2 -0.2494 (-0.4653)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3346 (-0.3341)\tD repr loss -0.4263 (-0.4463)\n",
            "Epoch: [6][230/781]\tTime  2.452 ( 2.492)\tData  0.000 ( 0.000)\tD(real) -0.5004 (0.5047)\tD(fake)1 0.2967 (-0.5560)\tD(fake)2 -1.2642 (-0.4981)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3400 (-0.3201)\tD repr loss -0.4277 (-0.4540)\n",
            "Epoch: [6][340/781]\tTime  2.476 ( 2.487)\tData  0.000 ( 0.000)\tD(real) -0.0908 (0.4994)\tD(fake)1 1.0143 (-0.5713)\tD(fake)2 -1.1203 (-0.5092)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3396 (-0.3178)\tD repr loss -0.4633 (-0.4555)\n",
            "Epoch: [6][450/781]\tTime  2.480 ( 2.483)\tData  0.000 ( 0.000)\tD(real) 1.0084 (0.5215)\tD(fake)1 1.6740 (-0.4703)\tD(fake)2 -0.0952 (-0.5023)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3685 (-0.3143)\tD repr loss -0.4636 (-0.4505)\n",
            "Epoch: [6][560/781]\tTime  2.470 ( 2.483)\tData  0.000 ( 0.000)\tD(real) 0.9815 (0.5096)\tD(fake)1 -0.0752 (-0.5152)\tD(fake)2 -0.2037 (-0.5011)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2396 (-0.3140)\tD repr loss -0.4981 (-0.4527)\n",
            "Epoch: [6][670/781]\tTime  2.493 ( 2.483)\tData  0.000 ( 0.000)\tD(real) 1.3111 (0.5194)\tD(fake)1 -1.0108 (-0.5067)\tD(fake)2 0.2751 (-0.5027)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4043 (-0.3182)\tD repr loss -0.3897 (-0.4519)\n",
            "Epoch: [6][780/781]\tTime  2.502 ( 2.484)\tData  0.000 ( 0.000)\tD(real) 0.9745 (0.5128)\tD(fake)1 -0.4400 (-0.5239)\tD(fake)2 -0.4289 (-0.5040)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3471 (-0.3208)\tD repr loss -0.3941 (-0.4540)\n",
            "Epoch: [6][780/781]\tTime  2.469 ( 2.483)\tData  0.000 ( 0.000)\tD(real) 0.9745 (0.5128)\tD(fake)1 -0.4400 (-0.5239)\tD(fake)2 -0.4289 (-0.5040)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3471 (-0.3208)\tD repr loss -0.3941 (-0.4540)\n",
            "Epoch: [7][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.1437 (0.2531)\tD(fake)1 -0.1137 (-0.1137)\tD(fake)2 -0.8579 (-0.5341)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3869 (-0.3869)\tD repr loss -0.4821 (-0.4792)\n",
            "Epoch: [7][120/781]\tTime  2.455 ( 2.509)\tData  0.000 ( 0.000)\tD(real) 1.2669 (0.5141)\tD(fake)1 -1.0493 (-0.4043)\tD(fake)2 0.2117 (-0.4984)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2849 (-0.3263)\tD repr loss -0.4246 (-0.4488)\n",
            "Epoch: [7][230/781]\tTime  2.486 ( 2.495)\tData  0.000 ( 0.000)\tD(real) 0.8074 (0.5068)\tD(fake)1 0.7990 (-0.3843)\tD(fake)2 -0.3206 (-0.4947)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3904 (-0.3267)\tD repr loss -0.4294 (-0.4563)\n",
            "Epoch: [7][340/781]\tTime  2.448 ( 2.486)\tData  0.000 ( 0.000)\tD(real) -0.5851 (0.5014)\tD(fake)1 -0.8490 (-0.4382)\tD(fake)2 -1.3676 (-0.4963)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3486 (-0.3249)\tD repr loss -0.4479 (-0.4582)\n",
            "Epoch: [7][450/781]\tTime  2.515 ( 2.484)\tData  0.000 ( 0.000)\tD(real) 2.1130 (0.5159)\tD(fake)1 -0.4646 (-0.4475)\tD(fake)2 1.2101 (-0.4758)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2736 (-0.3149)\tD repr loss -0.4054 (-0.4556)\n",
            "Epoch: [7][560/781]\tTime  2.490 ( 2.484)\tData  0.000 ( 0.000)\tD(real) 1.4073 (0.5104)\tD(fake)1 -0.2531 (-0.4936)\tD(fake)2 -0.0326 (-0.4840)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3472 (-0.3171)\tD repr loss -0.4242 (-0.4571)\n",
            "Epoch: [7][670/781]\tTime  2.473 ( 2.485)\tData  0.000 ( 0.000)\tD(real) 1.0314 (0.5132)\tD(fake)1 -0.5485 (-0.4641)\tD(fake)2 0.0131 (-0.4900)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3634 (-0.3189)\tD repr loss -0.4724 (-0.4574)\n",
            "Epoch: [7][780/781]\tTime  2.479 ( 2.483)\tData  0.000 ( 0.000)\tD(real) 0.5138 (0.5070)\tD(fake)1 -1.0762 (-0.4787)\tD(fake)2 -0.8476 (-0.4966)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4251 (-0.3193)\tD repr loss -0.4281 (-0.4593)\n",
            "Epoch: [7][780/781]\tTime  2.467 ( 2.483)\tData  0.000 ( 0.000)\tD(real) 0.5138 (0.5070)\tD(fake)1 -1.0762 (-0.4787)\tD(fake)2 -0.8476 (-0.4966)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4251 (-0.3193)\tD repr loss -0.4281 (-0.4593)\n",
            "Epoch: [8][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.7309 (0.7415)\tD(fake)1 0.6979 (0.6979)\tD(fake)2 0.5330 (-0.2732)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3777 (-0.3777)\tD repr loss -0.3926 (-0.4602)\n",
            "Epoch: [8][120/781]\tTime  2.488 ( 2.496)\tData  0.000 ( 0.000)\tD(real) 0.9390 (0.5262)\tD(fake)1 -0.4636 (-0.4558)\tD(fake)2 -0.6126 (-0.5111)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4126 (-0.3463)\tD repr loss -0.3484 (-0.4608)\n",
            "Epoch: [8][230/781]\tTime  2.511 ( 2.483)\tData  0.000 ( 0.000)\tD(real) 0.2950 (0.5508)\tD(fake)1 -0.8566 (-0.3152)\tD(fake)2 -0.7071 (-0.4719)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3221 (-0.3277)\tD repr loss -0.4194 (-0.4577)\n",
            "Epoch: [8][340/781]\tTime  2.505 ( 2.485)\tData  0.000 ( 0.000)\tD(real) 0.3959 (0.5341)\tD(fake)1 -0.2763 (-0.3730)\tD(fake)2 -0.7119 (-0.4752)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3840 (-0.3338)\tD repr loss -0.4534 (-0.4591)\n",
            "Epoch: [8][450/781]\tTime  2.454 ( 2.486)\tData  0.000 ( 0.000)\tD(real) 0.8493 (0.5346)\tD(fake)1 -0.3011 (-0.3487)\tD(fake)2 -0.2667 (-0.4715)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3400 (-0.3343)\tD repr loss -0.4515 (-0.4592)\n",
            "Epoch: [8][560/781]\tTime  2.505 ( 2.484)\tData  0.000 ( 0.000)\tD(real) 1.5076 (0.5372)\tD(fake)1 0.0157 (-0.3931)\tD(fake)2 0.3640 (-0.4748)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2738 (-0.3285)\tD repr loss -0.4862 (-0.4618)\n",
            "Epoch: [8][670/781]\tTime  2.508 ( 2.484)\tData  0.000 ( 0.000)\tD(real) 0.8803 (0.5303)\tD(fake)1 -0.2577 (-0.4095)\tD(fake)2 -0.5893 (-0.4759)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3971 (-0.3345)\tD repr loss -0.4305 (-0.4631)\n",
            "Epoch: [8][780/781]\tTime  2.508 ( 2.488)\tData  0.000 ( 0.000)\tD(real) -0.2571 (0.5373)\tD(fake)1 -0.8421 (-0.4399)\tD(fake)2 -1.0742 (-0.4741)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3769 (-0.3300)\tD repr loss -0.4542 (-0.4625)\n",
            "Epoch: [8][780/781]\tTime  2.495 ( 2.488)\tData  0.000 ( 0.000)\tD(real) -0.2571 (0.5373)\tD(fake)1 -0.8421 (-0.4399)\tD(fake)2 -1.0742 (-0.4741)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3769 (-0.3300)\tD repr loss -0.4542 (-0.4625)\n",
            "Epoch: [9][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.5893 (0.5504)\tD(fake)1 0.1681 (0.1681)\tD(fake)2 -0.7208 (-0.4331)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2572 (-0.2572)\tD repr loss -0.4468 (-0.4438)\n",
            "Epoch: [9][120/781]\tTime  2.496 ( 2.504)\tData  0.000 ( 0.000)\tD(real) 0.3611 (0.5256)\tD(fake)1 -0.3388 (-0.5499)\tD(fake)2 -0.5676 (-0.4846)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3956 (-0.2873)\tD repr loss -0.4022 (-0.4529)\n",
            "Epoch: [9][230/781]\tTime  2.488 ( 2.496)\tData  0.000 ( 0.000)\tD(real) 0.4859 (0.5094)\tD(fake)1 -1.1393 (-0.6916)\tD(fake)2 -0.6714 (-0.4905)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3299 (-0.3040)\tD repr loss -0.4444 (-0.4598)\n",
            "Epoch: [9][340/781]\tTime  2.513 ( 2.494)\tData  0.000 ( 0.000)\tD(real) -0.9192 (0.5171)\tD(fake)1 -0.8780 (-0.6116)\tD(fake)2 -1.3179 (-0.4923)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1674 (-0.3091)\tD repr loss -0.3379 (-0.4598)\n",
            "Epoch: [9][450/781]\tTime  2.510 ( 2.488)\tData  0.000 ( 0.000)\tD(real) 1.3513 (0.5150)\tD(fake)1 -1.2462 (-0.6256)\tD(fake)2 -0.9600 (-0.4888)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3282 (-0.3063)\tD repr loss -0.3655 (-0.4613)\n",
            "Epoch: [9][560/781]\tTime  2.491 ( 2.486)\tData  0.000 ( 0.000)\tD(real) 0.9206 (0.5237)\tD(fake)1 0.3344 (-0.5558)\tD(fake)2 -0.2227 (-0.4832)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3089 (-0.3103)\tD repr loss -0.4603 (-0.4621)\n",
            "Epoch: [9][670/781]\tTime  2.500 ( 2.484)\tData  0.000 ( 0.000)\tD(real) 1.0196 (0.5211)\tD(fake)1 -1.1422 (-0.5888)\tD(fake)2 0.0706 (-0.4857)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3899 (-0.3070)\tD repr loss -0.3953 (-0.4612)\n",
            "Epoch: [9][780/781]\tTime  2.528 ( 2.487)\tData  0.000 ( 0.000)\tD(real) 0.3532 (0.5220)\tD(fake)1 -1.3238 (-0.6146)\tD(fake)2 -0.8053 (-0.4870)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3250 (-0.3065)\tD repr loss -0.4623 (-0.4614)\n",
            "Epoch: [9][780/781]\tTime  2.476 ( 2.486)\tData  0.000 ( 0.000)\tD(real) 0.3532 (0.5220)\tD(fake)1 -1.3238 (-0.6146)\tD(fake)2 -0.8053 (-0.4870)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3250 (-0.3065)\tD repr loss -0.4623 (-0.4614)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUGjJ-6Pf3xE",
        "outputId": "788fd125-3758-4d29-d5a2-3e335e686a31"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.1226 (0.5044)\tD(fake)1 0.0939 (0.0939)\tD(fake)2 -0.1279 (-0.5063)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2990 (-0.2990)\tD repr loss -0.4206 (-0.4444)\n",
            "Epoch: [0][120/781]\tTime  2.495 ( 2.518)\tData  0.000 ( 0.000)\tD(real) 1.4085 (0.5325)\tD(fake)1 -1.2354 (-0.5883)\tD(fake)2 -0.0002 (-0.4993)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1551 (-0.3036)\tD repr loss -0.4336 (-0.4514)\n",
            "Epoch: [0][230/781]\tTime  2.512 ( 2.508)\tData  0.000 ( 0.000)\tD(real) 0.9589 (0.5573)\tD(fake)1 0.5633 (-0.6474)\tD(fake)2 -0.3426 (-0.5053)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3857 (-0.3274)\tD repr loss -0.4355 (-0.4616)\n",
            "Epoch: [0][340/781]\tTime  2.481 ( 2.505)\tData  0.000 ( 0.000)\tD(real) -0.3799 (0.5574)\tD(fake)1 -1.4992 (-0.6686)\tD(fake)2 -1.1746 (-0.5245)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3175 (-0.3321)\tD repr loss -0.3608 (-0.4658)\n",
            "Epoch: [0][450/781]\tTime  2.490 ( 2.503)\tData  0.000 ( 0.000)\tD(real) 0.3827 (0.5341)\tD(fake)1 -0.7139 (-0.6044)\tD(fake)2 -0.5819 (-0.5283)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4156 (-0.3296)\tD repr loss -0.4523 (-0.4670)\n",
            "Epoch: [0][560/781]\tTime  2.491 ( 2.500)\tData  0.000 ( 0.000)\tD(real) 1.5812 (0.5408)\tD(fake)1 -1.2397 (-0.6868)\tD(fake)2 -0.9372 (-0.5342)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4093 (-0.3283)\tD repr loss -0.3402 (-0.4677)\n",
            "Epoch: [0][670/781]\tTime  2.513 ( 2.499)\tData  0.000 ( 0.000)\tD(real) 1.0107 (0.5419)\tD(fake)1 -0.5292 (-0.6670)\tD(fake)2 0.0162 (-0.5346)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2873 (-0.3298)\tD repr loss -0.3982 (-0.4675)\n",
            "Epoch: [0][780/781]\tTime  2.489 ( 2.496)\tData  0.000 ( 0.000)\tD(real) 0.1730 (0.5376)\tD(fake)1 -1.3441 (-0.6513)\tD(fake)2 -0.9279 (-0.5326)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2612 (-0.3310)\tD repr loss -0.4391 (-0.4679)\n",
            "Epoch: [0][780/781]\tTime  2.484 ( 2.496)\tData  0.000 ( 0.000)\tD(real) 0.1730 (0.5376)\tD(fake)1 -1.3441 (-0.6513)\tD(fake)2 -0.9279 (-0.5326)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2612 (-0.3310)\tD repr loss -0.4391 (-0.4679)\n",
            "Epoch: [1][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.4921 (0.6088)\tD(fake)1 0.0569 (0.0569)\tD(fake)2 -0.0148 (-0.4446)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2608 (-0.2608)\tD repr loss -0.4274 (-0.4633)\n",
            "Epoch: [1][120/781]\tTime  2.518 ( 2.515)\tData  0.000 ( 0.000)\tD(real) -0.1886 (0.4583)\tD(fake)1 -0.9897 (-0.5632)\tD(fake)2 -1.2456 (-0.5266)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2969 (-0.3033)\tD repr loss -0.4667 (-0.4784)\n",
            "Epoch: [1][230/781]\tTime  2.437 ( 2.493)\tData  0.000 ( 0.000)\tD(real) 1.2399 (0.5195)\tD(fake)1 0.4224 (-0.4515)\tD(fake)2 0.2023 (-0.5093)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2963 (-0.3123)\tD repr loss -0.4794 (-0.4699)\n",
            "Epoch: [1][340/781]\tTime  2.451 ( 2.486)\tData  0.000 ( 0.000)\tD(real) 1.9079 (0.5245)\tD(fake)1 -0.4486 (-0.5327)\tD(fake)2 0.6240 (-0.5146)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2623 (-0.3024)\tD repr loss -0.4337 (-0.4689)\n",
            "Epoch: [1][450/781]\tTime  2.500 ( 2.488)\tData  0.000 ( 0.000)\tD(real) 1.2303 (0.5247)\tD(fake)1 0.1759 (-0.6103)\tD(fake)2 0.1958 (-0.5196)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3632 (-0.3139)\tD repr loss -0.4669 (-0.4702)\n",
            "Epoch: [1][560/781]\tTime  2.460 ( 2.485)\tData  0.000 ( 0.000)\tD(real) 0.6166 (0.5208)\tD(fake)1 0.3678 (-0.5731)\tD(fake)2 -0.6241 (-0.5196)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3157 (-0.3118)\tD repr loss -0.4987 (-0.4702)\n",
            "Epoch: [1][670/781]\tTime  2.443 ( 2.485)\tData  0.000 ( 0.000)\tD(real) 0.9483 (0.5206)\tD(fake)1 -0.3175 (-0.5660)\tD(fake)2 -0.0449 (-0.5193)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2873 (-0.3069)\tD repr loss -0.4639 (-0.4686)\n",
            "Epoch: [1][780/781]\tTime  2.506 ( 2.485)\tData  0.000 ( 0.000)\tD(real) 1.4473 (0.5274)\tD(fake)1 -0.3269 (-0.5757)\tD(fake)2 0.1721 (-0.5193)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3814 (-0.3087)\tD repr loss -0.4735 (-0.4689)\n",
            "Epoch: [1][780/781]\tTime  2.438 ( 2.485)\tData  0.000 ( 0.000)\tD(real) 1.4473 (0.5274)\tD(fake)1 -0.3269 (-0.5757)\tD(fake)2 0.1721 (-0.5193)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3814 (-0.3087)\tD repr loss -0.4735 (-0.4689)\n",
            "Epoch: [2][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.5825 (0.6312)\tD(fake)1 -1.0601 (-1.0601)\tD(fake)2 0.4703 (-0.3892)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3710 (-0.3710)\tD repr loss -0.4073 (-0.4874)\n",
            "Epoch: [2][120/781]\tTime  2.515 ( 2.495)\tData  0.000 ( 0.000)\tD(real) -0.2924 (0.5373)\tD(fake)1 -1.0275 (-0.7880)\tD(fake)2 -1.2320 (-0.5523)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3011 (-0.3309)\tD repr loss -0.4661 (-0.4844)\n",
            "Epoch: [2][230/781]\tTime  2.491 ( 2.493)\tData  0.000 ( 0.000)\tD(real) 0.9982 (0.5728)\tD(fake)1 -0.6423 (-0.7710)\tD(fake)2 -0.5973 (-0.5291)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2891 (-0.3123)\tD repr loss -0.4627 (-0.4766)\n",
            "Epoch: [2][340/781]\tTime  2.501 ( 2.493)\tData  0.000 ( 0.000)\tD(real) 1.2055 (0.5805)\tD(fake)1 0.2912 (-0.6937)\tD(fake)2 0.0404 (-0.5061)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3496 (-0.3088)\tD repr loss -0.4129 (-0.4705)\n",
            "Epoch: [2][450/781]\tTime  2.525 ( 2.489)\tData  0.000 ( 0.000)\tD(real) 0.1568 (0.5774)\tD(fake)1 -1.2618 (-0.6580)\tD(fake)2 -0.9166 (-0.5086)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2308 (-0.3112)\tD repr loss -0.4342 (-0.4719)\n",
            "Epoch: [2][560/781]\tTime  2.520 ( 2.490)\tData  0.000 ( 0.000)\tD(real) 1.1301 (0.5706)\tD(fake)1 0.8735 (-0.6194)\tD(fake)2 -0.3109 (-0.5142)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3528 (-0.3122)\tD repr loss -0.4400 (-0.4713)\n",
            "Epoch: [2][670/781]\tTime  2.485 ( 2.489)\tData  0.000 ( 0.000)\tD(real) 0.9959 (0.5756)\tD(fake)1 -1.0766 (-0.6155)\tD(fake)2 -0.2174 (-0.5055)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4016 (-0.3128)\tD repr loss -0.4988 (-0.4684)\n",
            "Epoch: [2][780/781]\tTime  2.510 ( 2.489)\tData  0.000 ( 0.000)\tD(real) 1.7334 (0.5650)\tD(fake)1 -0.7803 (-0.5986)\tD(fake)2 0.6178 (-0.5054)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2892 (-0.3168)\tD repr loss -0.3716 (-0.4682)\n",
            "Epoch: [2][780/781]\tTime  2.466 ( 2.488)\tData  0.000 ( 0.000)\tD(real) 1.7334 (0.5650)\tD(fake)1 -0.7803 (-0.5986)\tD(fake)2 0.6178 (-0.5054)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2892 (-0.3168)\tD repr loss -0.3716 (-0.4682)\n",
            "Epoch: [3][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.3042 (0.1888)\tD(fake)1 -1.3792 (-1.3792)\tD(fake)2 -0.8902 (-0.7298)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2107 (-0.2107)\tD repr loss -0.3889 (-0.4583)\n",
            "Epoch: [3][120/781]\tTime  2.451 ( 2.498)\tData  0.000 ( 0.000)\tD(real) -0.5485 (0.5048)\tD(fake)1 -1.1275 (-0.7653)\tD(fake)2 -1.2904 (-0.5451)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3772 (-0.2975)\tD repr loss -0.4023 (-0.4661)\n",
            "Epoch: [3][230/781]\tTime  2.505 ( 2.500)\tData  0.000 ( 0.000)\tD(real) -0.8562 (0.4936)\tD(fake)1 -1.1411 (-0.5097)\tD(fake)2 -1.4628 (-0.5170)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3630 (-0.3248)\tD repr loss -0.4259 (-0.4673)\n",
            "Epoch: [3][340/781]\tTime  2.515 ( 2.499)\tData  0.000 ( 0.000)\tD(real) -0.4027 (0.5333)\tD(fake)1 -1.7316 (-0.5766)\tD(fake)2 -1.1289 (-0.5090)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1280 (-0.3195)\tD repr loss -0.4662 (-0.4650)\n",
            "Epoch: [3][450/781]\tTime  2.468 ( 2.495)\tData  0.000 ( 0.000)\tD(real) -0.3013 (0.5396)\tD(fake)1 -1.1935 (-0.5037)\tD(fake)2 -1.2476 (-0.5001)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2531 (-0.3134)\tD repr loss -0.4288 (-0.4631)\n",
            "Epoch: [3][560/781]\tTime  2.487 ( 2.494)\tData  0.000 ( 0.000)\tD(real) 0.8165 (0.5396)\tD(fake)1 0.2890 (-0.4539)\tD(fake)2 -0.4145 (-0.4941)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3731 (-0.3119)\tD repr loss -0.3985 (-0.4641)\n",
            "Epoch: [3][670/781]\tTime  2.439 ( 2.491)\tData  0.000 ( 0.000)\tD(real) -0.1060 (0.5422)\tD(fake)1 -1.3134 (-0.5093)\tD(fake)2 -1.2611 (-0.5027)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3899 (-0.3110)\tD repr loss -0.4733 (-0.4647)\n",
            "Epoch: [3][780/781]\tTime  2.445 ( 2.489)\tData  0.000 ( 0.000)\tD(real) 1.6594 (0.5358)\tD(fake)1 -1.2108 (-0.4883)\tD(fake)2 0.3031 (-0.5019)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4013 (-0.3135)\tD repr loss -0.4084 (-0.4667)\n",
            "Epoch: [3][780/781]\tTime  2.480 ( 2.489)\tData  0.000 ( 0.000)\tD(real) 1.6594 (0.5358)\tD(fake)1 -1.2108 (-0.4883)\tD(fake)2 0.3031 (-0.5019)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4013 (-0.3135)\tD repr loss -0.4084 (-0.4667)\n",
            "Epoch: [4][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) -0.3160 (0.1742)\tD(fake)1 -1.2090 (-1.2090)\tD(fake)2 -1.2266 (-0.6769)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3304 (-0.3304)\tD repr loss -0.4518 (-0.4938)\n",
            "Epoch: [4][120/781]\tTime  2.486 ( 2.515)\tData  0.000 ( 0.000)\tD(real) 0.7647 (0.5225)\tD(fake)1 1.2329 (-0.4537)\tD(fake)2 -0.5209 (-0.4947)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2952 (-0.3482)\tD repr loss -0.4842 (-0.4648)\n",
            "Epoch: [4][230/781]\tTime  2.442 ( 2.503)\tData  0.000 ( 0.000)\tD(real) 1.3452 (0.5723)\tD(fake)1 -1.1572 (-0.5711)\tD(fake)2 0.6089 (-0.5022)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3556 (-0.3328)\tD repr loss -0.4065 (-0.4675)\n",
            "Epoch: [4][340/781]\tTime  2.453 ( 2.499)\tData  0.000 ( 0.000)\tD(real) 0.2231 (0.5492)\tD(fake)1 -0.5047 (-0.4989)\tD(fake)2 -0.8143 (-0.5202)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2831 (-0.3320)\tD repr loss -0.4662 (-0.4641)\n",
            "Epoch: [4][450/781]\tTime  2.529 ( 2.497)\tData  0.000 ( 0.000)\tD(real) -0.3210 (0.5727)\tD(fake)1 -0.7766 (-0.5037)\tD(fake)2 -1.0305 (-0.5078)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3787 (-0.3325)\tD repr loss -0.4702 (-0.4630)\n",
            "Epoch: [4][560/781]\tTime  2.498 ( 2.499)\tData  0.000 ( 0.000)\tD(real) 0.9408 (0.5663)\tD(fake)1 0.0486 (-0.5405)\tD(fake)2 -0.4376 (-0.5118)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3179 (-0.3281)\tD repr loss -0.4908 (-0.4636)\n",
            "Epoch: [4][670/781]\tTime  2.465 ( 2.495)\tData  0.000 ( 0.000)\tD(real) -0.3705 (0.5643)\tD(fake)1 -1.2225 (-0.5726)\tD(fake)2 -1.4538 (-0.5134)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3477 (-0.3304)\tD repr loss -0.4394 (-0.4638)\n",
            "Epoch: [4][780/781]\tTime  2.493 ( 2.495)\tData  0.000 ( 0.000)\tD(real) 0.7339 (0.5573)\tD(fake)1 0.4729 (-0.5482)\tD(fake)2 -0.6083 (-0.5116)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3639 (-0.3393)\tD repr loss -0.4716 (-0.4668)\n",
            "Epoch: [4][780/781]\tTime  2.447 ( 2.494)\tData  0.000 ( 0.000)\tD(real) 0.7339 (0.5573)\tD(fake)1 0.4729 (-0.5482)\tD(fake)2 -0.6083 (-0.5116)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3639 (-0.3393)\tD repr loss -0.4716 (-0.4668)\n",
            "Epoch: [5][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.9532 (0.7008)\tD(fake)1 -0.7316 (-0.7316)\tD(fake)2 -0.5617 (-0.4380)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3992 (-0.3992)\tD repr loss -0.4114 (-0.4402)\n",
            "Epoch: [5][120/781]\tTime  2.496 ( 2.496)\tData  0.000 ( 0.000)\tD(real) 0.1278 (0.5331)\tD(fake)1 -1.1864 (-0.5725)\tD(fake)2 -0.9020 (-0.5601)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3620 (-0.3730)\tD repr loss -0.4609 (-0.4790)\n",
            "Epoch: [5][230/781]\tTime  2.506 ( 2.491)\tData  0.000 ( 0.000)\tD(real) -0.1788 (0.5458)\tD(fake)1 -0.0482 (-0.5664)\tD(fake)2 -1.3097 (-0.5697)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3110 (-0.3381)\tD repr loss -0.5081 (-0.4728)\n",
            "Epoch: [5][340/781]\tTime  2.493 ( 2.494)\tData  0.000 ( 0.000)\tD(real) 1.5221 (0.5515)\tD(fake)1 -0.3627 (-0.6210)\tD(fake)2 -0.7499 (-0.5653)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3263 (-0.3525)\tD repr loss -0.4228 (-0.4755)\n",
            "Epoch: [5][450/781]\tTime  2.490 ( 2.492)\tData  0.000 ( 0.000)\tD(real) 1.4398 (0.5362)\tD(fake)1 -1.3039 (-0.6335)\tD(fake)2 0.0903 (-0.5631)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3553 (-0.3445)\tD repr loss -0.4557 (-0.4726)\n",
            "Epoch: [5][560/781]\tTime  2.502 ( 2.492)\tData  0.000 ( 0.000)\tD(real) -0.3253 (0.5324)\tD(fake)1 0.0604 (-0.6191)\tD(fake)2 -1.1880 (-0.5647)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3574 (-0.3502)\tD repr loss -0.4367 (-0.4753)\n",
            "Epoch: [5][670/781]\tTime  2.509 ( 2.492)\tData  0.000 ( 0.000)\tD(real) 1.3356 (0.5398)\tD(fake)1 -1.2414 (-0.5851)\tD(fake)2 0.1105 (-0.5555)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3616 (-0.3503)\tD repr loss -0.4835 (-0.4747)\n",
            "Epoch: [5][780/781]\tTime  2.490 ( 2.493)\tData  0.000 ( 0.000)\tD(real) 0.6995 (0.5361)\tD(fake)1 0.1712 (-0.5838)\tD(fake)2 -0.4654 (-0.5571)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3769 (-0.3547)\tD repr loss -0.4443 (-0.4737)\n",
            "Epoch: [5][780/781]\tTime  2.490 ( 2.493)\tData  0.000 ( 0.000)\tD(real) 0.6995 (0.5361)\tD(fake)1 0.1712 (-0.5838)\tD(fake)2 -0.4654 (-0.5571)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3769 (-0.3547)\tD repr loss -0.4443 (-0.4737)\n",
            "Epoch: [6][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.1767 (0.5459)\tD(fake)1 -0.9866 (-0.9866)\tD(fake)2 -0.6630 (-0.5604)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3604 (-0.3604)\tD repr loss -0.4468 (-0.4552)\n",
            "Epoch: [6][120/781]\tTime  2.461 ( 2.508)\tData  0.000 ( 0.000)\tD(real) 0.0273 (0.5148)\tD(fake)1 -1.3799 (-0.6453)\tD(fake)2 -0.9736 (-0.5638)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3655 (-0.3407)\tD repr loss -0.4771 (-0.4753)\n",
            "Epoch: [6][230/781]\tTime  2.453 ( 2.492)\tData  0.000 ( 0.000)\tD(real) 1.3506 (0.5306)\tD(fake)1 0.1842 (-0.5823)\tD(fake)2 0.0860 (-0.5540)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2291 (-0.3373)\tD repr loss -0.4524 (-0.4737)\n",
            "Epoch: [6][340/781]\tTime  2.458 ( 2.493)\tData  0.000 ( 0.000)\tD(real) 0.2186 (0.5888)\tD(fake)1 -0.7560 (-0.5255)\tD(fake)2 -0.8240 (-0.5332)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2457 (-0.3298)\tD repr loss -0.4157 (-0.4678)\n",
            "Epoch: [6][450/781]\tTime  2.487 ( 2.488)\tData  0.000 ( 0.000)\tD(real) 1.0630 (0.5928)\tD(fake)1 0.3986 (-0.4923)\tD(fake)2 -1.2301 (-0.5192)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3649 (-0.3354)\tD repr loss -0.2973 (-0.4678)\n",
            "Epoch: [6][560/781]\tTime  2.484 ( 2.491)\tData  0.000 ( 0.000)\tD(real) 1.4233 (0.5934)\tD(fake)1 -0.0754 (-0.4257)\tD(fake)2 0.0585 (-0.5055)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3652 (-0.3414)\tD repr loss -0.4103 (-0.4683)\n",
            "Epoch: [6][670/781]\tTime  2.484 ( 2.491)\tData  0.000 ( 0.000)\tD(real) 1.6132 (0.5865)\tD(fake)1 -0.2309 (-0.4225)\tD(fake)2 0.2414 (-0.5119)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2923 (-0.3446)\tD repr loss -0.3863 (-0.4715)\n",
            "Epoch: [6][780/781]\tTime  2.443 ( 2.491)\tData  0.000 ( 0.000)\tD(real) 1.5658 (0.5904)\tD(fake)1 -0.7794 (-0.4628)\tD(fake)2 0.3953 (-0.5064)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3769 (-0.3449)\tD repr loss -0.4719 (-0.4722)\n",
            "Epoch: [6][780/781]\tTime  2.463 ( 2.490)\tData  0.000 ( 0.000)\tD(real) 1.5658 (0.5904)\tD(fake)1 -0.7794 (-0.4628)\tD(fake)2 0.3953 (-0.5064)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3769 (-0.3449)\tD repr loss -0.4719 (-0.4722)\n",
            "Epoch: [7][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) -0.3055 (0.2012)\tD(fake)1 -1.3202 (-1.3202)\tD(fake)2 -1.2174 (-0.7562)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3557 (-0.3557)\tD repr loss -0.4584 (-0.4872)\n",
            "Epoch: [7][120/781]\tTime  2.477 ( 2.510)\tData  0.000 ( 0.000)\tD(real) -0.3004 (0.5595)\tD(fake)1 -1.1155 (-0.7539)\tD(fake)2 -1.3583 (-0.5506)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3350 (-0.3450)\tD repr loss -0.4549 (-0.4725)\n",
            "Epoch: [7][230/781]\tTime  2.459 ( 2.494)\tData  0.000 ( 0.000)\tD(real) 2.3946 (0.5809)\tD(fake)1 -1.0286 (-0.7480)\tD(fake)2 1.2430 (-0.5349)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3198 (-0.3468)\tD repr loss -0.3594 (-0.4706)\n",
            "Epoch: [7][340/781]\tTime  2.499 ( 2.491)\tData  0.000 ( 0.000)\tD(real) 0.4137 (0.5717)\tD(fake)1 -1.3770 (-0.8078)\tD(fake)2 -0.9675 (-0.5333)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3958 (-0.3439)\tD repr loss -0.4440 (-0.4685)\n",
            "Epoch: [7][450/781]\tTime  2.497 ( 2.491)\tData  0.000 ( 0.000)\tD(real) 1.3925 (0.5865)\tD(fake)1 -0.7823 (-0.7436)\tD(fake)2 0.2814 (-0.5273)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4020 (-0.3437)\tD repr loss -0.4600 (-0.4671)\n",
            "Epoch: [7][560/781]\tTime  2.508 ( 2.490)\tData  0.000 ( 0.000)\tD(real) -0.1253 (0.5734)\tD(fake)1 -0.9462 (-0.7149)\tD(fake)2 -1.0929 (-0.5324)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3261 (-0.3419)\tD repr loss -0.4379 (-0.4669)\n",
            "Epoch: [7][670/781]\tTime  2.522 ( 2.492)\tData  0.000 ( 0.000)\tD(real) 0.4363 (0.5705)\tD(fake)1 -1.0511 (-0.6908)\tD(fake)2 -0.6745 (-0.5374)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4332 (-0.3399)\tD repr loss -0.5034 (-0.4689)\n",
            "Epoch: [7][780/781]\tTime  2.455 ( 2.492)\tData  0.000 ( 0.000)\tD(real) 1.2947 (0.5696)\tD(fake)1 -0.9008 (-0.6518)\tD(fake)2 -0.0664 (-0.5349)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1892 (-0.3327)\tD repr loss -0.4863 (-0.4675)\n",
            "Epoch: [7][780/781]\tTime  2.491 ( 2.492)\tData  0.000 ( 0.000)\tD(real) 1.2947 (0.5696)\tD(fake)1 -0.9008 (-0.6518)\tD(fake)2 -0.0664 (-0.5349)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1892 (-0.3327)\tD repr loss -0.4863 (-0.4675)\n",
            "Epoch: [8][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.0802 (0.3929)\tD(fake)1 -1.2522 (-1.2522)\tD(fake)2 -1.1798 (-0.8007)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3690 (-0.3690)\tD repr loss -0.4254 (-0.4623)\n",
            "Epoch: [8][120/781]\tTime  2.508 ( 2.495)\tData  0.000 ( 0.000)\tD(real) -0.5051 (0.5460)\tD(fake)1 -1.2397 (-0.6942)\tD(fake)2 -1.4417 (-0.5966)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4226 (-0.3503)\tD repr loss -0.4485 (-0.4743)\n",
            "Epoch: [8][230/781]\tTime  2.500 ( 2.484)\tData  0.000 ( 0.000)\tD(real) 1.4914 (0.5725)\tD(fake)1 0.7575 (-0.5818)\tD(fake)2 -0.7451 (-0.5644)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4182 (-0.3392)\tD repr loss -0.3725 (-0.4661)\n",
            "Epoch: [8][340/781]\tTime  2.507 ( 2.488)\tData  0.000 ( 0.000)\tD(real) 2.0017 (0.5727)\tD(fake)1 0.3385 (-0.5512)\tD(fake)2 0.4861 (-0.5529)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0999 (-0.3294)\tD repr loss -0.4976 (-0.4640)\n",
            "Epoch: [8][450/781]\tTime  2.488 ( 2.492)\tData  0.000 ( 0.000)\tD(real) 1.7079 (0.5694)\tD(fake)1 -0.4770 (-0.5487)\tD(fake)2 0.2197 (-0.5499)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3197 (-0.3239)\tD repr loss -0.4906 (-0.4651)\n",
            "Epoch: [8][560/781]\tTime  2.511 ( 2.493)\tData  0.000 ( 0.000)\tD(real) 1.0042 (0.5708)\tD(fake)1 0.0536 (-0.5743)\tD(fake)2 -0.2239 (-0.5411)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3958 (-0.3275)\tD repr loss -0.4475 (-0.4659)\n",
            "Epoch: [8][670/781]\tTime  2.499 ( 2.493)\tData  0.000 ( 0.000)\tD(real) -0.0903 (0.5789)\tD(fake)1 -1.3297 (-0.5934)\tD(fake)2 -0.9848 (-0.5519)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3013 (-0.3267)\tD repr loss -0.4660 (-0.4667)\n",
            "Epoch: [8][780/781]\tTime  2.526 ( 2.493)\tData  0.000 ( 0.000)\tD(real) 1.3762 (0.5775)\tD(fake)1 1.0110 (-0.5555)\tD(fake)2 -0.1823 (-0.5473)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3651 (-0.3265)\tD repr loss -0.4627 (-0.4663)\n",
            "Epoch: [8][780/781]\tTime  2.457 ( 2.492)\tData  0.000 ( 0.000)\tD(real) 1.3762 (0.5775)\tD(fake)1 1.0110 (-0.5555)\tD(fake)2 -0.1823 (-0.5473)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3651 (-0.3265)\tD repr loss -0.4627 (-0.4663)\n",
            "Epoch: [9][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) -0.5996 (0.4067)\tD(fake)1 -1.1682 (-1.1682)\tD(fake)2 -1.2544 (-0.6963)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3021 (-0.3021)\tD repr loss -0.3982 (-0.4864)\n",
            "Epoch: [9][120/781]\tTime  2.488 ( 2.506)\tData  0.000 ( 0.000)\tD(real) 1.8173 (0.6005)\tD(fake)1 -0.5956 (-0.9318)\tD(fake)2 0.0884 (-0.6030)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2491 (-0.3204)\tD repr loss -0.4649 (-0.4657)\n",
            "Epoch: [9][230/781]\tTime  2.497 ( 2.493)\tData  0.000 ( 0.000)\tD(real) 0.1183 (0.5964)\tD(fake)1 0.3982 (-0.9041)\tD(fake)2 -1.2614 (-0.6238)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4205 (-0.3311)\tD repr loss -0.2962 (-0.4675)\n",
            "Epoch: [9][340/781]\tTime  2.482 ( 2.493)\tData  0.000 ( 0.000)\tD(real) 0.9820 (0.6055)\tD(fake)1 -0.0418 (-0.7671)\tD(fake)2 0.0624 (-0.5941)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2816 (-0.3314)\tD repr loss -0.4178 (-0.4716)\n",
            "Epoch: [9][450/781]\tTime  2.482 ( 2.490)\tData  0.000 ( 0.000)\tD(real) 1.8077 (0.6228)\tD(fake)1 -1.2196 (-0.7404)\tD(fake)2 0.3140 (-0.5821)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2991 (-0.3251)\tD repr loss -0.5163 (-0.4706)\n",
            "Epoch: [9][560/781]\tTime  2.486 ( 2.490)\tData  0.000 ( 0.000)\tD(real) 1.0213 (0.6226)\tD(fake)1 -0.3473 (-0.7501)\tD(fake)2 -0.2117 (-0.5752)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3996 (-0.3330)\tD repr loss -0.4786 (-0.4719)\n",
            "Epoch: [9][670/781]\tTime  2.528 ( 2.492)\tData  0.000 ( 0.000)\tD(real) 1.3723 (0.6147)\tD(fake)1 -0.9649 (-0.6842)\tD(fake)2 -0.2683 (-0.5744)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3061 (-0.3316)\tD repr loss -0.3729 (-0.4719)\n",
            "Epoch: [9][780/781]\tTime  2.458 ( 2.492)\tData  0.000 ( 0.000)\tD(real) -0.2055 (0.5992)\tD(fake)1 -0.6173 (-0.6800)\tD(fake)2 -1.3376 (-0.5758)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4226 (-0.3345)\tD repr loss -0.3875 (-0.4727)\n",
            "Epoch: [9][780/781]\tTime  2.430 ( 2.491)\tData  0.000 ( 0.000)\tD(real) -0.2055 (0.5992)\tD(fake)1 -0.6173 (-0.6800)\tD(fake)2 -1.3376 (-0.5758)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4226 (-0.3345)\tD repr loss -0.3875 (-0.4727)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uhsj8_owgDSl",
        "outputId": "6380b87c-305c-4d65-f2c8-2bad91e75b9e"
      },
      "source": [
        "args.G_consistency = 0.1\n",
        "args.D_consistency = 0.1\n",
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.3784 (0.5778)\tD(fake)1 0.2895 (0.2895)\tD(fake)2 -0.9139 (-0.5009)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4252 (-0.4252)\tD repr loss -0.4177 (-0.4859)\n",
            "Epoch: [0][120/781]\tTime  2.489 ( 2.520)\tData  0.000 ( 0.000)\tD(real) 0.2819 (0.6126)\tD(fake)1 -1.3790 (-0.5913)\tD(fake)2 -0.8322 (-0.5378)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4140 (-0.3540)\tD repr loss -0.3876 (-0.4679)\n",
            "Epoch: [0][230/781]\tTime  2.508 ( 2.514)\tData  0.000 ( 0.000)\tD(real) 0.6257 (0.6017)\tD(fake)1 -0.8787 (-0.4427)\tD(fake)2 -0.6665 (-0.5405)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3222 (-0.3405)\tD repr loss -0.4461 (-0.4684)\n",
            "Epoch: [0][340/781]\tTime  2.488 ( 2.503)\tData  0.000 ( 0.000)\tD(real) 0.4453 (0.5821)\tD(fake)1 0.0479 (-0.5122)\tD(fake)2 -0.8579 (-0.5492)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3633 (-0.3483)\tD repr loss -0.4677 (-0.4706)\n",
            "Epoch: [0][450/781]\tTime  2.481 ( 2.503)\tData  0.000 ( 0.000)\tD(real) 0.3026 (0.5933)\tD(fake)1 -1.1467 (-0.5507)\tD(fake)2 -0.8422 (-0.5535)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3770 (-0.3461)\tD repr loss -0.4141 (-0.4704)\n",
            "Epoch: [0][560/781]\tTime  2.502 ( 2.499)\tData  0.000 ( 0.000)\tD(real) 0.4432 (0.5908)\tD(fake)1 0.9152 (-0.5778)\tD(fake)2 -0.7599 (-0.5524)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4983 (-0.3458)\tD repr loss -0.4696 (-0.4685)\n",
            "Epoch: [0][670/781]\tTime  2.506 ( 2.501)\tData  0.000 ( 0.000)\tD(real) 0.6635 (0.5883)\tD(fake)1 -0.4533 (-0.6012)\tD(fake)2 -0.4534 (-0.5568)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3579 (-0.3460)\tD repr loss -0.4682 (-0.4677)\n",
            "Epoch: [0][780/781]\tTime  2.516 ( 2.499)\tData  0.000 ( 0.000)\tD(real) 1.0281 (0.5803)\tD(fake)1 -0.3173 (-0.6063)\tD(fake)2 -0.4889 (-0.5605)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3215 (-0.3436)\tD repr loss -0.2343 (-0.4684)\n",
            "Epoch: [0][780/781]\tTime  2.485 ( 2.499)\tData  0.000 ( 0.000)\tD(real) 1.0281 (0.5803)\tD(fake)1 -0.3173 (-0.6063)\tD(fake)2 -0.4889 (-0.5605)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3215 (-0.3436)\tD repr loss -0.2343 (-0.4684)\n",
            "Epoch: [1][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.1706 (0.7534)\tD(fake)1 0.5768 (0.5768)\tD(fake)2 0.2910 (-0.2960)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3988 (-0.3988)\tD repr loss -0.4691 (-0.4123)\n",
            "Epoch: [1][120/781]\tTime  2.505 ( 2.514)\tData  0.000 ( 0.000)\tD(real) -0.3223 (0.5189)\tD(fake)1 -0.7885 (-0.7136)\tD(fake)2 -1.3177 (-0.5429)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3228 (-0.3205)\tD repr loss -0.4552 (-0.4592)\n",
            "Epoch: [1][230/781]\tTime  2.525 ( 2.499)\tData  0.000 ( 0.000)\tD(real) 0.3862 (0.5896)\tD(fake)1 -0.7899 (-0.7228)\tD(fake)2 -0.7849 (-0.5325)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3731 (-0.3366)\tD repr loss -0.4706 (-0.4630)\n",
            "Epoch: [1][340/781]\tTime  2.506 ( 2.497)\tData  0.000 ( 0.000)\tD(real) 0.1879 (0.5845)\tD(fake)1 -1.4487 (-0.5814)\tD(fake)2 -0.8057 (-0.5396)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3698 (-0.3460)\tD repr loss -0.4859 (-0.4685)\n",
            "Epoch: [1][450/781]\tTime  2.491 ( 2.498)\tData  0.000 ( 0.000)\tD(real) 0.9715 (0.5810)\tD(fake)1 -0.1105 (-0.6182)\tD(fake)2 -0.4860 (-0.5399)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2676 (-0.3373)\tD repr loss -0.3565 (-0.4661)\n",
            "Epoch: [1][560/781]\tTime  2.496 ( 2.498)\tData  0.000 ( 0.000)\tD(real) 0.6494 (0.5710)\tD(fake)1 0.3963 (-0.5900)\tD(fake)2 -0.5950 (-0.5388)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3769 (-0.3369)\tD repr loss -0.4372 (-0.4640)\n",
            "Epoch: [1][670/781]\tTime  2.500 ( 2.496)\tData  0.000 ( 0.000)\tD(real) 2.3109 (0.5808)\tD(fake)1 -0.0548 (-0.5440)\tD(fake)2 0.8703 (-0.5358)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2933 (-0.3380)\tD repr loss -0.4596 (-0.4636)\n",
            "Epoch: [1][780/781]\tTime  2.501 ( 2.496)\tData  0.000 ( 0.000)\tD(real) 1.6570 (0.5736)\tD(fake)1 -0.4656 (-0.5863)\tD(fake)2 0.4007 (-0.5405)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3381 (-0.3389)\tD repr loss -0.4118 (-0.4650)\n",
            "Epoch: [1][780/781]\tTime  2.466 ( 2.495)\tData  0.000 ( 0.000)\tD(real) 1.6570 (0.5736)\tD(fake)1 -0.4656 (-0.5863)\tD(fake)2 0.4007 (-0.5405)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3381 (-0.3389)\tD repr loss -0.4118 (-0.4650)\n",
            "Epoch: [2][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.0923 (0.4580)\tD(fake)1 -1.2935 (-1.2935)\tD(fake)2 -0.0979 (-0.5653)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3476 (-0.3476)\tD repr loss -0.3790 (-0.4656)\n",
            "Epoch: [2][120/781]\tTime  2.479 ( 2.508)\tData  0.000 ( 0.000)\tD(real) -0.1087 (0.5229)\tD(fake)1 -1.3515 (-0.7277)\tD(fake)2 -0.9360 (-0.6180)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3802 (-0.3640)\tD repr loss -0.4600 (-0.4860)\n",
            "Epoch: [2][230/781]\tTime  2.487 ( 2.504)\tData  0.000 ( 0.000)\tD(real) 0.5084 (0.5573)\tD(fake)1 -1.1494 (-0.6039)\tD(fake)2 -0.6896 (-0.5821)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3421 (-0.3481)\tD repr loss -0.4931 (-0.4811)\n",
            "Epoch: [2][340/781]\tTime  2.512 ( 2.503)\tData  0.000 ( 0.000)\tD(real) 0.5705 (0.5588)\tD(fake)1 -0.7067 (-0.5419)\tD(fake)2 -0.5354 (-0.5811)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3591 (-0.3423)\tD repr loss -0.3368 (-0.4784)\n",
            "Epoch: [2][450/781]\tTime  2.485 ( 2.500)\tData  0.000 ( 0.000)\tD(real) 1.1070 (0.5911)\tD(fake)1 -0.1874 (-0.5005)\tD(fake)2 -0.2803 (-0.5587)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4046 (-0.3444)\tD repr loss -0.4463 (-0.4751)\n",
            "Epoch: [2][560/781]\tTime  2.494 ( 2.498)\tData  0.000 ( 0.000)\tD(real) 1.0973 (0.6093)\tD(fake)1 -0.5514 (-0.4849)\tD(fake)2 -0.2577 (-0.5571)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3032 (-0.3442)\tD repr loss -0.5477 (-0.4731)\n",
            "Epoch: [2][670/781]\tTime  2.496 ( 2.497)\tData  0.000 ( 0.000)\tD(real) 0.2554 (0.6119)\tD(fake)1 -1.0758 (-0.5335)\tD(fake)2 -0.8818 (-0.5578)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3052 (-0.3441)\tD repr loss -0.4402 (-0.4734)\n",
            "Epoch: [2][780/781]\tTime  2.451 ( 2.495)\tData  0.000 ( 0.000)\tD(real) -0.2191 (0.6073)\tD(fake)1 -0.8545 (-0.5670)\tD(fake)2 -1.0006 (-0.5597)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2425 (-0.3379)\tD repr loss -0.4611 (-0.4722)\n",
            "Epoch: [2][780/781]\tTime  2.499 ( 2.495)\tData  0.000 ( 0.000)\tD(real) -0.2191 (0.6073)\tD(fake)1 -0.8545 (-0.5670)\tD(fake)2 -1.0006 (-0.5597)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2425 (-0.3379)\tD repr loss -0.4611 (-0.4722)\n",
            "Epoch: [3][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) -0.3113 (0.5002)\tD(fake)1 -0.0125 (-0.0125)\tD(fake)2 -1.1247 (-0.3785)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3027 (-0.3027)\tD repr loss -0.5020 (-0.4648)\n",
            "Epoch: [3][120/781]\tTime  2.504 ( 2.502)\tData  0.000 ( 0.000)\tD(real) 1.7989 (0.5993)\tD(fake)1 -0.7835 (-0.6946)\tD(fake)2 0.4479 (-0.5186)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3541 (-0.3061)\tD repr loss -0.4548 (-0.4693)\n",
            "Epoch: [3][230/781]\tTime  2.496 ( 2.498)\tData  0.000 ( 0.000)\tD(real) 1.5878 (0.5739)\tD(fake)1 -0.5174 (-0.6171)\tD(fake)2 0.0671 (-0.5496)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3624 (-0.3194)\tD repr loss -0.4422 (-0.4759)\n",
            "Epoch: [3][340/781]\tTime  2.443 ( 2.491)\tData  0.000 ( 0.000)\tD(real) 0.9053 (0.5740)\tD(fake)1 0.1485 (-0.6767)\tD(fake)2 -0.8063 (-0.5647)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2896 (-0.3238)\tD repr loss -0.4067 (-0.4749)\n",
            "Epoch: [3][450/781]\tTime  2.502 ( 2.493)\tData  0.000 ( 0.000)\tD(real) 0.1010 (0.5747)\tD(fake)1 -1.1441 (-0.6624)\tD(fake)2 -0.9718 (-0.5577)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2145 (-0.3222)\tD repr loss -0.4114 (-0.4743)\n",
            "Epoch: [3][560/781]\tTime  2.494 ( 2.491)\tData  0.000 ( 0.000)\tD(real) 0.4221 (0.5709)\tD(fake)1 -1.3277 (-0.6574)\tD(fake)2 -0.8575 (-0.5622)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2132 (-0.3215)\tD repr loss -0.4497 (-0.4746)\n",
            "Epoch: [3][670/781]\tTime  2.493 ( 2.493)\tData  0.000 ( 0.000)\tD(real) 0.3910 (0.5698)\tD(fake)1 -0.7086 (-0.6393)\tD(fake)2 -0.7712 (-0.5625)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3871 (-0.3236)\tD repr loss -0.3969 (-0.4731)\n",
            "Epoch: [3][780/781]\tTime  2.515 ( 2.496)\tData  0.000 ( 0.000)\tD(real) 0.7115 (0.5684)\tD(fake)1 -0.6206 (-0.6253)\tD(fake)2 -0.4810 (-0.5665)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2766 (-0.3242)\tD repr loss -0.4663 (-0.4715)\n",
            "Epoch: [3][780/781]\tTime  2.475 ( 2.496)\tData  0.000 ( 0.000)\tD(real) 0.7115 (0.5684)\tD(fake)1 -0.6206 (-0.6253)\tD(fake)2 -0.4810 (-0.5665)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2766 (-0.3242)\tD repr loss -0.4663 (-0.4715)\n",
            "Epoch: [4][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.0181 (0.5115)\tD(fake)1 -0.7551 (-0.7551)\tD(fake)2 -1.0795 (-0.6116)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4293 (-0.4293)\tD repr loss -0.4401 (-0.4879)\n",
            "Epoch: [4][120/781]\tTime  2.491 ( 2.513)\tData  0.000 ( 0.000)\tD(real) 0.1929 (0.6368)\tD(fake)1 -1.0946 (-0.3806)\tD(fake)2 -0.8719 (-0.5390)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3386 (-0.3508)\tD repr loss -0.3540 (-0.4617)\n",
            "Epoch: [4][230/781]\tTime  2.507 ( 2.493)\tData  0.000 ( 0.000)\tD(real) 0.4987 (0.6236)\tD(fake)1 -1.0005 (-0.6041)\tD(fake)2 -0.8048 (-0.5417)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3899 (-0.3405)\tD repr loss -0.4111 (-0.4614)\n",
            "Epoch: [4][340/781]\tTime  2.506 ( 2.495)\tData  0.000 ( 0.000)\tD(real) 0.2963 (0.6274)\tD(fake)1 -1.3512 (-0.6812)\tD(fake)2 -1.0754 (-0.5452)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3703 (-0.3372)\tD repr loss -0.4670 (-0.4656)\n",
            "Epoch: [4][450/781]\tTime  2.470 ( 2.492)\tData  0.000 ( 0.000)\tD(real) 0.3659 (0.6193)\tD(fake)1 -1.2126 (-0.6951)\tD(fake)2 -0.3499 (-0.5542)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1641 (-0.3334)\tD repr loss -0.4026 (-0.4659)\n",
            "Epoch: [4][560/781]\tTime  2.508 ( 2.492)\tData  0.000 ( 0.000)\tD(real) 0.6959 (0.6079)\tD(fake)1 -0.5597 (-0.6763)\tD(fake)2 -0.5348 (-0.5644)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3447 (-0.3273)\tD repr loss -0.4395 (-0.4670)\n",
            "Epoch: [4][670/781]\tTime  2.509 ( 2.494)\tData  0.000 ( 0.000)\tD(real) 0.4604 (0.6168)\tD(fake)1 0.0733 (-0.6552)\tD(fake)2 -0.8507 (-0.5665)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3161 (-0.3317)\tD repr loss -0.4894 (-0.4671)\n",
            "Epoch: [4][780/781]\tTime  2.505 ( 2.493)\tData  0.000 ( 0.000)\tD(real) -0.4181 (0.6105)\tD(fake)1 -1.0316 (-0.6589)\tD(fake)2 -1.1943 (-0.5685)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3450 (-0.3311)\tD repr loss -0.4067 (-0.4692)\n",
            "Epoch: [4][780/781]\tTime  2.459 ( 2.493)\tData  0.000 ( 0.000)\tD(real) -0.4181 (0.6105)\tD(fake)1 -1.0316 (-0.6589)\tD(fake)2 -1.1943 (-0.5685)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3450 (-0.3311)\tD repr loss -0.4067 (-0.4692)\n",
            "Epoch: [5][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.2871 (0.7315)\tD(fake)1 -0.5259 (-0.5259)\tD(fake)2 -0.2539 (-0.5343)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2563 (-0.2563)\tD repr loss -0.4782 (-0.4921)\n",
            "Epoch: [5][120/781]\tTime  2.475 ( 2.487)\tData  0.000 ( 0.000)\tD(real) 1.2036 (0.6480)\tD(fake)1 -0.1573 (-0.8011)\tD(fake)2 -0.1652 (-0.5592)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3811 (-0.3361)\tD repr loss -0.4857 (-0.4873)\n",
            "Epoch: [5][230/781]\tTime  2.482 ( 2.486)\tData  0.000 ( 0.000)\tD(real) -0.7435 (0.6343)\tD(fake)1 -0.9723 (-0.7490)\tD(fake)2 -1.3948 (-0.5691)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3772 (-0.3533)\tD repr loss -0.4239 (-0.4833)\n",
            "Epoch: [5][340/781]\tTime  2.505 ( 2.486)\tData  0.000 ( 0.000)\tD(real) 0.1305 (0.6292)\tD(fake)1 -1.0336 (-0.6142)\tD(fake)2 -1.0020 (-0.5667)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2793 (-0.3485)\tD repr loss -0.4060 (-0.4814)\n",
            "Epoch: [5][450/781]\tTime  2.477 ( 2.482)\tData  0.000 ( 0.000)\tD(real) 0.0611 (0.6286)\tD(fake)1 -0.6469 (-0.6009)\tD(fake)2 -0.7351 (-0.5661)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4286 (-0.3496)\tD repr loss -0.5048 (-0.4793)\n",
            "Epoch: [5][560/781]\tTime  2.486 ( 2.485)\tData  0.000 ( 0.000)\tD(real) -0.3174 (0.6112)\tD(fake)1 -1.4709 (-0.6199)\tD(fake)2 -1.1207 (-0.5709)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3631 (-0.3473)\tD repr loss -0.4562 (-0.4804)\n",
            "Epoch: [5][670/781]\tTime  2.475 ( 2.486)\tData  0.000 ( 0.000)\tD(real) 0.2222 (0.5983)\tD(fake)1 -0.7565 (-0.6192)\tD(fake)2 -0.8540 (-0.5691)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2819 (-0.3449)\tD repr loss -0.4659 (-0.4789)\n",
            "Epoch: [5][780/781]\tTime  2.488 ( 2.487)\tData  0.000 ( 0.000)\tD(real) -0.4804 (0.5936)\tD(fake)1 -1.2076 (-0.6679)\tD(fake)2 -1.3954 (-0.5759)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2657 (-0.3443)\tD repr loss -0.4159 (-0.4799)\n",
            "Epoch: [5][780/781]\tTime  2.463 ( 2.487)\tData  0.000 ( 0.000)\tD(real) -0.4804 (0.5936)\tD(fake)1 -1.2076 (-0.6679)\tD(fake)2 -1.3954 (-0.5759)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2657 (-0.3443)\tD repr loss -0.4159 (-0.4799)\n",
            "Epoch: [6][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.2565 (0.7600)\tD(fake)1 -0.4163 (-0.4163)\tD(fake)2 -0.9945 (-0.6442)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2994 (-0.2994)\tD repr loss -0.4733 (-0.4892)\n",
            "Epoch: [6][120/781]\tTime  2.495 ( 2.501)\tData  0.000 ( 0.000)\tD(real) 1.6638 (0.6241)\tD(fake)1 -0.5902 (-0.4331)\tD(fake)2 0.0681 (-0.5844)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3537 (-0.3063)\tD repr loss -0.4959 (-0.4826)\n",
            "Epoch: [6][230/781]\tTime  2.500 ( 2.499)\tData  0.000 ( 0.000)\tD(real) 0.3042 (0.5937)\tD(fake)1 1.0962 (-0.5237)\tD(fake)2 -0.7549 (-0.5880)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3745 (-0.3257)\tD repr loss -0.4505 (-0.4806)\n",
            "Epoch: [6][340/781]\tTime  2.470 ( 2.490)\tData  0.000 ( 0.000)\tD(real) 1.7076 (0.6002)\tD(fake)1 -0.5248 (-0.5225)\tD(fake)2 0.2148 (-0.5746)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3514 (-0.3253)\tD repr loss -0.4704 (-0.4791)\n",
            "Epoch: [6][450/781]\tTime  2.487 ( 2.490)\tData  0.000 ( 0.000)\tD(real) 0.7808 (0.5879)\tD(fake)1 -0.2396 (-0.5491)\tD(fake)2 -0.6165 (-0.5781)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3374 (-0.3304)\tD repr loss -0.4899 (-0.4788)\n",
            "Epoch: [6][560/781]\tTime  2.462 ( 2.488)\tData  0.000 ( 0.000)\tD(real) 0.5300 (0.5728)\tD(fake)1 -1.2651 (-0.5657)\tD(fake)2 -0.8044 (-0.5821)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2944 (-0.3277)\tD repr loss -0.4712 (-0.4786)\n",
            "Epoch: [6][670/781]\tTime  2.482 ( 2.488)\tData  0.000 ( 0.000)\tD(real) 0.3314 (0.5685)\tD(fake)1 -0.6551 (-0.5511)\tD(fake)2 -0.6150 (-0.5784)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4099 (-0.3324)\tD repr loss -0.5058 (-0.4759)\n",
            "Epoch: [6][780/781]\tTime  2.478 ( 2.486)\tData  0.000 ( 0.000)\tD(real) 0.8430 (0.5793)\tD(fake)1 0.1467 (-0.5345)\tD(fake)2 -0.3452 (-0.5690)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3227 (-0.3384)\tD repr loss -0.5132 (-0.4777)\n",
            "Epoch: [6][780/781]\tTime  2.476 ( 2.486)\tData  0.000 ( 0.000)\tD(real) 0.8430 (0.5793)\tD(fake)1 0.1467 (-0.5345)\tD(fake)2 -0.3452 (-0.5690)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3227 (-0.3384)\tD repr loss -0.5132 (-0.4777)\n",
            "Epoch: [7][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) -0.1424 (0.4253)\tD(fake)1 -0.9869 (-0.9869)\tD(fake)2 -0.5456 (-0.6034)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2410 (-0.2410)\tD repr loss -0.3804 (-0.4554)\n",
            "Epoch: [7][120/781]\tTime  2.488 ( 2.516)\tData  0.000 ( 0.000)\tD(real) 0.7084 (0.6270)\tD(fake)1 -0.7974 (-0.6171)\tD(fake)2 -1.3602 (-0.5539)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3275 (-0.3238)\tD repr loss -0.3653 (-0.4692)\n",
            "Epoch: [7][230/781]\tTime  2.515 ( 2.501)\tData  0.000 ( 0.000)\tD(real) 1.4349 (0.6195)\tD(fake)1 -0.7448 (-0.3614)\tD(fake)2 0.1664 (-0.5279)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3473 (-0.3235)\tD repr loss -0.4851 (-0.4685)\n",
            "Epoch: [7][340/781]\tTime  2.484 ( 2.496)\tData  0.000 ( 0.000)\tD(real) -0.1652 (0.6070)\tD(fake)1 -0.5572 (-0.4972)\tD(fake)2 -0.8481 (-0.5501)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3342 (-0.3265)\tD repr loss -0.5254 (-0.4755)\n",
            "Epoch: [7][450/781]\tTime  2.516 ( 2.496)\tData  0.000 ( 0.000)\tD(real) 0.7314 (0.6091)\tD(fake)1 -0.2907 (-0.5625)\tD(fake)2 -0.4390 (-0.5603)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3399 (-0.3335)\tD repr loss -0.4742 (-0.4775)\n",
            "Epoch: [7][560/781]\tTime  2.440 ( 2.489)\tData  0.000 ( 0.000)\tD(real) 0.4866 (0.5980)\tD(fake)1 -1.2523 (-0.5877)\tD(fake)2 -0.8502 (-0.5598)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4360 (-0.3355)\tD repr loss -0.4528 (-0.4772)\n",
            "Epoch: [7][670/781]\tTime  2.502 ( 2.487)\tData  0.000 ( 0.000)\tD(real) 0.6100 (0.5935)\tD(fake)1 -1.0686 (-0.5547)\tD(fake)2 -0.8001 (-0.5605)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3483 (-0.3314)\tD repr loss -0.4424 (-0.4759)\n",
            "Epoch: [7][780/781]\tTime  2.446 ( 2.488)\tData  0.000 ( 0.000)\tD(real) 0.2165 (0.5857)\tD(fake)1 -0.4905 (-0.5788)\tD(fake)2 -0.7318 (-0.5622)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4082 (-0.3296)\tD repr loss -0.4620 (-0.4759)\n",
            "Epoch: [7][780/781]\tTime  2.439 ( 2.487)\tData  0.000 ( 0.000)\tD(real) 0.2165 (0.5857)\tD(fake)1 -0.4905 (-0.5788)\tD(fake)2 -0.7318 (-0.5622)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4082 (-0.3296)\tD repr loss -0.4620 (-0.4759)\n",
            "Epoch: [8][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.8819 (0.7990)\tD(fake)1 -0.5137 (-0.5137)\tD(fake)2 -1.4776 (-0.8123)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3561 (-0.3561)\tD repr loss -0.4038 (-0.4648)\n",
            "Epoch: [8][120/781]\tTime  2.496 ( 2.505)\tData  0.000 ( 0.000)\tD(real) -0.4012 (0.5958)\tD(fake)1 0.1376 (-0.4003)\tD(fake)2 -1.2007 (-0.5796)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3090 (-0.3330)\tD repr loss -0.4562 (-0.4739)\n",
            "Epoch: [8][230/781]\tTime  2.497 ( 2.499)\tData  0.000 ( 0.000)\tD(real) 0.5665 (0.5971)\tD(fake)1 0.1102 (-0.3606)\tD(fake)2 -1.1869 (-0.5747)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3448 (-0.3298)\tD repr loss -0.3322 (-0.4681)\n",
            "Epoch: [8][340/781]\tTime  2.515 ( 2.495)\tData  0.000 ( 0.000)\tD(real) -0.1664 (0.5928)\tD(fake)1 -1.1243 (-0.4184)\tD(fake)2 -1.1908 (-0.5573)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3427 (-0.3344)\tD repr loss -0.4240 (-0.4732)\n",
            "Epoch: [8][450/781]\tTime  2.488 ( 2.491)\tData  0.000 ( 0.000)\tD(real) -0.2951 (0.6008)\tD(fake)1 -0.4726 (-0.4105)\tD(fake)2 -1.0494 (-0.5552)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2612 (-0.3334)\tD repr loss -0.4156 (-0.4747)\n",
            "Epoch: [8][560/781]\tTime  2.506 ( 2.492)\tData  0.000 ( 0.000)\tD(real) 0.3058 (0.6081)\tD(fake)1 -1.1754 (-0.4813)\tD(fake)2 -0.8711 (-0.5588)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3393 (-0.3333)\tD repr loss -0.4759 (-0.4732)\n",
            "Epoch: [8][670/781]\tTime  2.508 ( 2.493)\tData  0.000 ( 0.000)\tD(real) 0.9256 (0.6015)\tD(fake)1 -0.3493 (-0.4782)\tD(fake)2 -1.2681 (-0.5580)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4350 (-0.3408)\tD repr loss -0.3154 (-0.4751)\n",
            "Epoch: [8][780/781]\tTime  2.491 ( 2.493)\tData  0.000 ( 0.000)\tD(real) 0.6975 (0.6072)\tD(fake)1 -0.0864 (-0.4756)\tD(fake)2 -0.5417 (-0.5534)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3268 (-0.3419)\tD repr loss -0.4380 (-0.4760)\n",
            "Epoch: [8][780/781]\tTime  2.452 ( 2.492)\tData  0.000 ( 0.000)\tD(real) 0.6975 (0.6072)\tD(fake)1 -0.0864 (-0.4756)\tD(fake)2 -0.5417 (-0.5534)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3268 (-0.3419)\tD repr loss -0.4380 (-0.4760)\n",
            "Epoch: [9][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) -0.5245 (0.5917)\tD(fake)1 -0.7625 (-0.7625)\tD(fake)2 -1.3928 (-0.5659)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3576 (-0.3576)\tD repr loss -0.4441 (-0.4873)\n",
            "Epoch: [9][120/781]\tTime  2.502 ( 2.508)\tData  0.000 ( 0.000)\tD(real) 0.4968 (0.5815)\tD(fake)1 -1.5450 (-0.8884)\tD(fake)2 -0.7954 (-0.5507)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1737 (-0.3203)\tD repr loss -0.4121 (-0.4802)\n",
            "Epoch: [9][230/781]\tTime  2.466 ( 2.501)\tData  0.000 ( 0.000)\tD(real) -0.2069 (0.5865)\tD(fake)1 -0.4204 (-0.7524)\tD(fake)2 -1.0111 (-0.5394)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3098 (-0.3285)\tD repr loss -0.4323 (-0.4794)\n",
            "Epoch: [9][340/781]\tTime  2.534 ( 2.502)\tData  0.000 ( 0.000)\tD(real) 1.5095 (0.5762)\tD(fake)1 -0.3181 (-0.6522)\tD(fake)2 -0.0598 (-0.5429)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3526 (-0.3297)\tD repr loss -0.3660 (-0.4810)\n",
            "Epoch: [9][450/781]\tTime  2.494 ( 2.501)\tData  0.000 ( 0.000)\tD(real) -0.0870 (0.5796)\tD(fake)1 -1.1612 (-0.6438)\tD(fake)2 -0.9420 (-0.5455)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4037 (-0.3326)\tD repr loss -0.4587 (-0.4784)\n",
            "Epoch: [9][560/781]\tTime  2.506 ( 2.498)\tData  0.000 ( 0.000)\tD(real) 2.2627 (0.5852)\tD(fake)1 0.1255 (-0.6264)\tD(fake)2 1.3753 (-0.5453)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3224 (-0.3303)\tD repr loss -0.4148 (-0.4777)\n",
            "Epoch: [9][670/781]\tTime  2.531 ( 2.498)\tData  0.000 ( 0.000)\tD(real) 0.8223 (0.5871)\tD(fake)1 0.5333 (-0.6195)\tD(fake)2 -0.0691 (-0.5466)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2951 (-0.3233)\tD repr loss -0.4530 (-0.4763)\n",
            "Epoch: [9][780/781]\tTime  2.497 ( 2.497)\tData  0.000 ( 0.000)\tD(real) 0.6955 (0.5840)\tD(fake)1 -0.3512 (-0.6394)\tD(fake)2 -0.6058 (-0.5498)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2848 (-0.3237)\tD repr loss -0.5097 (-0.4761)\n",
            "Epoch: [9][780/781]\tTime  2.479 ( 2.497)\tData  0.000 ( 0.000)\tD(real) 0.6955 (0.5840)\tD(fake)1 -0.3512 (-0.6394)\tD(fake)2 -0.6058 (-0.5498)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2848 (-0.3237)\tD repr loss -0.5097 (-0.4761)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNxlmBIutPfw",
        "outputId": "ae05f4b5-d23d-4e82-92b1-b8f8fe442c58"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.7971 (0.5271)\tD(fake)1 -0.4883 (-0.4883)\tD(fake)2 -0.4179 (-0.5746)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3016 (-0.3016)\tD repr loss -0.4692 (-0.4831)\n",
            "Epoch: [0][120/781]\tTime  2.514 ( 2.515)\tData  0.000 ( 0.000)\tD(real) 1.0849 (0.6965)\tD(fake)1 0.1287 (-0.5568)\tD(fake)2 -0.3890 (-0.5669)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4790 (-0.4068)\tD repr loss -0.4842 (-0.4932)\n",
            "Epoch: [0][230/781]\tTime  2.511 ( 2.503)\tData  0.000 ( 0.000)\tD(real) 1.6528 (0.7084)\tD(fake)1 -0.5923 (-0.6260)\tD(fake)2 -0.0327 (-0.5924)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4736 (-0.4033)\tD repr loss -0.5065 (-0.4858)\n",
            "Epoch: [0][340/781]\tTime  2.505 ( 2.498)\tData  0.000 ( 0.000)\tD(real) 1.6658 (0.7309)\tD(fake)1 -0.8356 (-0.6711)\tD(fake)2 0.0366 (-0.6006)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5049 (-0.4186)\tD repr loss -0.4500 (-0.4851)\n",
            "Epoch: [0][450/781]\tTime  2.489 ( 2.494)\tData  0.000 ( 0.000)\tD(real) 1.4754 (0.7204)\tD(fake)1 -0.2568 (-0.6841)\tD(fake)2 0.0070 (-0.6107)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4697 (-0.4307)\tD repr loss -0.5069 (-0.4876)\n",
            "Epoch: [0][560/781]\tTime  2.475 ( 2.494)\tData  0.000 ( 0.000)\tD(real) 0.9856 (0.7089)\tD(fake)1 -0.3843 (-0.6417)\tD(fake)2 -0.3814 (-0.6173)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4982 (-0.4308)\tD repr loss -0.4367 (-0.4878)\n",
            "Epoch: [0][670/781]\tTime  2.521 ( 2.496)\tData  0.000 ( 0.000)\tD(real) 0.0655 (0.7135)\tD(fake)1 -1.1320 (-0.6432)\tD(fake)2 -1.0650 (-0.6125)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5062 (-0.4372)\tD repr loss -0.4848 (-0.4884)\n",
            "Epoch: [0][780/781]\tTime  2.494 ( 2.494)\tData  0.000 ( 0.000)\tD(real) 0.6226 (0.7082)\tD(fake)1 -1.2973 (-0.6614)\tD(fake)2 -0.8654 (-0.6166)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5027 (-0.4440)\tD repr loss -0.3932 (-0.4905)\n",
            "Epoch: [0][780/781]\tTime  2.488 ( 2.494)\tData  0.000 ( 0.000)\tD(real) 0.6226 (0.7082)\tD(fake)1 -1.2973 (-0.6614)\tD(fake)2 -0.8654 (-0.6166)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5027 (-0.4440)\tD repr loss -0.3932 (-0.4905)\n",
            "Epoch: [1][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.5887 (0.8788)\tD(fake)1 -0.5278 (-0.5278)\tD(fake)2 -0.1045 (-0.5390)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3735 (-0.3735)\tD repr loss -0.5253 (-0.5196)\n",
            "Epoch: [1][120/781]\tTime  2.472 ( 2.491)\tData  0.000 ( 0.000)\tD(real) 1.0258 (0.7511)\tD(fake)1 -0.7800 (-0.6328)\tD(fake)2 -0.2498 (-0.6745)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5315 (-0.5056)\tD repr loss -0.4826 (-0.5090)\n",
            "Epoch: [1][230/781]\tTime  2.512 ( 2.494)\tData  0.000 ( 0.000)\tD(real) -0.2491 (0.7548)\tD(fake)1 -0.8653 (-0.7354)\tD(fake)2 -1.2902 (-0.6624)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5015 (-0.4965)\tD repr loss -0.4788 (-0.5016)\n",
            "Epoch: [1][340/781]\tTime  2.438 ( 2.487)\tData  0.000 ( 0.000)\tD(real) 0.0679 (0.7423)\tD(fake)1 -1.4752 (-0.6320)\tD(fake)2 -1.2412 (-0.6656)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5754 (-0.4987)\tD repr loss -0.4612 (-0.4990)\n",
            "Epoch: [1][450/781]\tTime  2.479 ( 2.487)\tData  0.000 ( 0.000)\tD(real) -0.1413 (0.7465)\tD(fake)1 -1.1805 (-0.6512)\tD(fake)2 -1.0972 (-0.6545)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4667 (-0.5018)\tD repr loss -0.4849 (-0.4986)\n",
            "Epoch: [1][560/781]\tTime  2.489 ( 2.484)\tData  0.000 ( 0.000)\tD(real) -0.0835 (0.7417)\tD(fake)1 -1.3196 (-0.6660)\tD(fake)2 -1.0137 (-0.6549)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4888 (-0.4989)\tD repr loss -0.4930 (-0.5020)\n",
            "Epoch: [1][670/781]\tTime  2.469 ( 2.485)\tData  0.000 ( 0.000)\tD(real) 0.4701 (0.7455)\tD(fake)1 -1.1878 (-0.6960)\tD(fake)2 -0.8844 (-0.6540)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5612 (-0.4907)\tD repr loss -0.4791 (-0.5018)\n",
            "Epoch: [1][780/781]\tTime  2.531 ( 2.486)\tData  0.000 ( 0.000)\tD(real) 0.7772 (0.7546)\tD(fake)1 -1.1881 (-0.6586)\tD(fake)2 -0.6913 (-0.6561)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3954 (-0.4903)\tD repr loss -0.4762 (-0.5015)\n",
            "Epoch: [1][780/781]\tTime  2.458 ( 2.486)\tData  0.000 ( 0.000)\tD(real) 0.7772 (0.7546)\tD(fake)1 -1.1881 (-0.6586)\tD(fake)2 -0.6913 (-0.6561)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3954 (-0.4903)\tD repr loss -0.4762 (-0.5015)\n",
            "Epoch: [2][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.9692 (0.9214)\tD(fake)1 -0.5951 (-0.5951)\tD(fake)2 -0.0985 (-0.6685)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4400 (-0.4400)\tD repr loss -0.3968 (-0.4976)\n",
            "Epoch: [2][120/781]\tTime  2.471 ( 2.489)\tData  0.000 ( 0.000)\tD(real) -0.2213 (0.7627)\tD(fake)1 -1.6693 (-0.6914)\tD(fake)2 -1.2969 (-0.6811)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1259 (-0.4554)\tD repr loss -0.4521 (-0.5087)\n",
            "Epoch: [2][230/781]\tTime  2.449 ( 2.484)\tData  0.000 ( 0.000)\tD(real) 1.1546 (0.7772)\tD(fake)1 0.0717 (-0.6291)\tD(fake)2 -0.3438 (-0.6658)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4848 (-0.4684)\tD repr loss -0.4985 (-0.5075)\n",
            "Epoch: [2][340/781]\tTime  2.505 ( 2.482)\tData  0.000 ( 0.000)\tD(real) -0.5146 (0.7677)\tD(fake)1 -0.3311 (-0.6515)\tD(fake)2 -1.4594 (-0.6640)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3967 (-0.4795)\tD repr loss -0.4890 (-0.5064)\n",
            "Epoch: [2][450/781]\tTime  2.510 ( 2.479)\tData  0.000 ( 0.000)\tD(real) 1.6408 (0.7651)\tD(fake)1 -0.6363 (-0.6136)\tD(fake)2 0.3083 (-0.6584)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5710 (-0.4876)\tD repr loss -0.5406 (-0.5072)\n",
            "Epoch: [2][560/781]\tTime  2.445 ( 2.476)\tData  0.000 ( 0.000)\tD(real) 1.4852 (0.7681)\tD(fake)1 0.0088 (-0.6337)\tD(fake)2 -0.0624 (-0.6599)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4826 (-0.4918)\tD repr loss -0.5250 (-0.5084)\n",
            "Epoch: [2][670/781]\tTime  2.501 ( 2.480)\tData  0.000 ( 0.000)\tD(real) 1.5848 (0.7655)\tD(fake)1 -0.3483 (-0.6561)\tD(fake)2 -0.0402 (-0.6620)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5169 (-0.4886)\tD repr loss -0.5004 (-0.5091)\n",
            "Epoch: [2][780/781]\tTime  2.508 ( 2.479)\tData  0.000 ( 0.000)\tD(real) 2.0008 (0.7757)\tD(fake)1 -0.1868 (-0.6683)\tD(fake)2 0.1168 (-0.6654)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6139 (-0.4850)\tD repr loss -0.4833 (-0.5084)\n",
            "Epoch: [2][780/781]\tTime  2.473 ( 2.479)\tData  0.000 ( 0.000)\tD(real) 2.0008 (0.7757)\tD(fake)1 -0.1868 (-0.6683)\tD(fake)2 0.1168 (-0.6654)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6139 (-0.4850)\tD repr loss -0.4833 (-0.5084)\n",
            "Epoch: [3][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.4686 (0.6600)\tD(fake)1 -1.3644 (-1.3644)\tD(fake)2 -1.0486 (-0.9102)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5309 (-0.5309)\tD repr loss -0.4707 (-0.5359)\n",
            "Epoch: [3][120/781]\tTime  2.443 ( 2.494)\tData  0.000 ( 0.000)\tD(real) 0.4815 (0.7870)\tD(fake)1 -1.1703 (-0.7901)\tD(fake)2 -1.0290 (-0.6985)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5250 (-0.5208)\tD repr loss -0.4494 (-0.5068)\n",
            "Epoch: [3][230/781]\tTime  2.462 ( 2.487)\tData  0.000 ( 0.000)\tD(real) 1.2321 (0.8206)\tD(fake)1 -0.2764 (-0.7475)\tD(fake)2 -0.1479 (-0.6830)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5504 (-0.5085)\tD repr loss -0.4810 (-0.5120)\n",
            "Epoch: [3][340/781]\tTime  2.453 ( 2.487)\tData  0.000 ( 0.000)\tD(real) -0.0203 (0.8274)\tD(fake)1 -1.1842 (-0.7874)\tD(fake)2 -1.2124 (-0.6951)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4944 (-0.5151)\tD repr loss -0.4614 (-0.5122)\n",
            "Epoch: [3][450/781]\tTime  2.505 ( 2.485)\tData  0.000 ( 0.000)\tD(real) -0.5564 (0.8200)\tD(fake)1 -0.3354 (-0.6960)\tD(fake)2 -1.4031 (-0.6856)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5352 (-0.5118)\tD repr loss -0.4858 (-0.5087)\n",
            "Epoch: [3][560/781]\tTime  2.462 ( 2.485)\tData  0.000 ( 0.000)\tD(real) 0.0001 (0.8076)\tD(fake)1 -1.0497 (-0.7143)\tD(fake)2 -1.1920 (-0.6886)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5516 (-0.5033)\tD repr loss -0.4634 (-0.5090)\n",
            "Epoch: [3][670/781]\tTime  2.483 ( 2.486)\tData  0.000 ( 0.000)\tD(real) 2.7158 (0.8194)\tD(fake)1 -0.8003 (-0.7270)\tD(fake)2 1.0018 (-0.6879)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5470 (-0.5032)\tD repr loss -0.4823 (-0.5079)\n",
            "Epoch: [3][780/781]\tTime  2.511 ( 2.488)\tData  0.000 ( 0.000)\tD(real) 2.2402 (0.8175)\tD(fake)1 -0.3561 (-0.7137)\tD(fake)2 0.1023 (-0.6878)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5479 (-0.5009)\tD repr loss -0.5043 (-0.5086)\n",
            "Epoch: [3][780/781]\tTime  2.474 ( 2.488)\tData  0.000 ( 0.000)\tD(real) 2.2402 (0.8175)\tD(fake)1 -0.3561 (-0.7137)\tD(fake)2 0.1023 (-0.6878)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5479 (-0.5009)\tD repr loss -0.5043 (-0.5086)\n",
            "Epoch: [4][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) -0.1900 (0.5825)\tD(fake)1 -1.2791 (-1.2791)\tD(fake)2 -1.3689 (-0.8757)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5046 (-0.5046)\tD repr loss -0.3915 (-0.4984)\n",
            "Epoch: [4][120/781]\tTime  2.495 ( 2.508)\tData  0.000 ( 0.000)\tD(real) 0.2766 (0.8179)\tD(fake)1 -0.3373 (-0.7448)\tD(fake)2 -1.2322 (-0.7262)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4861 (-0.4826)\tD repr loss -0.5076 (-0.5052)\n",
            "Epoch: [4][230/781]\tTime  2.501 ( 2.504)\tData  0.000 ( 0.000)\tD(real) 1.5097 (0.8224)\tD(fake)1 -0.1793 (-0.6995)\tD(fake)2 -0.3588 (-0.7097)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5860 (-0.4847)\tD repr loss -0.4777 (-0.5089)\n",
            "Epoch: [4][340/781]\tTime  2.471 ( 2.502)\tData  0.000 ( 0.000)\tD(real) 1.5039 (0.8483)\tD(fake)1 -0.4908 (-0.7119)\tD(fake)2 -0.4235 (-0.7086)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4839 (-0.5071)\tD repr loss -0.4679 (-0.5105)\n",
            "Epoch: [4][450/781]\tTime  2.513 ( 2.502)\tData  0.000 ( 0.000)\tD(real) 0.2821 (0.8392)\tD(fake)1 -1.1325 (-0.7218)\tD(fake)2 -1.7674 (-0.7089)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6154 (-0.5124)\tD repr loss -0.3278 (-0.5133)\n",
            "Epoch: [4][560/781]\tTime  2.474 ( 2.500)\tData  0.000 ( 0.000)\tD(real) 1.8015 (0.8479)\tD(fake)1 -0.2986 (-0.6882)\tD(fake)2 -0.0212 (-0.7013)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5753 (-0.5137)\tD repr loss -0.4506 (-0.5135)\n",
            "Epoch: [4][670/781]\tTime  2.493 ( 2.497)\tData  0.000 ( 0.000)\tD(real) 1.3002 (0.8509)\tD(fake)1 -0.6605 (-0.6327)\tD(fake)2 -0.3165 (-0.6996)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4378 (-0.5181)\tD repr loss -0.4443 (-0.5116)\n",
            "Epoch: [4][780/781]\tTime  2.499 ( 2.497)\tData  0.000 ( 0.000)\tD(real) 2.0988 (0.8500)\tD(fake)1 -0.7005 (-0.6721)\tD(fake)2 0.0848 (-0.7021)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4412 (-0.5162)\tD repr loss -0.4564 (-0.5132)\n",
            "Epoch: [4][780/781]\tTime  2.461 ( 2.497)\tData  0.000 ( 0.000)\tD(real) 2.0988 (0.8500)\tD(fake)1 -0.7005 (-0.6721)\tD(fake)2 0.0848 (-0.7021)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4412 (-0.5162)\tD repr loss -0.4564 (-0.5132)\n",
            "Epoch: [5][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) -0.0342 (0.6490)\tD(fake)1 -1.2387 (-1.2387)\tD(fake)2 -1.3695 (-0.8465)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1825 (-0.1825)\tD repr loss -0.4846 (-0.4356)\n",
            "Epoch: [5][120/781]\tTime  2.445 ( 2.501)\tData  0.000 ( 0.000)\tD(real) 1.1426 (0.8210)\tD(fake)1 -0.8698 (-0.8751)\tD(fake)2 -0.4984 (-0.7004)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3158 (-0.4912)\tD repr loss -0.5694 (-0.5158)\n",
            "Epoch: [5][230/781]\tTime  2.506 ( 2.499)\tData  0.000 ( 0.000)\tD(real) 1.9991 (0.8436)\tD(fake)1 -0.3509 (-0.7019)\tD(fake)2 0.1782 (-0.6993)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5245 (-0.5068)\tD repr loss -0.4621 (-0.5134)\n",
            "Epoch: [5][340/781]\tTime  2.472 ( 2.495)\tData  0.000 ( 0.000)\tD(real) 1.5663 (0.8418)\tD(fake)1 -0.3715 (-0.7566)\tD(fake)2 -0.2566 (-0.7040)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4904 (-0.5111)\tD repr loss -0.4681 (-0.5147)\n",
            "Epoch: [5][450/781]\tTime  2.486 ( 2.493)\tData  0.000 ( 0.000)\tD(real) 1.5585 (0.8347)\tD(fake)1 -0.2383 (-0.7598)\tD(fake)2 -0.3234 (-0.7112)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3929 (-0.5009)\tD repr loss -0.4261 (-0.5148)\n",
            "Epoch: [5][560/781]\tTime  2.480 ( 2.491)\tData  0.000 ( 0.000)\tD(real) 1.2835 (0.8420)\tD(fake)1 -0.1923 (-0.7361)\tD(fake)2 -0.6661 (-0.7138)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5247 (-0.4969)\tD repr loss -0.5128 (-0.5134)\n",
            "Epoch: [5][670/781]\tTime  2.502 ( 2.489)\tData  0.000 ( 0.000)\tD(real) 0.0745 (0.8521)\tD(fake)1 -1.0093 (-0.7317)\tD(fake)2 -1.0749 (-0.7134)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1296 (-0.4958)\tD repr loss -0.5445 (-0.5133)\n",
            "Epoch: [5][780/781]\tTime  2.479 ( 2.488)\tData  0.000 ( 0.000)\tD(real) -0.3178 (0.8533)\tD(fake)1 -0.9796 (-0.7400)\tD(fake)2 -1.5440 (-0.7171)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4751 (-0.5034)\tD repr loss -0.4694 (-0.5161)\n",
            "Epoch: [5][780/781]\tTime  2.453 ( 2.487)\tData  0.000 ( 0.000)\tD(real) -0.3178 (0.8533)\tD(fake)1 -0.9796 (-0.7400)\tD(fake)2 -1.5440 (-0.7171)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4751 (-0.5034)\tD repr loss -0.4694 (-0.5161)\n",
            "Epoch: [6][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.1211 (0.8036)\tD(fake)1 -0.5400 (-0.5400)\tD(fake)2 -0.4086 (-0.6775)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5761 (-0.5761)\tD repr loss -0.4759 (-0.5329)\n",
            "Epoch: [6][120/781]\tTime  2.436 ( 2.508)\tData  0.000 ( 0.000)\tD(real) 1.0217 (0.8898)\tD(fake)1 1.0637 (-0.5445)\tD(fake)2 -0.6223 (-0.6965)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5394 (-0.5389)\tD repr loss -0.4586 (-0.5227)\n",
            "Epoch: [6][230/781]\tTime  2.496 ( 2.501)\tData  0.000 ( 0.000)\tD(real) 0.4749 (0.8882)\tD(fake)1 -1.4474 (-0.6406)\tD(fake)2 -0.9312 (-0.7086)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5038 (-0.5425)\tD repr loss -0.5091 (-0.5193)\n",
            "Epoch: [6][340/781]\tTime  2.508 ( 2.500)\tData  0.000 ( 0.000)\tD(real) 0.1421 (0.9056)\tD(fake)1 -1.2362 (-0.6720)\tD(fake)2 -1.2303 (-0.7119)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4916 (-0.5421)\tD repr loss -0.5064 (-0.5177)\n",
            "Epoch: [6][450/781]\tTime  2.494 ( 2.497)\tData  0.000 ( 0.000)\tD(real) 2.6899 (0.9036)\tD(fake)1 -1.2410 (-0.7020)\tD(fake)2 0.9573 (-0.7032)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4155 (-0.5430)\tD repr loss -0.4725 (-0.5184)\n",
            "Epoch: [6][560/781]\tTime  2.465 ( 2.494)\tData  0.000 ( 0.000)\tD(real) -0.2039 (0.8892)\tD(fake)1 -0.7961 (-0.6798)\tD(fake)2 -1.4314 (-0.7105)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5166 (-0.5406)\tD repr loss -0.4658 (-0.5187)\n",
            "Epoch: [6][670/781]\tTime  2.507 ( 2.494)\tData  0.000 ( 0.000)\tD(real) 1.8556 (0.8929)\tD(fake)1 0.0400 (-0.6713)\tD(fake)2 -0.1351 (-0.7064)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6263 (-0.5371)\tD repr loss -0.4283 (-0.5177)\n",
            "Epoch: [6][780/781]\tTime  2.440 ( 2.494)\tData  0.000 ( 0.000)\tD(real) 0.9945 (0.8862)\tD(fake)1 -0.0419 (-0.6768)\tD(fake)2 -0.7396 (-0.7025)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4887 (-0.5346)\tD repr loss -0.5210 (-0.5176)\n",
            "Epoch: [6][780/781]\tTime  2.476 ( 2.493)\tData  0.000 ( 0.000)\tD(real) 0.9945 (0.8862)\tD(fake)1 -0.0419 (-0.6768)\tD(fake)2 -0.7396 (-0.7025)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4887 (-0.5346)\tD repr loss -0.5210 (-0.5176)\n",
            "Epoch: [7][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.0729 (0.7837)\tD(fake)1 -0.9581 (-0.9581)\tD(fake)2 -0.6169 (-0.7188)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5653 (-0.5653)\tD repr loss -0.4732 (-0.5445)\n",
            "Epoch: [7][120/781]\tTime  2.475 ( 2.505)\tData  0.000 ( 0.000)\tD(real) 1.1001 (0.8575)\tD(fake)1 -0.7453 (-0.9326)\tD(fake)2 -0.7194 (-0.7112)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5191 (-0.5109)\tD repr loss -0.5094 (-0.5228)\n",
            "Epoch: [7][230/781]\tTime  2.450 ( 2.493)\tData  0.000 ( 0.000)\tD(real) 1.0901 (0.8899)\tD(fake)1 0.6085 (-0.7060)\tD(fake)2 -0.7025 (-0.7114)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4738 (-0.4999)\tD repr loss -0.5406 (-0.5166)\n",
            "Epoch: [7][340/781]\tTime  2.495 ( 2.486)\tData  0.000 ( 0.000)\tD(real) 0.7397 (0.8992)\tD(fake)1 -1.0635 (-0.7534)\tD(fake)2 -0.9026 (-0.7170)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5431 (-0.5137)\tD repr loss -0.5096 (-0.5157)\n",
            "Epoch: [7][450/781]\tTime  2.488 ( 2.484)\tData  0.000 ( 0.000)\tD(real) 1.5768 (0.8896)\tD(fake)1 0.4251 (-0.7287)\tD(fake)2 -0.1664 (-0.7191)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5546 (-0.5189)\tD repr loss -0.5167 (-0.5188)\n",
            "Epoch: [7][560/781]\tTime  2.461 ( 2.484)\tData  0.000 ( 0.000)\tD(real) 0.7712 (0.8770)\tD(fake)1 0.0158 (-0.7263)\tD(fake)2 -0.5539 (-0.7212)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4660 (-0.5100)\tD repr loss -0.4992 (-0.5199)\n",
            "Epoch: [7][670/781]\tTime  2.480 ( 2.484)\tData  0.000 ( 0.000)\tD(real) 1.1035 (0.8726)\tD(fake)1 -1.2020 (-0.7460)\tD(fake)2 -0.6597 (-0.7207)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4845 (-0.5089)\tD repr loss -0.4355 (-0.5198)\n",
            "Epoch: [7][780/781]\tTime  2.460 ( 2.483)\tData  0.000 ( 0.000)\tD(real) 1.7013 (0.8761)\tD(fake)1 -0.6510 (-0.7705)\tD(fake)2 -0.0920 (-0.7193)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4599 (-0.5109)\tD repr loss -0.5189 (-0.5192)\n",
            "Epoch: [7][780/781]\tTime  2.470 ( 2.483)\tData  0.000 ( 0.000)\tD(real) 1.7013 (0.8761)\tD(fake)1 -0.6510 (-0.7705)\tD(fake)2 -0.0920 (-0.7193)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4599 (-0.5109)\tD repr loss -0.5189 (-0.5192)\n",
            "Epoch: [8][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) -0.3223 (0.5613)\tD(fake)1 -1.2747 (-1.2747)\tD(fake)2 -1.5331 (-0.8652)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5110 (-0.5110)\tD repr loss -0.4149 (-0.5059)\n",
            "Epoch: [8][120/781]\tTime  2.507 ( 2.511)\tData  0.000 ( 0.000)\tD(real) 1.4417 (0.8532)\tD(fake)1 -0.0102 (-0.5964)\tD(fake)2 -0.0703 (-0.7118)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5717 (-0.5456)\tD repr loss -0.5146 (-0.5239)\n",
            "Epoch: [8][230/781]\tTime  2.498 ( 2.486)\tData  0.000 ( 0.000)\tD(real) 0.9070 (0.8842)\tD(fake)1 -1.4874 (-0.7800)\tD(fake)2 -0.6495 (-0.7109)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5049 (-0.5394)\tD repr loss -0.5340 (-0.5167)\n",
            "Epoch: [8][340/781]\tTime  2.496 ( 2.484)\tData  0.000 ( 0.000)\tD(real) 1.6913 (0.8922)\tD(fake)1 -0.4870 (-0.7961)\tD(fake)2 -0.2223 (-0.7172)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4628 (-0.5339)\tD repr loss -0.5272 (-0.5193)\n",
            "Epoch: [8][450/781]\tTime  2.509 ( 2.482)\tData  0.000 ( 0.000)\tD(real) 0.7640 (0.8906)\tD(fake)1 -1.3681 (-0.7874)\tD(fake)2 -0.7630 (-0.7278)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5671 (-0.5338)\tD repr loss -0.5320 (-0.5196)\n",
            "Epoch: [8][560/781]\tTime  2.492 ( 2.481)\tData  0.000 ( 0.000)\tD(real) 1.0924 (0.8865)\tD(fake)1 0.0142 (-0.7410)\tD(fake)2 -0.7555 (-0.7315)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5465 (-0.5335)\tD repr loss -0.4671 (-0.5209)\n",
            "Epoch: [8][670/781]\tTime  2.452 ( 2.484)\tData  0.000 ( 0.000)\tD(real) -0.2193 (0.8887)\tD(fake)1 -0.1190 (-0.7628)\tD(fake)2 -1.3010 (-0.7291)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5611 (-0.5300)\tD repr loss -0.5151 (-0.5205)\n",
            "Epoch: [8][780/781]\tTime  2.488 ( 2.485)\tData  0.000 ( 0.000)\tD(real) 1.9436 (0.8950)\tD(fake)1 -0.4985 (-0.7592)\tD(fake)2 -0.1620 (-0.7298)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4946 (-0.5269)\tD repr loss -0.4779 (-0.5212)\n",
            "Epoch: [8][780/781]\tTime  2.473 ( 2.485)\tData  0.000 ( 0.000)\tD(real) 1.9436 (0.8950)\tD(fake)1 -0.4985 (-0.7592)\tD(fake)2 -0.1620 (-0.7298)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4946 (-0.5269)\tD repr loss -0.4779 (-0.5212)\n",
            "Epoch: [9][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 2.5905 (1.3191)\tD(fake)1 -1.2659 (-1.2659)\tD(fake)2 0.4132 (-0.6809)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5716 (-0.5716)\tD repr loss -0.4649 (-0.5044)\n",
            "Epoch: [9][120/781]\tTime  2.503 ( 2.512)\tData  0.000 ( 0.000)\tD(real) 1.9702 (0.9437)\tD(fake)1 -0.4368 (-0.8666)\tD(fake)2 -0.0492 (-0.7357)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5213 (-0.5221)\tD repr loss -0.4512 (-0.5149)\n",
            "Epoch: [9][230/781]\tTime  2.449 ( 2.496)\tData  0.000 ( 0.000)\tD(real) 1.4853 (0.9282)\tD(fake)1 0.0716 (-0.7725)\tD(fake)2 -0.3799 (-0.7385)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5333 (-0.5295)\tD repr loss -0.4816 (-0.5202)\n",
            "Epoch: [9][340/781]\tTime  2.508 ( 2.494)\tData  0.000 ( 0.000)\tD(real) 1.7562 (0.9096)\tD(fake)1 -0.7238 (-0.8097)\tD(fake)2 -0.1217 (-0.7392)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6205 (-0.5164)\tD repr loss -0.4623 (-0.5181)\n",
            "Epoch: [9][450/781]\tTime  2.506 ( 2.491)\tData  0.000 ( 0.000)\tD(real) 1.0424 (0.9078)\tD(fake)1 -0.3665 (-0.8146)\tD(fake)2 -0.4393 (-0.7362)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5354 (-0.5131)\tD repr loss -0.4596 (-0.5198)\n",
            "Epoch: [9][560/781]\tTime  2.503 ( 2.491)\tData  0.000 ( 0.000)\tD(real) 0.9783 (0.9092)\tD(fake)1 0.2774 (-0.8054)\tD(fake)2 -0.6890 (-0.7371)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5550 (-0.5143)\tD repr loss -0.5479 (-0.5197)\n",
            "Epoch: [9][670/781]\tTime  2.469 ( 2.491)\tData  0.000 ( 0.000)\tD(real) 1.4897 (0.9036)\tD(fake)1 -0.0974 (-0.7967)\tD(fake)2 -0.2806 (-0.7386)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5041 (-0.5176)\tD repr loss -0.4381 (-0.5215)\n",
            "Epoch: [9][780/781]\tTime  2.485 ( 2.489)\tData  0.000 ( 0.000)\tD(real) 0.4419 (0.9032)\tD(fake)1 -1.5003 (-0.8241)\tD(fake)2 -1.1162 (-0.7373)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4918 (-0.5172)\tD repr loss -0.4790 (-0.5219)\n",
            "Epoch: [9][780/781]\tTime  2.478 ( 2.489)\tData  0.000 ( 0.000)\tD(real) 0.4419 (0.9032)\tD(fake)1 -1.5003 (-0.8241)\tD(fake)2 -1.1162 (-0.7373)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4918 (-0.5172)\tD repr loss -0.4790 (-0.5219)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iepY_Go7tf7Y",
        "outputId": "517db310-bfd5-4cc0-ebda-204da3cc242f"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.0876 (0.9184)\tD(fake)1 -0.2512 (-0.2512)\tD(fake)2 -0.7887 (-0.7016)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6195 (-0.6195)\tD repr loss -0.5407 (-0.5573)\n",
            "Epoch: [0][120/781]\tTime  2.507 ( 2.506)\tData  0.000 ( 0.000)\tD(real) -0.2538 (0.9355)\tD(fake)1 -0.8608 (-0.8388)\tD(fake)2 -1.4774 (-0.7330)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5387 (-0.5732)\tD repr loss -0.4969 (-0.5332)\n",
            "Epoch: [0][230/781]\tTime  2.501 ( 2.493)\tData  0.000 ( 0.000)\tD(real) 1.4325 (0.9340)\tD(fake)1 -0.0954 (-0.8337)\tD(fake)2 -0.4479 (-0.7454)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5877 (-0.5740)\tD repr loss -0.4878 (-0.5348)\n",
            "Epoch: [0][340/781]\tTime  2.509 ( 2.490)\tData  0.000 ( 0.000)\tD(real) 0.1130 (0.9322)\tD(fake)1 -1.0674 (-0.7952)\tD(fake)2 -1.4172 (-0.7493)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5452 (-0.5394)\tD repr loss -0.4543 (-0.5259)\n",
            "Epoch: [0][450/781]\tTime  2.449 ( 2.489)\tData  0.000 ( 0.000)\tD(real) 1.1951 (0.9343)\tD(fake)1 -0.3291 (-0.7899)\tD(fake)2 -0.5418 (-0.7446)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5484 (-0.5385)\tD repr loss -0.5080 (-0.5247)\n",
            "Epoch: [0][560/781]\tTime  2.561 ( 2.492)\tData  0.000 ( 0.000)\tD(real) -0.1235 (0.9352)\tD(fake)1 -0.1283 (-0.7473)\tD(fake)2 -1.3068 (-0.7422)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4737 (-0.5314)\tD repr loss -0.5148 (-0.5240)\n",
            "Epoch: [0][670/781]\tTime  2.453 ( 2.493)\tData  0.000 ( 0.000)\tD(real) -0.0993 (0.9371)\tD(fake)1 -1.2096 (-0.7743)\tD(fake)2 -1.1926 (-0.7453)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4199 (-0.5308)\tD repr loss -0.3780 (-0.5228)\n",
            "Epoch: [0][780/781]\tTime  2.510 ( 2.494)\tData  0.000 ( 0.000)\tD(real) 1.1468 (0.9347)\tD(fake)1 -0.8097 (-0.7811)\tD(fake)2 -0.8222 (-0.7430)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2368 (-0.5262)\tD repr loss -0.4582 (-0.5218)\n",
            "Epoch: [0][780/781]\tTime  2.474 ( 2.493)\tData  0.000 ( 0.000)\tD(real) 1.1468 (0.9347)\tD(fake)1 -0.8097 (-0.7811)\tD(fake)2 -0.8222 (-0.7430)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2368 (-0.5262)\tD repr loss -0.4582 (-0.5218)\n",
            "Epoch: [1][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.8503 (1.1615)\tD(fake)1 -0.6038 (-0.6038)\tD(fake)2 -0.2025 (-0.8110)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6044 (-0.6044)\tD repr loss -0.4433 (-0.5085)\n",
            "Epoch: [1][120/781]\tTime  2.511 ( 2.522)\tData  0.000 ( 0.000)\tD(real) 1.9417 (0.9828)\tD(fake)1 -0.5139 (-0.9996)\tD(fake)2 -0.1929 (-0.7608)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1374 (-0.4948)\tD repr loss -0.4782 (-0.5171)\n",
            "Epoch: [1][230/781]\tTime  2.464 ( 2.512)\tData  0.000 ( 0.000)\tD(real) 0.1268 (0.9870)\tD(fake)1 -1.3038 (-0.9460)\tD(fake)2 -1.2503 (-0.7563)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6138 (-0.4737)\tD repr loss -0.4868 (-0.5153)\n",
            "Epoch: [1][340/781]\tTime  2.490 ( 2.502)\tData  0.000 ( 0.000)\tD(real) -0.1243 (0.9677)\tD(fake)1 -0.6704 (-0.8687)\tD(fake)2 -1.3449 (-0.7541)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4654 (-0.4846)\tD repr loss -0.5142 (-0.5181)\n",
            "Epoch: [1][450/781]\tTime  2.500 ( 2.500)\tData  0.000 ( 0.000)\tD(real) 2.3085 (0.9787)\tD(fake)1 -0.9835 (-0.8197)\tD(fake)2 0.2414 (-0.7459)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5460 (-0.4952)\tD repr loss -0.4778 (-0.5190)\n",
            "Epoch: [1][560/781]\tTime  2.508 ( 2.506)\tData  0.000 ( 0.000)\tD(real) 2.0564 (0.9612)\tD(fake)1 -1.5662 (-0.8423)\tD(fake)2 -0.0836 (-0.7473)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5414 (-0.5093)\tD repr loss -0.5027 (-0.5217)\n",
            "Epoch: [1][670/781]\tTime  2.508 ( 2.507)\tData  0.000 ( 0.000)\tD(real) 1.6581 (0.9641)\tD(fake)1 -1.5114 (-0.8185)\tD(fake)2 -0.6028 (-0.7482)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5276 (-0.5128)\tD repr loss -0.4738 (-0.5198)\n",
            "Epoch: [1][780/781]\tTime  2.500 ( 2.505)\tData  0.000 ( 0.000)\tD(real) -0.3811 (0.9548)\tD(fake)1 -1.2909 (-0.8031)\tD(fake)2 -1.4357 (-0.7528)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5424 (-0.5155)\tD repr loss -0.4797 (-0.5195)\n",
            "Epoch: [1][780/781]\tTime  2.479 ( 2.505)\tData  0.000 ( 0.000)\tD(real) -0.3811 (0.9548)\tD(fake)1 -1.2909 (-0.8031)\tD(fake)2 -1.4357 (-0.7528)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5424 (-0.5155)\tD repr loss -0.4797 (-0.5195)\n",
            "Epoch: [2][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.9175 (1.1202)\tD(fake)1 -0.4306 (-0.4306)\tD(fake)2 -0.1434 (-0.6544)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2153 (-0.2153)\tD repr loss -0.4467 (-0.4582)\n",
            "Epoch: [2][120/781]\tTime  2.496 ( 2.505)\tData  0.000 ( 0.000)\tD(real) 1.0904 (0.9563)\tD(fake)1 -0.5039 (-0.6803)\tD(fake)2 -0.7185 (-0.7593)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5291 (-0.4980)\tD repr loss -0.5117 (-0.5226)\n",
            "Epoch: [2][230/781]\tTime  2.512 ( 2.501)\tData  0.000 ( 0.000)\tD(real) 1.0351 (0.9293)\tD(fake)1 -0.5481 (-0.6133)\tD(fake)2 -0.7744 (-0.7484)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5443 (-0.5086)\tD repr loss -0.4941 (-0.5272)\n",
            "Epoch: [2][340/781]\tTime  2.513 ( 2.499)\tData  0.000 ( 0.000)\tD(real) 0.8926 (0.9245)\tD(fake)1 -0.4468 (-0.7000)\tD(fake)2 -0.7416 (-0.7561)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5449 (-0.5197)\tD repr loss -0.4584 (-0.5286)\n",
            "Epoch: [2][450/781]\tTime  2.497 ( 2.498)\tData  0.000 ( 0.000)\tD(real) 0.2936 (0.9328)\tD(fake)1 -1.1784 (-0.6524)\tD(fake)2 -1.2864 (-0.7534)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4650 (-0.5153)\tD repr loss -0.4418 (-0.5248)\n",
            "Epoch: [2][560/781]\tTime  2.464 ( 2.492)\tData  0.000 ( 0.000)\tD(real) 1.0174 (0.9279)\tD(fake)1 -0.5282 (-0.6695)\tD(fake)2 -0.6169 (-0.7549)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5864 (-0.5121)\tD repr loss -0.4882 (-0.5254)\n",
            "Epoch: [2][670/781]\tTime  2.481 ( 2.491)\tData  0.000 ( 0.000)\tD(real) 0.6119 (0.9283)\tD(fake)1 -1.2799 (-0.6869)\tD(fake)2 -0.8819 (-0.7553)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4831 (-0.5157)\tD repr loss -0.5424 (-0.5246)\n",
            "Epoch: [2][780/781]\tTime  2.526 ( 2.494)\tData  0.000 ( 0.000)\tD(real) -0.4540 (0.9278)\tD(fake)1 -1.2257 (-0.7085)\tD(fake)2 -1.4225 (-0.7529)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5195 (-0.5102)\tD repr loss -0.5511 (-0.5225)\n",
            "Epoch: [2][780/781]\tTime  2.479 ( 2.493)\tData  0.000 ( 0.000)\tD(real) -0.4540 (0.9278)\tD(fake)1 -1.2257 (-0.7085)\tD(fake)2 -1.4225 (-0.7529)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5195 (-0.5102)\tD repr loss -0.5511 (-0.5225)\n",
            "Epoch: [3][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) -0.3080 (0.8866)\tD(fake)1 -0.4685 (-0.4685)\tD(fake)2 -1.6216 (-0.7861)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5192 (-0.5192)\tD repr loss -0.4404 (-0.4834)\n",
            "Epoch: [3][120/781]\tTime  2.508 ( 2.509)\tData  0.000 ( 0.000)\tD(real) 1.8130 (0.9200)\tD(fake)1 -0.4675 (-0.7884)\tD(fake)2 0.0115 (-0.7362)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4631 (-0.5134)\tD repr loss -0.4777 (-0.5226)\n",
            "Epoch: [3][230/781]\tTime  2.504 ( 2.502)\tData  0.000 ( 0.000)\tD(real) 0.1272 (0.9400)\tD(fake)1 -0.9142 (-0.8428)\tD(fake)2 -1.4213 (-0.7505)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5593 (-0.5108)\tD repr loss -0.4879 (-0.5208)\n",
            "Epoch: [3][340/781]\tTime  2.505 ( 2.502)\tData  0.000 ( 0.000)\tD(real) 0.1740 (0.9465)\tD(fake)1 -0.7390 (-0.8509)\tD(fake)2 -1.2938 (-0.7469)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5812 (-0.5278)\tD repr loss -0.4798 (-0.5220)\n",
            "Epoch: [3][450/781]\tTime  2.506 ( 2.499)\tData  0.000 ( 0.000)\tD(real) 1.4561 (0.9426)\tD(fake)1 -0.3428 (-0.8314)\tD(fake)2 -0.3382 (-0.7421)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5939 (-0.5325)\tD repr loss -0.5145 (-0.5239)\n",
            "Epoch: [3][560/781]\tTime  2.488 ( 2.497)\tData  0.000 ( 0.000)\tD(real) -0.1511 (0.9443)\tD(fake)1 -1.1712 (-0.8407)\tD(fake)2 -1.4272 (-0.7478)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6171 (-0.5262)\tD repr loss -0.4838 (-0.5229)\n",
            "Epoch: [3][670/781]\tTime  2.519 ( 2.497)\tData  0.000 ( 0.000)\tD(real) 0.2343 (0.9578)\tD(fake)1 -1.5354 (-0.8484)\tD(fake)2 -1.3042 (-0.7482)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5306 (-0.5304)\tD repr loss -0.5437 (-0.5243)\n",
            "Epoch: [3][780/781]\tTime  2.461 ( 2.494)\tData  0.000 ( 0.000)\tD(real) -0.2239 (0.9565)\tD(fake)1 -1.3181 (-0.8215)\tD(fake)2 -1.2961 (-0.7503)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5131 (-0.5235)\tD repr loss -0.4928 (-0.5243)\n",
            "Epoch: [3][780/781]\tTime  2.447 ( 2.494)\tData  0.000 ( 0.000)\tD(real) -0.2239 (0.9565)\tD(fake)1 -1.3181 (-0.8215)\tD(fake)2 -1.2961 (-0.7503)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5131 (-0.5235)\tD repr loss -0.4928 (-0.5243)\n",
            "Epoch: [4][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.8063 (1.1088)\tD(fake)1 -0.4009 (-0.4009)\tD(fake)2 -0.1970 (-0.6292)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5564 (-0.5564)\tD repr loss -0.5205 (-0.5277)\n",
            "Epoch: [4][120/781]\tTime  2.511 ( 2.490)\tData  0.000 ( 0.000)\tD(real) 0.8195 (0.9430)\tD(fake)1 0.1965 (-0.8767)\tD(fake)2 -1.0234 (-0.7575)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6191 (-0.4783)\tD repr loss -0.4696 (-0.5206)\n",
            "Epoch: [4][230/781]\tTime  2.487 ( 2.479)\tData  0.000 ( 0.000)\tD(real) 1.1254 (0.9545)\tD(fake)1 -0.3754 (-0.7617)\tD(fake)2 -0.7322 (-0.7569)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4475 (-0.4925)\tD repr loss -0.5012 (-0.5257)\n",
            "Epoch: [4][340/781]\tTime  2.492 ( 2.478)\tData  0.000 ( 0.000)\tD(real) 0.2036 (0.9535)\tD(fake)1 -0.2176 (-0.6754)\tD(fake)2 -0.8956 (-0.7654)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5688 (-0.5116)\tD repr loss -0.4098 (-0.5260)\n",
            "Epoch: [4][450/781]\tTime  2.443 ( 2.478)\tData  0.000 ( 0.000)\tD(real) 1.5728 (0.9468)\tD(fake)1 -0.7817 (-0.6641)\tD(fake)2 -0.2957 (-0.7641)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5290 (-0.5189)\tD repr loss -0.4995 (-0.5271)\n",
            "Epoch: [4][560/781]\tTime  2.511 ( 2.482)\tData  0.000 ( 0.000)\tD(real) 0.9681 (0.9397)\tD(fake)1 -0.9746 (-0.6933)\tD(fake)2 -0.8221 (-0.7641)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5469 (-0.5259)\tD repr loss -0.5012 (-0.5281)\n",
            "Epoch: [4][670/781]\tTime  2.454 ( 2.483)\tData  0.000 ( 0.000)\tD(real) -0.0800 (0.9368)\tD(fake)1 -1.2069 (-0.7059)\tD(fake)2 -1.3495 (-0.7665)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5892 (-0.5226)\tD repr loss -0.5182 (-0.5276)\n",
            "Epoch: [4][780/781]\tTime  2.498 ( 2.484)\tData  0.000 ( 0.000)\tD(real) 1.7688 (0.9449)\tD(fake)1 -0.3054 (-0.6947)\tD(fake)2 -0.3332 (-0.7603)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6026 (-0.5252)\tD repr loss -0.5395 (-0.5273)\n",
            "Epoch: [4][780/781]\tTime  2.478 ( 2.484)\tData  0.000 ( 0.000)\tD(real) 1.7688 (0.9449)\tD(fake)1 -0.3054 (-0.6947)\tD(fake)2 -0.3332 (-0.7603)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6026 (-0.5252)\tD repr loss -0.5395 (-0.5273)\n",
            "Epoch: [5][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.0650 (0.8446)\tD(fake)1 -1.3941 (-1.3941)\tD(fake)2 -1.2841 (-0.8357)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4205 (-0.4205)\tD repr loss -0.5152 (-0.5242)\n",
            "Epoch: [5][120/781]\tTime  2.500 ( 2.507)\tData  0.000 ( 0.000)\tD(real) 1.0494 (0.9383)\tD(fake)1 -1.3807 (-0.7763)\tD(fake)2 -0.8909 (-0.7633)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5450 (-0.5240)\tD repr loss -0.5336 (-0.5246)\n",
            "Epoch: [5][230/781]\tTime  2.512 ( 2.509)\tData  0.000 ( 0.000)\tD(real) 2.7114 (0.9927)\tD(fake)1 -0.7078 (-0.9023)\tD(fake)2 0.0905 (-0.7620)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5900 (-0.5313)\tD repr loss -0.4973 (-0.5251)\n",
            "Epoch: [5][340/781]\tTime  2.467 ( 2.502)\tData  0.000 ( 0.000)\tD(real) 0.5549 (0.9989)\tD(fake)1 -0.6567 (-0.8866)\tD(fake)2 -1.1251 (-0.7711)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5612 (-0.5411)\tD repr loss -0.5037 (-0.5290)\n",
            "Epoch: [5][450/781]\tTime  2.467 ( 2.495)\tData  0.000 ( 0.000)\tD(real) 1.7059 (0.9927)\tD(fake)1 -0.4959 (-0.8171)\tD(fake)2 -0.2190 (-0.7668)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5796 (-0.5403)\tD repr loss -0.4348 (-0.5288)\n",
            "Epoch: [5][560/781]\tTime  2.487 ( 2.495)\tData  0.000 ( 0.000)\tD(real) 1.5244 (0.9763)\tD(fake)1 -0.5300 (-0.8189)\tD(fake)2 -0.4815 (-0.7670)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4994 (-0.5327)\tD repr loss -0.4923 (-0.5291)\n",
            "Epoch: [5][670/781]\tTime  2.528 ( 2.498)\tData  0.000 ( 0.000)\tD(real) 1.6545 (0.9872)\tD(fake)1 -0.5185 (-0.8225)\tD(fake)2 -0.4716 (-0.7655)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5837 (-0.5359)\tD repr loss -0.5512 (-0.5277)\n",
            "Epoch: [5][780/781]\tTime  2.498 ( 2.500)\tData  0.000 ( 0.000)\tD(real) 1.1534 (0.9762)\tD(fake)1 0.0290 (-0.7866)\tD(fake)2 -0.6984 (-0.7620)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5809 (-0.5352)\tD repr loss -0.5082 (-0.5277)\n",
            "Epoch: [5][780/781]\tTime  2.444 ( 2.499)\tData  0.000 ( 0.000)\tD(real) 1.1534 (0.9762)\tD(fake)1 0.0290 (-0.7866)\tD(fake)2 -0.6984 (-0.7620)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5809 (-0.5352)\tD repr loss -0.5082 (-0.5277)\n",
            "Epoch: [6][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) -0.3257 (0.6505)\tD(fake)1 -1.0377 (-1.0377)\tD(fake)2 -1.4885 (-0.8319)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6278 (-0.6278)\tD repr loss -0.5033 (-0.5446)\n",
            "Epoch: [6][120/781]\tTime  2.508 ( 2.509)\tData  0.000 ( 0.000)\tD(real) 1.8964 (0.8867)\tD(fake)1 -0.2999 (-0.7635)\tD(fake)2 0.3699 (-0.7593)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4333 (-0.5388)\tD repr loss -0.5003 (-0.5283)\n",
            "Epoch: [6][230/781]\tTime  2.522 ( 2.505)\tData  0.000 ( 0.000)\tD(real) 0.2291 (0.8930)\tD(fake)1 -1.4574 (-0.8269)\tD(fake)2 -1.2574 (-0.7655)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1128 (-0.5243)\tD repr loss -0.5620 (-0.5287)\n",
            "Epoch: [6][340/781]\tTime  2.511 ( 2.500)\tData  0.000 ( 0.000)\tD(real) 0.3435 (0.9049)\tD(fake)1 -1.1477 (-0.8161)\tD(fake)2 -1.0480 (-0.7691)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5441 (-0.5188)\tD repr loss -0.4248 (-0.5294)\n",
            "Epoch: [6][450/781]\tTime  2.512 ( 2.498)\tData  0.000 ( 0.000)\tD(real) 0.0633 (0.9204)\tD(fake)1 -1.6048 (-0.8424)\tD(fake)2 -1.4526 (-0.7701)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5439 (-0.5243)\tD repr loss -0.4781 (-0.5308)\n",
            "Epoch: [6][560/781]\tTime  2.498 ( 2.497)\tData  0.000 ( 0.000)\tD(real) 0.4582 (0.9269)\tD(fake)1 -0.9824 (-0.7697)\tD(fake)2 -1.0745 (-0.7677)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5728 (-0.5264)\tD repr loss -0.4986 (-0.5297)\n",
            "Epoch: [6][670/781]\tTime  2.518 ( 2.496)\tData  0.000 ( 0.000)\tD(real) 1.6995 (0.9376)\tD(fake)1 -0.7218 (-0.7428)\tD(fake)2 -0.1589 (-0.7682)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5345 (-0.5251)\tD repr loss -0.5216 (-0.5282)\n",
            "Epoch: [6][780/781]\tTime  2.495 ( 2.493)\tData  0.000 ( 0.000)\tD(real) 1.4781 (0.9417)\tD(fake)1 -0.0356 (-0.7295)\tD(fake)2 -0.4014 (-0.7651)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5703 (-0.5271)\tD repr loss -0.5489 (-0.5268)\n",
            "Epoch: [6][780/781]\tTime  2.486 ( 2.493)\tData  0.000 ( 0.000)\tD(real) 1.4781 (0.9417)\tD(fake)1 -0.0356 (-0.7295)\tD(fake)2 -0.4014 (-0.7651)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5703 (-0.5271)\tD repr loss -0.5489 (-0.5268)\n",
            "Epoch: [7][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.3974 (0.7993)\tD(fake)1 -1.7982 (-1.7982)\tD(fake)2 -1.1190 (-0.9005)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1682 (-0.1682)\tD repr loss -0.5296 (-0.4833)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-23fcf3414282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_per_cell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msave_vid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-a02757e7183e>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         train(train_loader, model, simsiam,\n\u001b[0;32m---> 19\u001b[0;31m             D_criterion, G_criterion, D_optimizer, G_optimizer, epoch, args)\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mD_sched\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mG_sched\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-78a49954f70b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, simsiam, D_criterion, G_criterion, D_optimizer, G_optimizer, epoch, args)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;31m# Sample from generator given repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                     \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_G\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0;31m# Classify real and fake data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mD_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_h\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-13367ec6e7bf>\u001b[0m in \u001b[0;36msample_G\u001b[0;34m(repr)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatent_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfake\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim_noise\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-91c9f974657c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z, repr)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock4\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-91c9f974657c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, repr)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbypass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/upsampling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malign_corners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor)\u001b[0m\n\u001b[1;32m   3710\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_nearest1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3711\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nearest\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3712\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_nearest2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3713\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nearest\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3714\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_nearest3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5V-0_k5tpiW"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdIo707ZyUic"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9naW-A2OGLMg"
      },
      "source": [
        "args.G_consistency = 1.\n",
        "args.D_consistency = 1.\n",
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzUaCS1tS8YV"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKWZPniqS5uX"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYyP-fb7S-WE"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jC0_2Vt4Yd6"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogpaUfV94ZJI"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5Bh97MA4aCW"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMSlrEvie7Pa"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvYdbtKQe_2-"
      },
      "source": [
        "def show_grid(grid):\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(grid.permute(1,2,0))\n",
        "\n",
        "def sample_interpolated_repr(real1, real2):\n",
        "    repr1, repr2 = get_repr(real1), get_repr(real2)\n",
        "    repr = slerp(repr1, repr2)\n",
        "    #repr = lerp(repr1, repr2)\n",
        "    return repr\n",
        "\n",
        "def show_sample(data_sampler):\n",
        "    x, _ = next(data_sampler)\n",
        "    #plt.hist(F.normalize(simsiam.encoder(x)).detach()[0].cpu().numpy()); return\n",
        "    x1 = x.cuda(args.gpu)[:16]\n",
        "    x2 = x.cuda(args.gpu)[16:32]\n",
        "    show_grid(vutils.make_grid(inv_normalize(x1).cpu(), padding=2, nrow=4))\n",
        "    show_grid(vutils.make_grid(inv_normalize(x2).cpu(), padding=2, nrow=4))\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x_fake1 = sample_G(sample_interpolated_repr(x1, x2))\n",
        "        x_fake2 = sample_G(sample_interpolated_repr(x1, x2))\n",
        "    show_grid(vutils.make_grid(inv_normalize(x_fake1).cpu(), padding=2, nrow=4))\n",
        "    show_grid(vutils.make_grid(inv_normalize(x_fake2).cpu(), padding=2, nrow=4))\n",
        "\n",
        "data_sampler = iter(train_loader)\n",
        "show_sample(data_sampler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gfx3T5m2wah"
      },
      "source": [
        "def show_sample2(data_sampler):\n",
        "    x, _ = next(data_sampler)\n",
        "    x = x.cuda(args.gpu)[:16]\n",
        "    show_grid(vutils.make_grid(inv_normalize(x).cpu(), padding=2, nrow=4))\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x_fake = sample_G(get_repr(x))\n",
        "    show_grid(vutils.make_grid(inv_normalize(x_fake).cpu(), padding=2, nrow=4))\n",
        "\n",
        "show_sample2(data_sampler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKfockIQPyzO"
      },
      "source": [
        "def show_sample3(data_sampler):\n",
        "    x, _ = next(data_sampler)\n",
        "    x = x.cuda(args.gpu)[:16]\n",
        "    show_grid(vutils.make_grid(inv_normalize(x).cpu(), padding=2, nrow=4))\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        repr1 = -1+2*torch.rand(16, args.repr_dim).cuda(args.gpu)\n",
        "        repr2 = torch.randn(16, args.repr_dim).cuda(args.gpu)\n",
        "        x_fake1 = sample_G(repr1)\n",
        "        x_fake2 = sample_G(repr2)\n",
        "    show_grid(vutils.make_grid(inv_normalize(x_fake1).cpu(), padding=2, nrow=4))\n",
        "    show_grid(vutils.make_grid(inv_normalize(x_fake2).cpu(), padding=2, nrow=4))\n",
        "\n",
        "show_sample3(data_sampler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtDpMGCMid7O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU296umGlbxU"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqJajcHmlcOD"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itX7h7kylcnQ"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuR7QOUQlc7p"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2wAhFAbldNu"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZDNQca57Hif"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GAN Metrics"
      ],
      "metadata": {
        "id": "fOJDDiKcl_Bf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Samples"
      ],
      "metadata": {
        "id": "amfnRSk_nF6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLES_DIR = f\"{GANSIAM_DIR}/generated_samples\"\n",
        "NUM_SAMPLES = 10000\n",
        "! mkdir \"{SAMPLES_DIR}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9iP0Jgy0ZtY",
        "outputId": "abb1d6c2-c94d-4708-b8a6-f54e171ec346"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/My Drive/gansiam/generated_samples’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training dataset loader to sample repr\n",
        "train_dataset = datasets.ImageFolder(\n",
        "    root=os.path.join(TINYIMAGENET_DIR, 'train'),\n",
        "    transform=transforms.Compose(augmentation))\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=args.batch_size, shuffle=True,\n",
        "    num_workers=0, pin_memory=True, sampler=None, drop_last=True)"
      ],
      "metadata": {
        "id": "58HfLOhYoq9q"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.utils import save_image\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "model.eval()\n",
        "im_idx = 0\n",
        "for _ in tqdm(range(NUM_SAMPLES // (len(train_loader) * args.batch_size) + 1)):\n",
        "    for x, _ in tqdm(train_loader):\n",
        "        if im_idx > NUM_SAMPLES:\n",
        "            break\n",
        "        x = x.cuda(args.gpu)\n",
        "        with torch.no_grad():\n",
        "            repr = get_repr(x)\n",
        "            noise = sample_noise(args.batch_size).cuda(args.gpu)\n",
        "            z = latent_transform(repr, noise)\n",
        "            x_fake = model.G(z, repr)\n",
        "        for batch_idx in range(args.batch_size):\n",
        "            save_image(x_fake[batch_idx], f\"{SAMPLES_DIR}/{im_idx:04}.png\",\n",
        "                       normalize=True, range=(-1,1))\n",
        "            im_idx += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150,
          "referenced_widgets": [
            "ce15db1308cf4137a2651c8dfe89f3c2",
            "8703519d345d4810b176a58f12e00af3",
            "9442ab6eda044d92a55b12aadd92a654",
            "2444b40302af4c889a2ae77e7c01a3b3",
            "5b87e2d7c84e41d390d9b563c688a7b7",
            "28ea9c3081944102a13d7b6d3857eeb1",
            "d822e29f9bde48b69ed5d7190fb60cef",
            "ecef038dece54a0ab78ad42ac9512dea",
            "4b8dbe767bb9460bba2e7b209d16fdf8",
            "6a11c43e1ef24e8a9a6bbbac57f00baa",
            "68328d286f264b8a9af2596a229ddb0a",
            "d80138f64466454e9e4b082a2ca9ae2d",
            "2435793fc4104ff28dd4f7331d190de7",
            "e1670c2b447a4f4aa3a90cf43063099c",
            "57845f65f9ed4616a94a8705c24a5633",
            "c2a0baa293da4d80882a040cc2213d05",
            "94b490b78049466e9841e8d19375bab3",
            "81ec79b2732541c68192101ea5ed93c5",
            "fe4dc33999b2426cb90c315f0132315f",
            "27db98ab6d5540b98eacbc5533566cee",
            "e40ed04938fd43c4806e148878ebd31b",
            "168e2b0a3f9846aaa4da5fa989d4ee43"
          ]
        },
        "id": "hjdpBkcUtJtM",
        "outputId": "82b43974-c135-4711-9acc-3af2df80391d"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce15db1308cf4137a2651c8dfe89f3c2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d80138f64466454e9e4b082a2ca9ae2d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/781 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inception Score"
      ],
      "metadata": {
        "id": "w00eHq1ltw41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/sbarratt/inception-score-pytorch.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XUf5i4o6brj",
        "outputId": "5fc88231-e41f-4d29-977e-49eedc2b9763"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'inception-score-pytorch' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd inception-score-pytorch\n",
        "from inception_score import inception_score\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUBqMUnamS77",
        "outputId": "28987e77-ae00-4971-af9d-d1f6dcb1c33d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/inception-score-pytorch\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Images(torch.utils.data.Dataset):\n",
        "    def __init__(self, main_dir, transform=None):\n",
        "        self.main_dir = main_dir\n",
        "        self.transform = transform\n",
        "        all_imgs = os.listdir(main_dir)\n",
        "        self.total_imgs = sorted(all_imgs)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.total_imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n",
        "        image = Image.open(img_loc).convert(\"RGB\")\n",
        "        if self.transform is not None:\n",
        "            tensor_image = self.transform(image)\n",
        "        else:\n",
        "            tensor_image = torch.Tensor(image)\n",
        "        return tensor_image\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(299),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "samples_dataset = Images(SAMPLES_DIR, transform)"
      ],
      "metadata": {
        "id": "8BNlMvEeve07"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inception_score(samples_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BWuNsEPm6O2",
        "outputId": "28af6e8f-3541-4c1d-aad7-7ef8c2545d17"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/inception-score-pytorch/inception_score.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x).data.cpu().numpy()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2.390274434158649, 0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FID"
      ],
      "metadata": {
        "id": "e1jht22Lxtt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-fid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caGUOYRfxwvT",
        "outputId": "e1044bb5-4ede-42c2-db2b-7f73b4b409a5"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-fid\n",
            "  Downloading pytorch-fid-0.2.1.tar.gz (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (1.19.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (7.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.1->pytorch-fid) (3.10.0.2)\n",
            "Building wheels for collected packages: pytorch-fid\n",
            "  Building wheel for pytorch-fid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-fid: filename=pytorch_fid-0.2.1-py3-none-any.whl size=14835 sha256=b9bc2b25138faafe83b7bbaf0976cc2611cf27f577434f011a84cee638138e24\n",
            "  Stored in directory: /root/.cache/pip/wheels/24/ac/03/c5634775c8a64f702343ef5923278f8d3bb8c651debc4a6890\n",
            "Successfully built pytorch-fid\n",
            "Installing collected packages: pytorch-fid\n",
            "Successfully installed pytorch-fid-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"{TINYIMAGENET_DIR}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXrQF37bFsku",
        "outputId": "6274e097-c073-4db6-be52-2d7a774f24f4"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tiny-imagenet-200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# flatten tiny imagenet\n",
        "! rm -rf flattinyimagenet && mkdir -p flattinyimagenet\n",
        "! for folder in \"tiny-imagenet-200\"/train/*; do for im in \"$folder\"/images/*; do cp \"$(echo $im | tr 'A-Z' 'a-z')\" flattinyimagenet ; done; done"
      ],
      "metadata": {
        "id": "IaMFBXuBCrsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pytorch_fid --device cuda:0 flattinyimagenet \"{SAMPLES_DIR}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEruFG3__bTv",
        "outputId": "682169ca-873b-4165-d3c2-1b62bc717b66"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tcmalloc: large alloc 1638400000 bytes == 0x5629ab83a000 @  0x7f13b71661e7 0x7f13b4c6646e 0x7f13b4cb6c7b 0x7f13b4cb735f 0x7f13b4d59103 0x5629299fb4b0 0x5629299fb240 0x562929a6f0f3 0x562929a699ee 0x5629299fcbda 0x562929a6a915 0x562929a699ee 0x5629299fcbda 0x562929a6a915 0x562929a69ced 0x5629299fcbda 0x562929a6a915 0x562929a699ee 0x5629299fcbda 0x562929a6a915 0x5629299fcafa 0x562929a6ed00 0x562929a699ee 0x562929a696f3 0x562929a67b60 0x5629299fb349 0x5629299fb240 0x562929a6e973 0x562929a699ee 0x5629299fcbda 0x562929a6a915\n",
            "100% 2000/2000 [04:04<00:00,  8.19it/s]\n",
            "tcmalloc: large alloc 1638400000 bytes == 0x562a0d2ea000 @  0x7f13b71661e7 0x7f13b4c6646e 0x7f13b4cb6c7b 0x7f13b4cb6d97 0x7f13b4cb04a5 0x7f13b4d5b823 0x5629299fb544 0x5629299fb240 0x562929a6f627 0x562929a699ee 0x56292993be2b 0x7f13b4ca3ef7 0x5629299fb437 0x5629299fb240 0x562929a6e973 0x562929a699ee 0x5629299fcbda 0x562929a6b737 0x562929a699ee 0x5629299fcbda 0x562929a6a915 0x562929a69ced 0x5629299fcbda 0x562929a6a915 0x562929a699ee 0x5629299fcbda 0x562929a6a915 0x5629299fcafa 0x562929a6ed00 0x562929a699ee 0x562929a696f3\n",
            "100% 203/203 [00:29<00:00,  6.90it/s]\n",
            "FID:  230.0156421720286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5e8mEUXaCZ5D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}